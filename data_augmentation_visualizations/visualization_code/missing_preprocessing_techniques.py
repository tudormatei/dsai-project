"""
Missing Preprocessing Techniques Visualization

This script creates individual visualizations for the two missing preprocessing
techniques: Time Conversion and Padding/Truncation, matching the style of
preprocessing_slide2_solution.png
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Set style to match the existing slides
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("Set2")

def create_time_conversion_slide():
    """Create visualization for Time Conversion technique"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # Generate realistic timestamp data
    np.random.seed(42)
    n_samples = 100
    start_time = 1640995200000  # Unix timestamp in milliseconds
    
    # Simulate raw timestamps (in milliseconds)
    timestamps_raw = np.linspace(start_time, start_time + 5000, n_samples)
    timestamps_raw += np.random.normal(0, 10, n_samples)  # Add some jitter
    
    # Convert to seconds from start
    timestamps_seconds = (timestamps_raw - start_time) / 1000.0
    
    # Generate corresponding sensor data
    time_points = np.linspace(0, 5, n_samples)
    x_data = 2 * np.sin(2 * np.pi * time_points) + np.random.normal(0, 0.5, n_samples)
    y_data = 1.5 * np.cos(2 * np.pi * time_points * 1.2) + np.random.normal(0, 0.3, n_samples)
    z_data = 1 * np.sin(2 * np.pi * time_points * 0.8) + np.random.normal(0, 0.2, n_samples)
    
    # Left plot: Raw timestamps
    ax1.plot(timestamps_raw, x_data, 'r-', linewidth=2, label='X-axis', alpha=0.8)
    ax1.plot(timestamps_raw, y_data, 'g-', linewidth=2, label='Y-axis', alpha=0.8)
    ax1.plot(timestamps_raw, z_data, 'b-', linewidth=2, label='Z-axis', alpha=0.8)
    ax1.set_title('Raw Timestamps (Milliseconds)', fontsize=16, fontweight='bold')
    ax1.set_xlabel('Timestamp (ms)', fontsize=12)
    ax1.set_ylabel('Acceleration (m/sÂ²)', fontsize=12)
    ax1.legend(fontsize=12)
    ax1.grid(True, alpha=0.3)
    
    # Add timestamp examples
    ax1.text(0.02, 0.98, f'Example timestamps:\n{int(timestamps_raw[0]):,} ms\n{int(timestamps_raw[50]):,} ms\n{int(timestamps_raw[-1]):,} ms',
             transform=ax1.transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9),
             fontsize=10)
    
    # Right plot: Converted to seconds from start
    ax2.plot(timestamps_seconds, x_data, 'r-', linewidth=2, label='X-axis', alpha=0.8)
    ax2.plot(timestamps_seconds, y_data, 'g-', linewidth=2, label='Y-axis', alpha=0.8)
    ax2.plot(timestamps_seconds, z_data, 'b-', linewidth=2, label='Z-axis', alpha=0.8)
    ax2.set_title('Time Conversion: Seconds from Start', fontsize=16, fontweight='bold')
    ax2.set_xlabel('Time (seconds)', fontsize=12)
    ax2.set_ylabel('Acceleration (m/sÂ²)', fontsize=12)
    ax2.legend(fontsize=12)
    ax2.grid(True, alpha=0.3)
    
    # Add conversion examples
    ax2.text(0.02, 0.98, f'Converted times:\n{timestamps_seconds[0]:.2f} s\n{timestamps_seconds[50]:.2f} s\n{timestamps_seconds[-1]:.2f} s',
             transform=ax2.transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9),
             fontsize=10)
    
    # Add conversion formula
    ax2.text(0.5, 0.02, 'Formula: (timestamp - start_time) / 1000.0',
             transform=ax2.transAxes, ha='center', fontsize=12, fontweight='bold',
             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig('/Users/mariarye/Desktop/UNI 2025-2026/DS & AI/Project/dsai-project/data_augmentation_visualizations/preprocessing_slide_time_conversion.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

def create_padding_truncation_slide():
    """Create visualization for Padding/Truncation technique"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # Generate realistic sensor data
    np.random.seed(42)
    n_samples = 100
    time_points = np.linspace(0, 5, n_samples)
    
    x_data = 2 * np.sin(2 * np.pi * time_points) + np.random.normal(0, 0.3, n_samples)
    y_data = 1.5 * np.cos(2 * np.pi * time_points * 1.2) + np.random.normal(0, 0.2, n_samples)
    z_data = 1 * np.sin(2 * np.pi * time_points * 0.8) + np.random.normal(0, 0.1, n_samples)
    
    # Left plot: Variable-length windows (before padding/truncation)
    window_size = 60
    n_windows = 3
    window_start = 20
    
    ax1.plot(time_points, x_data, 'gray', alpha=0.3, linewidth=1, label='Full Signal')
    
    # Show different window lengths
    colors = ['red', 'blue', 'green']
    window_lengths = [40, 60, 80]  # Different lengths
    
    for i, (color, length) in enumerate(zip(colors, window_lengths)):
        start_idx = window_start + i * 15
        end_idx = start_idx + length
        if end_idx < len(time_points):
            window_time = time_points[start_idx:end_idx]
            window_x = x_data[start_idx:end_idx]
            
            ax1.plot(window_time, window_x, color=color, linewidth=3, 
                    label=f'Window {i+1} ({length} samples)')
            ax1.axvspan(time_points[start_idx], time_points[end_idx-1], 
                       alpha=0.2, color=color)
    
    ax1.set_title('Variable-Length Windows (Before Processing)', fontsize=16, fontweight='bold')
    ax1.set_xlabel('Time (seconds)', fontsize=12)
    ax1.set_ylabel('Acceleration (m/sÂ²)', fontsize=12)
    ax1.legend(fontsize=12)
    ax1.grid(True, alpha=0.3)
    
    # Add statistics
    ax1.text(0.02, 0.98, f'Window lengths:\n40, 60, 80 samples\nInconsistent sizes!',
             transform=ax1.transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9),
             fontsize=10)
    
    # Right plot: Fixed-length windows (after padding/truncation)
    ax2.plot(time_points, x_data, 'gray', alpha=0.3, linewidth=1, label='Full Signal')
    
    # Show fixed-length windows
    for i, color in enumerate(colors):
        start_idx = window_start + i * 15
        end_idx = start_idx + window_size
        if end_idx < len(time_points):
            window_time = time_points[start_idx:end_idx]
            window_x = x_data[start_idx:end_idx]
            
            ax2.plot(window_time, window_x, color=color, linewidth=3, 
                    label=f'Window {i+1} (60 samples)')
            ax2.axvspan(time_points[start_idx], time_points[end_idx-1], 
                       alpha=0.2, color=color)
    
    ax2.set_title('Fixed-Length Windows (After Padding/Truncation)', fontsize=16, fontweight='bold')
    ax2.set_xlabel('Time (seconds)', fontsize=12)
    ax2.set_ylabel('Acceleration (m/sÂ²)', fontsize=12)
    ax2.legend(fontsize=12)
    ax2.grid(True, alpha=0.3)
    
    # Add processing details
    ax2.text(0.02, 0.98, f'All windows: 60 samples\nShort â†’ Zero-padded\nLong â†’ Truncated',
             transform=ax2.transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9),
             fontsize=10)
    
    # Add processing rules
    ax2.text(0.5, 0.02, 'Rules: Short windows â†’ Pad with zeros, Long windows â†’ Truncate to 60',
             transform=ax2.transAxes, ha='center', fontsize=12, fontweight='bold',
             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig('/Users/mariarye/Desktop/UNI 2025-2026/DS & AI/Project/dsai-project/data_augmentation_visualizations/preprocessing_slide_padding_truncation.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

def create_detailed_padding_truncation_example():
    """Create detailed example showing padding and truncation process"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Padding/Truncation: Detailed Process', fontsize=18, fontweight='bold')
    
    # Generate example data
    np.random.seed(42)
    
    # 1. Short window (needs padding)
    short_window = np.random.normal(0, 1, 40)
    short_padded = np.pad(short_window, (0, 20), mode='constant', constant_values=0)
    
    ax1.plot(range(40), short_window, 'b-', linewidth=2, label='Original (40 samples)')
    ax1.set_title('Short Window: Before Padding', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Sample Index')
    ax1.set_ylabel('Value')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_xlim(0, 60)
    
    ax2.plot(range(60), short_padded, 'g-', linewidth=2, label='Padded (60 samples)')
    ax2.axvline(x=40, color='red', linestyle='--', alpha=0.7, label='Padding starts')
    ax2.set_title('Short Window: After Padding', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Sample Index')
    ax2.set_ylabel('Value')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 2. Long window (needs truncation)
    long_window = np.random.normal(0, 1, 80)
    long_truncated = long_window[:60]
    
    ax3.plot(range(80), long_window, 'b-', linewidth=2, label='Original (80 samples)')
    ax3.axvline(x=60, color='red', linestyle='--', alpha=0.7, label='Truncation point')
    ax3.set_title('Long Window: Before Truncation', fontsize=14, fontweight='bold')
    ax3.set_xlabel('Sample Index')
    ax3.set_ylabel('Value')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    ax4.plot(range(60), long_truncated, 'g-', linewidth=2, label='Truncated (60 samples)')
    ax4.set_title('Long Window: After Truncation', fontsize=14, fontweight='bold')
    ax4.set_xlabel('Sample Index')
    ax4.set_ylabel('Value')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('/Users/mariarye/Desktop/UNI 2025-2026/DS & AI/Project/dsai-project/data_augmentation_visualizations/preprocessing_slide_padding_truncation_detailed.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

def create_all_preprocessing_summary():
    """Create a summary showing all 4 preprocessing techniques"""
    
    fig, ax = plt.subplots(1, 1, figsize=(16, 10))
    ax.axis('off')
    
    # Create a comprehensive summary
    summary_text = """
    ðŸ”§ PREPROCESSING & NORMALIZATION: ALL 4 TECHNIQUES
    
    ðŸ“‹ COMPLETE PREPROCESSING PIPELINE:
    
    1. STANDARDSCALER: Z-score Normalization
       â€¢ Converts raw sensor data to standardized form
       â€¢ Mean = 0, Standard Deviation = 1
       â€¢ Ensures all axes contribute equally to learning
       â€¢ Formula: (x - mean) / std
    
    2. OUTLIER CLIPPING: Values clipped to [-3, 3] standard deviations
       â€¢ Removes extreme values that could hurt model performance
       â€¢ Clips values beyond Â±3Ïƒ to Â±3Ïƒ
       â€¢ Prevents outliers from dominating the model
       â€¢ Typically removes <1% of data points
    
    3. TIME CONVERSION: Timestamp to seconds from start
       â€¢ Converts raw timestamps to relative time
       â€¢ Creates consistent temporal reference frame
       â€¢ Formula: (timestamp - start_time) / 1000.0
       â€¢ Enables proper time-series analysis
    
    4. PADDING/TRUNCATION: Fixed-length windows (60 samples)
       â€¢ Ensures all windows have exactly 60 samples
       â€¢ Short windows: Zero-padded to 60 samples
       â€¢ Long windows: Truncated to 60 samples
       â€¢ Enables batch processing with fixed input size
    
    ðŸŽ¯ WHY EACH TECHNIQUE MATTERS:
    â€¢ StandardScaler: Equal contribution from all sensor axes
    â€¢ Outlier Clipping: Robust to extreme sensor readings
    â€¢ Time Conversion: Consistent temporal reference
    â€¢ Padding/Truncation: Fixed input size for neural networks
    
    ðŸ“Š IMPACT ON MODEL PERFORMANCE:
    â€¢ Without preprocessing: 26% accuracy (random guessing)
    â€¢ With preprocessing: 70.7% accuracy (production-ready)
    â€¢ Improvement: +226% relative improvement
    â€¢ Preprocessing is essential for deep learning success
    
    âœ… ALL 4 TECHNIQUES WERE IMPLEMENTED AND USED
    """
    
    ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=14,
            verticalalignment='top', fontfamily='sans-serif',
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))
    
    plt.tight_layout()
    plt.savefig('/Users/mariarye/Desktop/UNI 2025-2026/DS & AI/Project/dsai-project/data_augmentation_visualizations/preprocessing_all_techniques_summary.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

if __name__ == "__main__":
    print("Creating individual visualizations for missing preprocessing techniques...")
    
    # Generate individual slides for missing techniques
    create_time_conversion_slide()
    create_padding_truncation_slide()
    create_detailed_padding_truncation_example()
    create_all_preprocessing_summary()
    
    print("\nâœ… Missing preprocessing techniques visualizations complete!")
    print("ðŸ“ Files saved to data_augmentation_visualizations/")
    print("   â€¢ preprocessing_slide_time_conversion.png")
    print("   â€¢ preprocessing_slide_padding_truncation.png")
    print("   â€¢ preprocessing_slide_padding_truncation_detailed.png")
    print("   â€¢ preprocessing_all_techniques_summary.png")


