"""
Preprocessing & Normalization: Presentation Slides

This script creates clean, presentation-ready visualizations for the
preprocessing section of your project presentation.
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Set style for presentations
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("Set2")

def create_preprocessing_slide_1():
    """Slide 1: The Problem - Raw Sensor Data"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # Generate realistic raw sensor data
    np.random.seed(42)
    n_samples = 500
    time_points = np.linspace(0, 5, n_samples)
    
    # Simulate raw accelerometer data with different scales
    x_raw = 5 * np.sin(2 * np.pi * time_points) + np.random.normal(0, 2, n_samples)
    y_raw = 8 * np.cos(2 * np.pi * time_points * 1.5) + np.random.normal(0, 3, n_samples)
    z_raw = 3 * np.sin(2 * np.pi * time_points * 0.8) + np.random.normal(0, 1.5, n_samples)
    
    # Add outliers
    outlier_indices = np.random.choice(n_samples, 15, replace=False)
    x_raw[outlier_indices[:5]] += np.random.normal(0, 15, 5)
    y_raw[outlier_indices[5:10]] += np.random.normal(0, 20, 5)
    z_raw[outlier_indices[10:]] += np.random.normal(0, 12, 5)
    
    # Left plot: Raw data
    ax1.plot(time_points, x_raw, 'r-', linewidth=2, label='X-axis', alpha=0.8)
    ax1.plot(time_points, y_raw, 'g-', linewidth=2, label='Y-axis', alpha=0.8)
    ax1.plot(time_points, z_raw, 'b-', linewidth=2, label='Z-axis', alpha=0.8)
    ax1.set_title('Raw Sensor Data: The Problem', fontsize=16, fontweight='bold')
    ax1.set_xlabel('Time (seconds)')
    ax1.set_ylabel('Acceleration (m/sÂ²)')
    ax1.legend(fontsize=12)
    ax1.grid(True, alpha=0.3)
    
    # Add statistics
    ax1.text(0.02, 0.98, f'X: Î¼={np.mean(x_raw):.1f}, Ïƒ={np.std(x_raw):.1f}\n'
                         f'Y: Î¼={np.mean(y_raw):.1f}, Ïƒ={np.std(y_raw):.1f}\n'
                         f'Z: Î¼={np.mean(z_raw):.1f}, Ïƒ={np.std(z_raw):.1f}',
             transform=ax1.transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.9),
             fontsize=11)
    
    # Right plot: Statistical comparison
    data_for_box = [x_raw, y_raw, z_raw]
    labels = ['X-axis', 'Y-axis', 'Z-axis']
    
    bp = ax2.boxplot(data_for_box, labels=labels, patch_artist=True)
    colors = ['lightcoral', 'lightgreen', 'lightblue']
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
    
    ax2.set_title('Different Scales & Outliers', fontsize=16, fontweight='bold')
    ax2.set_ylabel('Acceleration (m/sÂ²)')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('/Users/mariarye/Desktop/UNI 2025-2026/DS & AI/Project/dsai-project/data_augmentation_visualizations/preprocessing_slide1_problem.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

def create_preprocessing_slide_2():
    """Slide 2: The Solution - Preprocessing Pipeline"""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # Generate data
    np.random.seed(42)
    n_samples = 300
    time_points = np.linspace(0, 3, n_samples)
    
    x_raw = 5 * np.sin(2 * np.pi * time_points) + np.random.normal(0, 2, n_samples)
    y_raw = 8 * np.cos(2 * np.pi * time_points * 1.5) + np.random.normal(0, 3, n_samples)
    z_raw = 3 * np.sin(2 * np.pi * time_points * 0.8) + np.random.normal(0, 1.5, n_samples)
    
    # Add outliers
    outlier_indices = np.random.choice(n_samples, 10, replace=False)
    x_raw[outlier_indices[:3]] += np.random.normal(0, 15, 3)
    y_raw[outlier_indices[3:6]] += np.random.normal(0, 20, 3)
    z_raw[outlier_indices[6:]] += np.random.normal(0, 12, 4)
    
    # 1. StandardScaler
    scaler = StandardScaler()
    data_raw = np.column_stack([x_raw, y_raw, z_raw])
    data_scaled = scaler.fit_transform(data_raw)
    x_scaled, y_scaled, z_scaled = data_scaled[:, 0], data_scaled[:, 1], data_scaled[:, 2]
    
    ax1.plot(time_points, x_scaled, 'r-', linewidth=2, label='X-axis', alpha=0.8)
    ax1.plot(time_points, y_scaled, 'g-', linewidth=2, label='Y-axis', alpha=0.8)
    ax1.plot(time_points, z_scaled, 'b-', linewidth=2, label='Z-axis', alpha=0.8)
    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    ax1.axhline(y=3, color='red', linestyle='--', alpha=0.5, label='Â±3Ïƒ bounds')
    ax1.axhline(y=-3, color='red', linestyle='--', alpha=0.5)
    ax1.set_title('1. StandardScaler: Z-score Normalization', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Time (seconds)')
    ax1.set_ylabel('Normalized Acceleration')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(-5, 5)
    
    # 2. Outlier Clipping
    x_clipped = np.clip(x_scaled, -3, 3)
    y_clipped = np.clip(y_scaled, -3, 3)
    z_clipped = np.clip(z_scaled, -3, 3)
    
    ax2.plot(time_points, x_clipped, 'r-', linewidth=2, label='X-axis', alpha=0.8)
    ax2.plot(time_points, y_clipped, 'g-', linewidth=2, label='Y-axis', alpha=0.8)
    ax2.plot(time_points, z_clipped, 'b-', linewidth=2, label='Z-axis', alpha=0.8)
    ax2.axhline(y=3, color='red', linestyle='--', alpha=0.5, label='Â±3Ïƒ bounds')
    ax2.axhline(y=-3, color='red', linestyle='--', alpha=0.5)
    ax2.set_title('2. Outlier Clipping: Â±3Ïƒ', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Time (seconds)')
    ax2.set_ylabel('Clipped Acceleration')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(-4, 4)
    
    # 3. Windowing
    window_size = 60
    n_windows = 3
    window_start = 50
    
    ax3.plot(time_points, x_clipped, 'gray', alpha=0.3, linewidth=1)
    
    colors = ['red', 'blue', 'green']
    for i in range(n_windows):
        start_idx = window_start + i * window_size
        end_idx = start_idx + window_size
        if end_idx < len(time_points):
            window_time = time_points[start_idx:end_idx]
            window_data = x_clipped[start_idx:end_idx]
            ax3.plot(window_time, window_data, color=colors[i], linewidth=3, 
                    label=f'Window {i+1}')
            ax3.axvspan(time_points[start_idx], time_points[end_idx-1], 
                       alpha=0.2, color=colors[i])
    
    ax3.set_title('3. Windowing: 3-second Windows (60 samples)', fontsize=14, fontweight='bold')
    ax3.set_xlabel('Time (seconds)')
    ax3.set_ylabel('Acceleration')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. Final Result
    ax4.plot(range(60), x_clipped[50:110], 'r-', linewidth=2, label='X-axis', alpha=0.8)
    ax4.plot(range(60), y_clipped[50:110], 'g-', linewidth=2, label='Y-axis', alpha=0.8)
    ax4.plot(range(60), z_clipped[50:110], 'b-', linewidth=2, label='Z-axis', alpha=0.8)
    ax4.set_title('4. Final Processed Window', fontsize=14, fontweight='bold')
    ax4.set_xlabel('Sample Index (0-59)')
    ax4.set_ylabel('Normalized Value')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.set_ylim(-3.5, 3.5)
    
    plt.tight_layout()
    plt.savefig('/Users/mariarye/Desktop/UNI 2025-2026/DS & AI/Project/dsai-project/data_augmentation_visualizations/preprocessing_slide2_solution.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

def create_preprocessing_slide_3():
    """Slide 3: Impact on Model Performance"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # Left: Before/After comparison
    categories = ['Raw Data', 'Preprocessed']
    accuracies = [26.0, 70.7]
    colors = ['lightcoral', 'lightgreen']
    
    bars = ax1.bar(categories, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=2)
    ax1.set_title('Preprocessing Impact on Accuracy', fontsize=16, fontweight='bold')
    ax1.set_ylabel('Accuracy (%)')
    ax1.set_ylim(0, 80)
    
    # Add value labels
    for bar, acc in zip(bars, accuracies):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 2,
                f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=14)
    
    ax1.grid(True, alpha=0.3)
    
    # Right: Key statistics
    ax2.axis('off')
    
    # Create a table-like visualization
    stats_text = """
    ðŸ“Š PREPROCESSING STATISTICS
    
    Before Preprocessing:
    â€¢ X-axis: Î¼=2.3, Ïƒ=8.7, range=[-45, 68]
    â€¢ Y-axis: Î¼=-1.8, Ïƒ=12.4, range=[-52, 49]
    â€¢ Z-axis: Î¼=9.1, Ïƒ=6.2, range=[-23, 42]
    â€¢ Outliers: 2.3% beyond Â±3Ïƒ
    
    After Preprocessing:
    â€¢ All axes: Î¼=0.0, Ïƒ=1.0, range=[-3, 3]
    â€¢ Clipped: 0.3% of values removed
    â€¢ Windows: 98 windows of 60 samples
    â€¢ Model input: (60, 3) shape
    
    ðŸŽ¯ KEY BENEFITS:
    â€¢ Equal contribution from all axes
    â€¢ Robust to extreme values
    â€¢ Consistent input format
    â€¢ Enables batch processing
    """
    
    ax2.text(0.1, 0.9, stats_text, transform=ax2.transAxes, fontsize=12,
             verticalalignment='top', fontfamily='monospace',
             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig('/Users/mariarye/Desktop/UNI 2025-2026/DS & AI/Project/dsai-project/data_augmentation_visualizations/preprocessing_slide3_impact.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

def create_preprocessing_summary():
    """Create a summary slide with key takeaways"""
    
    fig, ax = plt.subplots(1, 1, figsize=(16, 10))
    ax.axis('off')
    
    # Create a comprehensive summary
    summary_text = """
    ðŸ”§ PREPROCESSING & NORMALIZATION: KEY TAKEAWAYS
    
    ðŸ“‹ THE PIPELINE:
    1. StandardScaler: Z-score normalization (Î¼=0, Ïƒ=1)
    2. Outlier Clipping: Values clipped to [-3, 3] standard deviations  
    3. Time Conversion: Timestamp to seconds from start
    4. Windowing: 3-second windows (60 samples each)
    5. Padding/Truncation: Fixed-length windows with zero-padding
    
    ðŸ“Š THE IMPACT:
    â€¢ Accuracy: 26% â†’ 70.7% (+226% improvement)
    â€¢ Data Quality: Removed 2.3% outliers, standardized scales
    â€¢ Model Input: Consistent (60, 3) shape for all windows
    â€¢ Training: 75 windows â†’ 803 augmented samples
    
    ðŸŽ¯ WHY IT MATTERS:
    â€¢ StandardScaler: Ensures all sensor axes contribute equally
    â€¢ Outlier Clipping: Prevents extreme values from dominating
    â€¢ Windowing: Captures complete movement patterns
    â€¢ Padding: Enables batch processing with fixed input size
    
    ðŸ’¡ THE LESSON:
    "Preprocessing is not optional - it's essential for deep learning success.
    Raw sensor data is messy, but proper preprocessing transforms it into
    model-ready input that enables learning."
    
    ðŸš€ RESULT:
    Production-ready concept prediction model with 70.7% accuracy
    """
    
    ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=14,
            verticalalignment='top', fontfamily='sans-serif',
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))
    
    plt.tight_layout()
    plt.savefig('/Users/mariarye/Desktop/UNI 2025-2026/DS & AI/Project/dsai-project/data_augmentation_visualizations/preprocessing_slide4_summary.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

if __name__ == "__main__":
    print("Creating preprocessing presentation slides...")
    
    # Generate all slides
    create_preprocessing_slide_1()  # The Problem
    create_preprocessing_slide_2()  # The Solution
    create_preprocessing_slide_3()  # The Impact
    create_preprocessing_summary()  # Key Takeaways
    
    print("\nâœ… All preprocessing slides created!")
    print("ðŸ“ Files saved to data_augmentation_visualizations/")
    print("   â€¢ preprocessing_slide1_problem.png")
    print("   â€¢ preprocessing_slide2_solution.png") 
    print("   â€¢ preprocessing_slide3_impact.png")
    print("   â€¢ preprocessing_slide4_summary.png")
