{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7ab0ad-7559-4121-8e17-a4def85659af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6734c992-572f-4b01-9974-3077baa41d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6349053d-69a7-4233-8f6a-64f90b1d311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (10726, 200, 3)\n",
      "y shape: (10726,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 200  # number of samples per window (~2â€“4 seconds depending on frequency)\n",
    "step_size = 100    # 50% overlap\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for activity in df['activity'].unique():\n",
    "    df_act = df[df['activity'] == activity]\n",
    "    signals = df_act[['x-axis','y-axis','z-axis']].values\n",
    "    \n",
    "    for start in range(0, len(signals) - window_size, step_size):\n",
    "        end = start + window_size\n",
    "        X.append(signals[start:end])  # shape: (window_size, 3)\n",
    "        y.append(activity)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"X shape:\", X.shape)  # (num_windows, window_size, 3)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0ad6b0-290b-4080-8af4-b97bdb41717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_reshaped = X.reshape(-1, 3)\n",
    "X_scaled = scaler.fit_transform(X_reshaped)\n",
    "X_scaled = X_scaled.reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea1e4da-4431-447e-aae2-b675be01f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "num_classes = y_categorical.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c922aa3-5ffa-4c1a-8f2d-37ccf3c92663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 198, 64)           640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 198, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 196, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 98, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 98, 64)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 96, 128)           24704     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 96, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 48, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 48, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6144)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               786560    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825,798\n",
      "Trainable params: 825,414\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(window_size, 3)),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "823762fb-892c-48a0-96d2-304b4aa161b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "118/118 [==============================] - 7s 49ms/step - loss: 0.6876 - accuracy: 0.7788 - val_loss: 10.4773 - val_accuracy: 0.1085\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.3338 - accuracy: 0.8811 - val_loss: 11.7857 - val_accuracy: 0.2191\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2355 - accuracy: 0.9150 - val_loss: 5.2923 - val_accuracy: 0.4664\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1675 - accuracy: 0.9403 - val_loss: 0.7850 - val_accuracy: 0.8424\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1258 - accuracy: 0.9580 - val_loss: 0.5574 - val_accuracy: 0.8620\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.0858 - accuracy: 0.9691 - val_loss: 0.4112 - val_accuracy: 0.8978\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.0950 - accuracy: 0.9679 - val_loss: 0.3101 - val_accuracy: 0.9096\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.0810 - accuracy: 0.9716 - val_loss: 0.1696 - val_accuracy: 0.9481\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.0671 - accuracy: 0.9780 - val_loss: 0.2221 - val_accuracy: 0.9428\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.2031 - val_accuracy: 0.9431\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0397 - accuracy: 0.9860 - val_loss: 0.2239 - val_accuracy: 0.9487\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 0.0431 - accuracy: 0.9842 - val_loss: 0.1610 - val_accuracy: 0.9559\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.0546 - accuracy: 0.9819 - val_loss: 0.1847 - val_accuracy: 0.9671\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0431 - accuracy: 0.9876 - val_loss: 0.1377 - val_accuracy: 0.9646\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0621 - accuracy: 0.9818 - val_loss: 0.1764 - val_accuracy: 0.9521\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.1104 - val_accuracy: 0.9667\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0362 - accuracy: 0.9897 - val_loss: 0.1442 - val_accuracy: 0.9627\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.0297 - accuracy: 0.9899 - val_loss: 0.1133 - val_accuracy: 0.9727\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.0302 - accuracy: 0.9907 - val_loss: 0.1151 - val_accuracy: 0.9643\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.1230 - val_accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.3, random_state=42, stratify=y_encoded)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a306173-21dd-4cf1-b184-a3ee744b0156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9671\n",
      "Test Accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
