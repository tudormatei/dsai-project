{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cf7069",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <B111F8D5-6AC6-3245-A6B5-94693F6992AB> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     build_info,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/tracker.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:308\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:270\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[1;32m    269\u001b[0m         libname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(lib_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[1;32m    271\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) could not be loaded.\u001b[39m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124mLikely causes:\u001b[39m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124m  * OpenMP runtime is not installed\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[1;32m    279\u001b[0m \n\u001b[1;32m    280\u001b[0m \u001b[38;5;124m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[1;32m    281\u001b[0m \n\u001b[1;32m    282\u001b[0m \u001b[38;5;124mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         )\n\u001b[1;32m    285\u001b[0m     _register_log_callback(lib)\n\u001b[1;32m    287\u001b[0m     libver \u001b[38;5;241m=\u001b[39m _lib_version(lib)\n",
      "\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <B111F8D5-6AC6-3245-A6B5-94693F6992AB> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_windows = pd.read_csv('./data/final_window_labels.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = ['periodicity', 'temporal_stability', 'coordination']\n",
    "continuous_columns = ['motion_intensity', 'vertical_dominance']\n",
    "\n",
    "X_final = df_windows[discrete_columns + continuous_columns].values\n",
    "\n",
    "y_label_str = df_windows['activity'].values\n",
    "activity_mapping = {act: i for i, act in enumerate(np.unique(y_label_str))}\n",
    "y_label = np.array([activity_mapping[act] for act in y_label_str])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y_label, test_size=0.25, random_state=42, stratify=y_label\n",
    ")\n",
    "\n",
    "# Helper function to calculate AUROC for multi-class problems\n",
    "def calculate_auroc(y_true, y_pred_proba, num_classes):\n",
    "    y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
    "    \n",
    "    if y_true_bin.shape[1] == 1:\n",
    "        return roc_auc_score(y_true_bin, y_pred_proba[:, 1])\n",
    "    else:\n",
    "        return roc_auc_score(y_true_bin, y_pred_proba, multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tudor\\miniconda3\\envs\\mod9\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "=== Neural Network ===\n",
      "Accuracy: 0.39473684210526316\n",
      "AUROC: 0.8298131080389145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.33      0.29      0.31         7\n",
      "           2       0.83      0.83      0.83         6\n",
      "           3       0.50      0.83      0.62         6\n",
      "           4       0.38      0.50      0.43         6\n",
      "           5       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.39        38\n",
      "   macro avg       0.34      0.41      0.37        38\n",
      "weighted avg       0.33      0.39      0.35        38\n",
      "\n",
      "[[0 0 0 2 3 1]\n",
      " [0 2 0 1 1 3]\n",
      " [0 0 5 1 0 0]\n",
      " [0 0 1 5 0 0]\n",
      " [0 0 0 1 3 2]\n",
      " [2 4 0 0 1 0]]\n",
      "\n",
      "=== Decision Tree ===\n",
      "Accuracy: 0.5263157894736842\n",
      "AUROC: 0.7165098566308243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.50      0.35         6\n",
      "           1       0.60      0.43      0.50         7\n",
      "           2       0.83      0.83      0.83         6\n",
      "           3       1.00      0.50      0.67         6\n",
      "           4       0.40      0.33      0.36         6\n",
      "           5       0.50      0.57      0.53         7\n",
      "\n",
      "    accuracy                           0.53        38\n",
      "   macro avg       0.60      0.53      0.54        38\n",
      "weighted avg       0.60      0.53      0.54        38\n",
      "\n",
      "[[3 0 0 0 2 1]\n",
      " [2 3 0 0 1 1]\n",
      " [0 1 5 0 0 0]\n",
      " [2 0 1 3 0 0]\n",
      " [2 0 0 0 2 2]\n",
      " [2 1 0 0 0 4]]\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.39473684210526316\n",
      "AUROC: 0.8705837173579108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.25      0.29      0.27         7\n",
      "           2       0.83      0.83      0.83         6\n",
      "           3       0.50      0.83      0.62         6\n",
      "           4       0.38      0.50      0.43         6\n",
      "           5       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.39        38\n",
      "   macro avg       0.33      0.41      0.36        38\n",
      "weighted avg       0.32      0.39      0.35        38\n",
      "\n",
      "[[0 0 0 2 3 1]\n",
      " [0 2 0 1 1 3]\n",
      " [0 0 5 1 0 0]\n",
      " [0 0 1 5 0 0]\n",
      " [0 0 0 1 3 2]\n",
      " [0 6 0 0 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tudor\\miniconda3\\envs\\mod9\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\tudor\\miniconda3\\envs\\mod9\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\tudor\\miniconda3\\envs\\mod9\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "Accuracy: 0.631578947368421\n",
      "AUROC: 0.8504684299795185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.17      0.22         6\n",
      "           1       1.00      0.71      0.83         7\n",
      "           2       0.83      0.83      0.83         6\n",
      "           3       0.75      0.50      0.60         6\n",
      "           4       0.50      0.67      0.57         6\n",
      "           5       0.50      0.86      0.63         7\n",
      "\n",
      "    accuracy                           0.63        38\n",
      "   macro avg       0.65      0.62      0.62        38\n",
      "weighted avg       0.66      0.63      0.62        38\n",
      "\n",
      "[[1 0 0 0 3 2]\n",
      " [0 5 0 0 0 2]\n",
      " [0 0 5 1 0 0]\n",
      " [1 0 1 3 1 0]\n",
      " [0 0 0 0 4 2]\n",
      " [1 0 0 0 0 6]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tudor\\miniconda3\\envs\\mod9\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [13:34:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "Accuracy: 0.5526315789473685\n",
      "AUROC: 0.8475462429595493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33         6\n",
      "           1       1.00      0.71      0.83         7\n",
      "           2       0.71      0.83      0.77         6\n",
      "           3       0.60      0.50      0.55         6\n",
      "           4       0.50      0.50      0.50         6\n",
      "           5       0.33      0.43      0.38         7\n",
      "\n",
      "    accuracy                           0.55        38\n",
      "   macro avg       0.58      0.55      0.56        38\n",
      "weighted avg       0.58      0.55      0.56        38\n",
      "\n",
      "[[2 0 0 0 2 2]\n",
      " [0 5 0 0 0 2]\n",
      " [0 0 5 1 0 0]\n",
      " [2 0 1 3 0 0]\n",
      " [0 0 1 0 3 2]\n",
      " [2 0 0 1 1 3]]\n",
      "\n",
      "=== SVM (RBF) ===\n",
      "Accuracy: 0.5526315789473685\n",
      "AUROC: 0.8648393497183818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.80      0.57      0.67         7\n",
      "           2       0.83      0.83      0.83         6\n",
      "           3       0.50      0.83      0.62         6\n",
      "           4       0.33      0.50      0.40         6\n",
      "           5       0.50      0.57      0.53         7\n",
      "\n",
      "    accuracy                           0.55        38\n",
      "   macro avg       0.49      0.55      0.51        38\n",
      "weighted avg       0.50      0.55      0.51        38\n",
      "\n",
      "[[0 0 0 2 3 1]\n",
      " [0 4 0 1 1 1]\n",
      " [0 0 5 1 0 0]\n",
      " [0 0 1 5 0 0]\n",
      " [0 0 0 1 3 2]\n",
      " [0 1 0 0 2 4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tudor\\miniconda3\\envs\\mod9\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\tudor\\miniconda3\\envs\\mod9\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\tudor\\miniconda3\\envs\\mod9\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# ---------- Neural Network ----------\n",
    "num_classes = len(activity_mapping)\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_final.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    validation_data=(X_test, y_test_cat),\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred_nn = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(\"=== Neural Network ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nn))\n",
    "print(\"AUROC:\", calculate_auroc(y_test, y_pred_probs, num_classes))\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "print(confusion_matrix(y_test, y_pred_nn))\n",
    "print()\n",
    "\n",
    "# ---------- Decision Tree ----------\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_proba_dt = dt.predict_proba(X_test)\n",
    "\n",
    "print(\"=== Decision Tree ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"AUROC:\", calculate_auroc(y_test, y_pred_proba_dt, num_classes))\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print()\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_proba_lr = lr.predict_proba(X_test)\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"AUROC:\", calculate_auroc(y_test, y_pred_proba_lr, num_classes))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# ---------- Random Forest ----------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_proba_rf = rf.predict_proba(X_test)\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"AUROC:\", calculate_auroc(y_test, y_pred_proba_rf, num_classes))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print()\n",
    "\n",
    "# ---------- XGBoost ----------\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_pred_proba_xgb = xgb.predict_proba(X_test)\n",
    "\n",
    "print(\"=== XGBoost ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"AUROC:\", calculate_auroc(y_test, y_pred_proba_xgb, num_classes))\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print()\n",
    "\n",
    "# ---------- SVM (RBF Kernel) ----------\n",
    "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_proba_svm = svm.predict_proba(X_test)\n",
    "\n",
    "print(\"=== SVM (RBF) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"AUROC:\", calculate_auroc(y_test, y_pred_proba_svm, num_classes))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b6412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and mapping saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lr, \"./models/lr_concept_to_activity.pkl\")\n",
    "joblib.dump(activity_mapping, \"./models/activity_mapping.pkl\")\n",
    "\n",
    "print(\"Model and mapping saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
