{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7b3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edcfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"./data/merged_dataset_with_concepts.csv\")\n",
    "window_df = pd.read_csv(\"./data/merged_window_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5ccc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8802, 10)\n",
      "(150, 8)\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.shape)\n",
    "print(window_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e492226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data columns to save: ['user', 'activity', 'timestamp', 'x-axis', 'y-axis', 'z-axis', 'time_s', 'periodicity', 'temporal_stability', 'coordination', 'movement_variability', 'movement_consistency']\n",
      "Window data columns to save: ['window_idx', 'user', 'activity', 'start_time', 'end_time', 'periodicity', 'temporal_stability', 'coordination', 'movement_variability', 'movement_consistency', 'movement_variability', 'movement_consistency']\n"
     ]
    }
   ],
   "source": [
    "# these are what rule based concepts we're calculating\n",
    "raw_data_concepts = [\"movement_variability\", \"movement_consistency\"]\n",
    "window_data_concepts = [\"movement_variability\", \"movement_consistency\"]\n",
    "\n",
    "# which of these concepts to actually exclude from the export csvs (so what concepts we actually dont want used for training)\n",
    "rules_to_exclude_from_saving = [\"static_posture\"]\n",
    "\n",
    "raw_df_cols_to_save = [col for col in (list(raw_df.columns) + raw_data_concepts)  if col not in rules_to_exclude_from_saving]\n",
    "window_df_cols_to_save = [col for col in (list(window_df.columns) + raw_data_concepts + window_data_concepts) if col not in rules_to_exclude_from_saving]\n",
    "print(\"Raw data columns to save:\", raw_df_cols_to_save)\n",
    "print(\"Window data columns to save:\", window_df_cols_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "366efea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating movement variability for raw data...\n",
      "Calculating movement consistency for raw data...\n",
      "New rule-based concepts computed for raw data!\n",
      "\n",
      "Calculating movement variability for window data...\n",
      "Calculating movement consistency for window data...\n",
      "New rule-based concepts computed for window data!\n",
      "\n",
      "=== NORMALIZATION VERIFICATION ===\n",
      "Raw data - Movement variability range: 0.0000 to 1.0000\n",
      "Raw data - Movement consistency range: 0.0000 to 1.0000\n",
      "Raw data - Static posture range: 0.0000 to 1.0000\n",
      "\n",
      "Window data - Movement variability range: 0.0000 to 1.0000\n",
      "Window data - Movement consistency range: 0.0000 to 1.0000\n",
      "Contextual Features Configuration:\n",
      "  periodicity: Independent\n",
      "  temporal_stability: Independent\n",
      "  coordination: Independent\n",
      "  movement_variability: Independent\n",
      "  movement_consistency: Independent\n"
     ]
    }
   ],
   "source": [
    "# Calculate concepts for both raw data and window data\n",
    "\n",
    "def calculate_raw_data_movement_variability(df, window_size=50):\n",
    "    \"\"\"Calculate movement variability for each row using a sliding window\"\"\"\n",
    "    variability_scores = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        start_idx = max(0, i - window_size // 2)\n",
    "        end_idx = min(len(df), i + window_size // 2)\n",
    "        \n",
    "        window_data = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        if len(window_data) < 5:\n",
    "            variability_scores.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        variability = magnitude.std()\n",
    "        variability_scores.append(variability)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    variability_scores = np.array(variability_scores)\n",
    "    if variability_scores.max() > variability_scores.min():\n",
    "        normalized = (variability_scores - variability_scores.min()) / (variability_scores.max() - variability_scores.min())\n",
    "    else:\n",
    "        normalized = np.zeros_like(variability_scores)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def calculate_raw_data_movement_consistency(df, window_size=50):\n",
    "    \"\"\"Calculate movement consistency for each row using a sliding window\"\"\"\n",
    "    consistency_scores = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        start_idx = max(0, i - window_size // 2)\n",
    "        end_idx = min(len(df), i + window_size // 2)\n",
    "        \n",
    "        window_data = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        if len(window_data) < 10:\n",
    "            consistency_scores.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        if len(magnitude) >= 2:\n",
    "            correlation = np.corrcoef(magnitude[:-1], magnitude[1:])[0, 1]\n",
    "            if np.isnan(correlation):\n",
    "                consistency_scores.append(0.0)\n",
    "            else:\n",
    "                consistency_scores.append(correlation)\n",
    "        else:\n",
    "            consistency_scores.append(0.0)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    consistency_scores = np.array(consistency_scores)\n",
    "    if consistency_scores.max() > consistency_scores.min():\n",
    "        normalized = (consistency_scores - consistency_scores.min()) / (consistency_scores.max() - consistency_scores.min())\n",
    "    else:\n",
    "        normalized = np.zeros_like(consistency_scores)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def calculate_movement_variability(df_sensor, df_windows):\n",
    "    \"\"\"Calculate movement variability as normalized standard deviation of magnitude for each window\"\"\"\n",
    "    variability_scores = []\n",
    "    \n",
    "    # First pass: collect all variability values to calculate global min/max for normalization\n",
    "    temp_variability = []\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 5:  \n",
    "            continue\n",
    "            \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        variability = magnitude.std()\n",
    "        temp_variability.append(variability)\n",
    "    \n",
    "    # Calculate normalization parameters\n",
    "    if len(temp_variability) > 0:\n",
    "        min_var = min(temp_variability)\n",
    "        max_var = max(temp_variability)\n",
    "        var_range = max_var - min_var\n",
    "    else:\n",
    "        min_var = 0\n",
    "        var_range = 1\n",
    "    \n",
    "    # Second pass: calculate normalized variability\n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            variability_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 5:  \n",
    "            variability_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        variability = magnitude.std()\n",
    "        \n",
    "        # Normalize to [0, 1] range\n",
    "        if var_range > 0:\n",
    "            normalized_variability = (variability - min_var) / var_range\n",
    "        else:\n",
    "            normalized_variability = 0.0\n",
    "            \n",
    "        variability_scores.append(normalized_variability)\n",
    "    \n",
    "    return np.array(variability_scores)\n",
    "\n",
    "def calculate_movement_consistency(df_sensor, df_windows):\n",
    "    \"\"\"Calculate movement consistency as normalized temporal correlation for each window\"\"\"\n",
    "    consistency_scores = []\n",
    "    \n",
    "    # First pass: collect all correlation values to calculate global min/max for normalization\n",
    "    temp_consistency = []\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 10:  \n",
    "            continue\n",
    "            \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        if len(magnitude) >= 2:\n",
    "            correlation = np.corrcoef(magnitude[:-1], magnitude[1:])[0, 1]\n",
    "            if not np.isnan(correlation):\n",
    "                temp_consistency.append(correlation)\n",
    "    \n",
    "    # Calculate normalization parameters\n",
    "    if len(temp_consistency) > 0:\n",
    "        min_consistency = min(temp_consistency)\n",
    "        max_consistency = max(temp_consistency)\n",
    "        consistency_range = max_consistency - min_consistency\n",
    "    else:\n",
    "        min_consistency = 0\n",
    "        consistency_range = 1\n",
    "    \n",
    "    # Second pass: calculate normalized consistency\n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            consistency_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 10:  \n",
    "            consistency_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        if len(magnitude) >= 2:\n",
    "            correlation = np.corrcoef(magnitude[:-1], magnitude[1:])[0, 1]\n",
    "            if np.isnan(correlation):\n",
    "                consistency_scores.append(0.0)\n",
    "            else:\n",
    "                # Normalize to [0, 1] range\n",
    "                if consistency_range > 0:\n",
    "                    normalized_consistency = (correlation - min_consistency) / consistency_range\n",
    "                else:\n",
    "                    normalized_consistency = 0.0\n",
    "                consistency_scores.append(normalized_consistency)\n",
    "        else:\n",
    "            consistency_scores.append(0.0)\n",
    "    \n",
    "    return np.array(consistency_scores)\n",
    "\n",
    "def detect_static_posture(df, window_size=10):\n",
    "    \"\"\"\n",
    "    Detect static posture based on signal variance, not motion intensity.\n",
    "    This removes the circular dependency.\n",
    "    \"\"\"\n",
    "    static_posture = np.zeros(len(df))\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        start_idx = max(0, i - window_size // 2)\n",
    "        end_idx = min(len(df), i + window_size // 2)\n",
    "        \n",
    "        # Get window of sensor data\n",
    "        window_data = df.iloc[start_idx:end_idx][['x-axis', 'y-axis', 'z-axis']].values\n",
    "        \n",
    "        # Calculate signal variance (not magnitude-based)\n",
    "        signal_variance = np.var(window_data, axis=0).mean()\n",
    "        \n",
    "        # Static if variance is very low (indicating minimal movement)\n",
    "        static_posture[i] = 1.0 if signal_variance < 0.5 else 0.0\n",
    "    \n",
    "    return static_posture\n",
    "\n",
    "# Apply static posture detection based on variance\n",
    "raw_df[\"static_posture\"] = detect_static_posture(raw_df)\n",
    "\n",
    "# Calculate new rule-based concepts for RAW data (using sliding windows)\n",
    "print(\"Calculating movement variability for raw data...\")\n",
    "raw_df['movement_variability'] = calculate_raw_data_movement_variability(raw_df)\n",
    "\n",
    "print(\"Calculating movement consistency for raw data...\")\n",
    "raw_df['movement_consistency'] = calculate_raw_data_movement_consistency(raw_df)\n",
    "\n",
    "print(\"New rule-based concepts computed for raw data!\")\n",
    "\n",
    "# Calculate new rule-based concepts for window data (using fixed windows)\n",
    "print(\"\\nCalculating movement variability for window data...\")\n",
    "window_df['movement_variability'] = calculate_movement_variability(raw_df, window_df)\n",
    "\n",
    "print(\"Calculating movement consistency for window data...\")\n",
    "window_df['movement_consistency'] = calculate_movement_consistency(raw_df, window_df)\n",
    "\n",
    "print(\"New rule-based concepts computed for window data!\")\n",
    "\n",
    "# Verify normalization ranges\n",
    "print(f\"\\n=== NORMALIZATION VERIFICATION ===\")\n",
    "print(f\"Raw data - Movement variability range: {raw_df['movement_variability'].min():.4f} to {raw_df['movement_variability'].max():.4f}\")\n",
    "print(f\"Raw data - Movement consistency range: {raw_df['movement_consistency'].min():.4f} to {raw_df['movement_consistency'].max():.4f}\")\n",
    "print(f\"Raw data - Static posture range: {raw_df['static_posture'].min():.4f} to {raw_df['static_posture'].max():.4f}\")\n",
    "print(f\"\\nWindow data - Movement variability range: {window_df['movement_variability'].min():.4f} to {window_df['movement_variability'].max():.4f}\")\n",
    "print(f\"Window data - Movement consistency range: {window_df['movement_consistency'].min():.4f} to {window_df['movement_consistency'].max():.4f}\")\n",
    "\n",
    "# Define contextual relationships - which features should use static posture contextually\n",
    "def get_contextual_features_config():\n",
    "    \"\"\"\n",
    "    Define which features should use static posture contextually.\n",
    "    This configuration determines how static posture influences other motion concepts.\n",
    "    \"\"\"\n",
    "    contextual_config = {\n",
    "        'periodicity': False,       # Independent - periodic patterns don't depend on static posture\n",
    "        'temporal_stability': False, # Independent - temporal stability is about consistency, not static periods\n",
    "        'coordination': False,      # Independent - coordination is about limb synchronization, not static posture\n",
    "        'movement_variability': False, # Independent - movement variability is about motion patterns, not static posture\n",
    "        'movement_consistency': False, # Independent - movement consistency is about temporal patterns, not static posture\n",
    "    }\n",
    "    return contextual_config\n",
    "\n",
    "# Get the contextual configuration\n",
    "contextual_config = get_contextual_features_config()\n",
    "print(\"Contextual Features Configuration:\")\n",
    "for feature, uses_context in contextual_config.items():\n",
    "    print(f\"  {feature}: {'Uses static posture context' if uses_context else 'Independent'}\")\n",
    "\n",
    "def compute_window_features(df, start, end):\n",
    "    segment = df[(df[\"time_s\"] >= start) & (df[\"time_s\"] <= end)]\n",
    "    if len(segment) == 0:\n",
    "        return pd.Series({\n",
    "            \"static_posture\": np.nan\n",
    "        })\n",
    "    \n",
    "    # FIXED: Static posture based on signal variance, not motion intensity\n",
    "    signal_variance = np.var(segment[['x-axis', 'y-axis', 'z-axis']].values, axis=0).mean()\n",
    "    static_posture = 1.0 if signal_variance < 0.5 else 0.0\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"static_posture\": static_posture\n",
    "    })\n",
    "\n",
    "window_features = window_df.apply(lambda row: compute_window_features(raw_df, row[\"start_time\"], row[\"end_time\"]), axis=1)\n",
    "window_df = pd.concat([window_df, window_features], axis=1)\n",
    "\n",
    "raw_df.to_csv(\"./data/final_dataset.csv\", columns=raw_df_cols_to_save, index=False)\n",
    "window_df.to_csv(\"./data/final_window_labels.csv\", columns=window_df_cols_to_save, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17af35c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ALL CONCEPTS OVERVIEW ===\n",
      "Original human-labeled concepts: ['periodicity', 'temporal_stability', 'coordination']\n",
      "New rule-based concepts (raw data): ['movement_variability', 'movement_consistency']\n",
      "New rule-based concepts (window data): ['movement_variability', 'movement_consistency']\n",
      "\n",
      "=== RAW DATA STATISTICS ===\n",
      "Original concepts:\n",
      "       periodicity  temporal_stability  coordination\n",
      "count  8802.000000         8802.000000   8802.000000\n",
      "mean      0.288798            0.638491      0.684674\n",
      "std       0.382089            0.292539      0.327604\n",
      "min       0.000000            0.000000      0.000000\n",
      "25%       0.000000            0.500000      0.500000\n",
      "50%       0.000000            0.500000      0.500000\n",
      "75%       0.500000            1.000000      1.000000\n",
      "max       1.000000            1.000000      1.000000\n",
      "\n",
      "New rule-based concepts (raw data):\n",
      "       movement_variability  movement_consistency\n",
      "count           8802.000000           8802.000000\n",
      "mean               0.403026              0.668021\n",
      "std                0.287398              0.123407\n",
      "min                0.000000              0.000000\n",
      "25%                0.016247              0.610372\n",
      "50%                0.497894              0.691889\n",
      "75%                0.604725              0.749124\n",
      "max                1.000000              1.000000\n",
      "\n",
      "=== WINDOW DATA STATISTICS ===\n",
      "Original concepts:\n",
      "       periodicity  temporal_stability  coordination\n",
      "count   150.000000          150.000000    150.000000\n",
      "mean      0.283333            0.630000      0.680000\n",
      "std       0.381698            0.297811      0.334182\n",
      "min       0.000000            0.000000      0.000000\n",
      "25%       0.000000            0.500000      0.500000\n",
      "50%       0.000000            0.500000      0.500000\n",
      "75%       0.500000            1.000000      1.000000\n",
      "max       1.000000            1.000000      1.000000\n",
      "\n",
      "New rule-based concepts:\n",
      "       movement_variability  movement_consistency  movement_variability  \\\n",
      "count            150.000000            150.000000            150.000000   \n",
      "mean               0.402851              0.687160              0.402851   \n",
      "std                0.306913              0.208730              0.306913   \n",
      "min                0.000000              0.000000              0.000000   \n",
      "25%                0.010566              0.579992              0.010566   \n",
      "50%                0.513740              0.752383              0.513740   \n",
      "75%                0.610973              0.838029              0.610973   \n",
      "max                1.000000              1.000000              1.000000   \n",
      "\n",
      "       movement_consistency  \n",
      "count            150.000000  \n",
      "mean               0.687160  \n",
      "std                0.208730  \n",
      "min                0.000000  \n",
      "25%                0.579992  \n",
      "50%                0.752383  \n",
      "75%                0.838029  \n",
      "max                1.000000  \n",
      "\n",
      "=== DATA SHAPES ===\n",
      "Raw data: (8802, 13)\n",
      "Window data: (150, 11)\n"
     ]
    }
   ],
   "source": [
    "# Get all concept columns from the original data\n",
    "original_concepts = ['periodicity', 'temporal_stability', 'coordination']\n",
    "\n",
    "print(\"=== ALL CONCEPTS OVERVIEW ===\")\n",
    "print(f\"Original human-labeled concepts: {original_concepts}\")\n",
    "print(f\"New rule-based concepts (raw data): {raw_data_concepts}\")\n",
    "print(f\"New rule-based concepts (window data): {window_data_concepts}\")\n",
    "\n",
    "print(f\"\\n=== RAW DATA STATISTICS ===\")\n",
    "print(\"Original concepts:\")\n",
    "print(raw_df[original_concepts].describe())\n",
    "print(\"\\nNew rule-based concepts (raw data):\")\n",
    "print(raw_df[raw_data_concepts].describe())\n",
    "\n",
    "print(f\"\\n=== WINDOW DATA STATISTICS ===\")\n",
    "print(\"Original concepts:\")\n",
    "print(window_df[original_concepts].describe())\n",
    "print(\"\\nNew rule-based concepts:\")\n",
    "print(window_df[raw_data_concepts + window_data_concepts].describe())\n",
    "\n",
    "print(f\"\\n=== DATA SHAPES ===\")\n",
    "print(f\"Raw data: {raw_df.shape}\")\n",
    "print(f\"Window data: {window_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eeb55f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW DATA SAMPLE ===\n",
      "Original concepts:\n",
      "   periodicity  temporal_stability  coordination\n",
      "0          1.0                 0.5           0.5\n",
      "1          1.0                 0.5           0.5\n",
      "2          1.0                 0.5           0.5\n",
      "3          1.0                 0.5           0.5\n",
      "4          1.0                 0.5           0.5\n",
      "\n",
      "New rule-based concepts (raw data):\n",
      "   movement_variability  movement_consistency\n",
      "0              0.733765              0.550603\n",
      "1              0.719276              0.549582\n",
      "2              0.718162              0.545124\n",
      "3              0.705651              0.550513\n",
      "4              0.694645              0.548606\n",
      "\n",
      "=== WINDOW DATA SAMPLE ===\n",
      "Original concepts:\n",
      "   periodicity  temporal_stability  coordination\n",
      "0          1.0                 0.5           0.5\n",
      "1          1.0                 0.5           0.5\n",
      "2          0.5                 0.5           0.5\n",
      "3          1.0                 0.5           0.5\n",
      "4          1.0                 0.5           0.5\n",
      "\n",
      "New rule-based concepts:\n",
      "   movement_variability  movement_consistency  movement_variability  \\\n",
      "0              0.700410              0.627730              0.700410   \n",
      "1              0.565783              0.626847              0.565783   \n",
      "2              0.628687              0.661077              0.628687   \n",
      "3              0.550219              0.699294              0.550219   \n",
      "4              0.731759              0.832724              0.731759   \n",
      "\n",
      "   movement_consistency  \n",
      "0              0.627730  \n",
      "1              0.626847  \n",
      "2              0.661077  \n",
      "3              0.699294  \n",
      "4              0.832724  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== RAW DATA SAMPLE ===\")\n",
    "print(\"Original concepts:\")\n",
    "print(raw_df[original_concepts].head())\n",
    "print(\"\\nNew rule-based concepts (raw data):\")\n",
    "print(raw_df[raw_data_concepts].head())\n",
    "\n",
    "print(\"\\n=== WINDOW DATA SAMPLE ===\")\n",
    "print(\"Original concepts:\")\n",
    "print(window_df[original_concepts].head())\n",
    "print(\"\\nNew rule-based concepts:\")\n",
    "print(window_df[raw_data_concepts + window_data_concepts].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
