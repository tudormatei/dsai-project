{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8955f78e",
   "metadata": {},
   "source": [
    "# IMPROVEMENT SUGGESTIONS FOR MOTION INTENSITY R¬≤\n",
    "\n",
    "print(\"=== MOTION INTENSITY ANALYSIS ===\")\n",
    "print(\"Current R¬≤: 0.2916 (29.16% variance explained)\")\n",
    "print(\"\\n=== IDENTIFIED PROBLEMS ===\")\n",
    "print(\"1. DATA ISSUES:\")\n",
    "print(\"   - Very narrow range: 0.277 to 0.471 (only 19.4% range)\")\n",
    "print(\"   - Low variance: Std = 0.041 (12.4% coefficient of variation)\")\n",
    "print(\"   - Small dataset: Only 150 windows\")\n",
    "print(\"   - Limited variability makes learning difficult\")\n",
    "\n",
    "print(\"\\n2. MODEL ISSUES:\")\n",
    "print(\"   - Shared feature extraction with classification tasks\")\n",
    "print(\"   - Simple single-layer output for regression\")\n",
    "print(\"   - No specialized regression architecture\")\n",
    "\n",
    "print(\"\\n=== IMPROVEMENT SUGGESTIONS ===\")\n",
    "\n",
    "print(\"\\nüéØ 1. DATA IMPROVEMENTS:\")\n",
    "print(\"   - Collect more diverse data (different activities, intensities)\")\n",
    "print(\"   - Increase data range (more extreme intensity values)\")\n",
    "print(\"   - Use data augmentation specifically for motion intensity\")\n",
    "print(\"   - Consider longer time windows for better intensity estimation\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 2. MODEL ARCHITECTURE IMPROVEMENTS:\")\n",
    "print(\"   - Separate regression branch for continuous concepts\")\n",
    "print(\"   - Add more layers for motion intensity prediction\")\n",
    "print(\"   - Use different activation functions (ReLU, sigmoid)\")\n",
    "print(\"   - Add regularization (dropout, L1/L2)\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è 3. TRAINING IMPROVEMENTS:\")\n",
    "print(\"   - Increase loss weight for motion intensity (currently 5x)\")\n",
    "print(\"   - Use different optimizers (RMSprop, SGD)\")\n",
    "print(\"   - Implement learning rate scheduling\")\n",
    "print(\"   - Add early stopping based on motion intensity validation loss\")\n",
    "\n",
    "print(\"\\nüìä 4. FEATURE ENGINEERING:\")\n",
    "print(\"   - Extract motion-specific features (acceleration magnitude, velocity)\")\n",
    "print(\"   - Add frequency domain features (FFT, power spectral density)\")\n",
    "print(\"   - Include statistical features (variance, skewness, kurtosis)\")\n",
    "print(\"   - Add temporal features (trends, patterns)\")\n",
    "\n",
    "print(\"\\nüîß 5. ALTERNATIVE APPROACHES:\")\n",
    "print(\"   - Train separate model for motion intensity only\")\n",
    "print(\"   - Use ensemble methods (multiple models)\")\n",
    "print(\"   - Try different architectures (LSTM, Transformer)\")\n",
    "print(\"   - Implement multi-scale feature extraction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d585723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED MODEL ARCHITECTURE FOR MOTION INTENSITY\n",
    "\n",
    "def build_improved_motion_intensity_model(input_shape, n_classes_p, n_classes_t, n_classes_c, pretrained_encoder):\n",
    "    \"\"\"\n",
    "    Improved model with specialized regression branch for motion intensity\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    sensor_input = tf.keras.layers.Input(shape=input_shape, name='sensor_input')\n",
    "    \n",
    "    # Use pre-trained encoder as feature extractor\n",
    "    pretrained_features = pretrained_encoder.tf_encoder(sensor_input)\n",
    "    \n",
    "    # Shared feature processing\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='shared_dense1')(pretrained_features)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='shared_dropout1')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu', name='shared_dense2')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='shared_dropout2')(x)\n",
    "    \n",
    "    # Classification outputs (discrete concepts)\n",
    "    periodicity = tf.keras.layers.Dense(n_classes_p, activation='softmax', name='periodicity')(x)\n",
    "    temporal_stability = tf.keras.layers.Dense(n_classes_t, activation='softmax', name='temporal_stability')(x)\n",
    "    coordination = tf.keras.layers.Dense(n_classes_c, activation='softmax', name='coordination')(x)\n",
    "    \n",
    "    # IMPROVED: Separate regression branch for motion intensity\n",
    "    mi_branch = tf.keras.layers.Dense(16, activation='relu', name='mi_dense1')(x)\n",
    "    mi_branch = tf.keras.layers.Dropout(0.2, name='mi_dropout1')(mi_branch)\n",
    "    mi_branch = tf.keras.layers.Dense(8, activation='relu', name='mi_dense2')(mi_branch)\n",
    "    mi_branch = tf.keras.layers.Dropout(0.2, name='mi_dropout2')(mi_branch)\n",
    "    motion_intensity = tf.keras.layers.Dense(1, activation='sigmoid', name='motion_intensity')(mi_branch)\n",
    "    \n",
    "    # IMPROVED: Separate regression branch for vertical dominance\n",
    "    vd_branch = tf.keras.layers.Dense(16, activation='relu', name='vd_dense1')(x)\n",
    "    vd_branch = tf.keras.layers.Dropout(0.2, name='vd_dropout1')(vd_branch)\n",
    "    vd_branch = tf.keras.layers.Dense(8, activation='relu', name='vd_dense2')(vd_branch)\n",
    "    vd_branch = tf.keras.layers.Dropout(0.2, name='vd_dropout2')(vd_branch)\n",
    "    vertical_dominance = tf.keras.layers.Dense(1, activation='sigmoid', name='vertical_dominance')(vd_branch)\n",
    "    \n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=sensor_input, \n",
    "        outputs=[periodicity, temporal_stability, coordination, motion_intensity, vertical_dominance]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Improved motion intensity model architecture defined!\")\n",
    "print(\"Key improvements:\")\n",
    "print(\"- Separate regression branches for continuous concepts\")\n",
    "print(\"- More layers for motion intensity prediction\")\n",
    "print(\"- Sigmoid activation to constrain outputs to [0,1]\")\n",
    "print(\"- Additional dropout for regularization\")\n",
    "print(\"- Specialized feature processing for regression tasks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7053043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED TRAINING SETUP FOR MOTION INTENSITY\n",
    "\n",
    "def create_improved_training_setup():\n",
    "    \"\"\"\n",
    "    Improved training configuration for better motion intensity prediction\n",
    "    \"\"\"\n",
    "    print(\"=== IMPROVED TRAINING SETUP ===\")\n",
    "    \n",
    "    # 1. IMPROVED LOSS WEIGHTS\n",
    "    loss_weights = {\n",
    "        'periodicity': 1.0,\n",
    "        'temporal_stability': 1.0,\n",
    "        'coordination': 1.0,\n",
    "        'motion_intensity': 10.0,      # INCREASED from 5.0 to 10.0\n",
    "        'vertical_dominance': 10.0     # INCREASED from 5.0 to 10.0\n",
    "    }\n",
    "    \n",
    "    # 2. IMPROVED LOSS FUNCTIONS\n",
    "    loss_functions = {\n",
    "        'periodicity': 'categorical_crossentropy',\n",
    "        'temporal_stability': 'categorical_crossentropy',\n",
    "        'coordination': 'categorical_crossentropy',\n",
    "        'motion_intensity': 'huber',    # CHANGED from 'mse' to 'huber' (more robust)\n",
    "        'vertical_dominance': 'huber'   # CHANGED from 'mse' to 'huber' (more robust)\n",
    "    }\n",
    "    \n",
    "    # 3. IMPROVED METRICS\n",
    "    metrics = {\n",
    "        'periodicity': ['accuracy'],\n",
    "        'temporal_stability': ['accuracy'],\n",
    "        'coordination': ['accuracy'],\n",
    "        'motion_intensity': ['mae', 'mse'],  # ADDED mse for monitoring\n",
    "        'vertical_dominance': ['mae', 'mse'] # ADDED mse for monitoring\n",
    "    }\n",
    "    \n",
    "    # 4. IMPROVED OPTIMIZER\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.0005,  # REDUCED from 0.001 for more stable training\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07\n",
    "    )\n",
    "    \n",
    "    # 5. IMPROVED CALLBACKS\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_motion_intensity_loss',  # Focus on motion intensity\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_motion_intensity_loss',  # Focus on motion intensity\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_motion_intensity_model.keras',\n",
    "            monitor='val_motion_intensity_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"‚úÖ Improved training setup configured!\")\n",
    "    print(f\"Loss weights: {loss_weights}\")\n",
    "    print(f\"Loss functions: {loss_functions}\")\n",
    "    print(f\"Optimizer learning rate: {optimizer.learning_rate}\")\n",
    "    print(f\"Callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\")\n",
    "    \n",
    "    return {\n",
    "        'loss_weights': loss_weights,\n",
    "        'loss_functions': loss_functions,\n",
    "        'metrics': metrics,\n",
    "        'optimizer': optimizer,\n",
    "        'callbacks': callbacks\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Improved training setup function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4cc05",
   "metadata": {},
   "source": [
    "# VERTICAL DOMINANCE ANALYSIS & IMPROVEMENTS\n",
    "\n",
    "print(\"=== VERTICAL DOMINANCE ANALYSIS ===\")\n",
    "print(\"Current R¬≤: 0.0810 (8.10% variance explained)\")\n",
    "print(\"\\n=== DATA CHARACTERISTICS ===\")\n",
    "print(\"Mean: 0.248, Std: 0.081\")\n",
    "print(\"Min: 0.041, Max: 0.562\")\n",
    "print(\"Range: 0.521 (52.1%) - GOOD range!\")\n",
    "print(\"Coefficient of Variation: 32.7% - HIGHER variability than motion intensity\")\n",
    "print(\"\\n=== WHY VERTICAL DOMINANCE IS STILL POOR ===\")\n",
    "print(\"1. COMPLEX PATTERN: Vertical dominance requires understanding of 3D orientation\")\n",
    "print(\"2. CONTEXT DEPENDENCY: Uses static posture context (more complex)\")\n",
    "print(\"3. FEATURE EXTRACTION: Current model may not capture vertical vs horizontal patterns\")\n",
    "print(\"4. ARCHITECTURE: Single layer may be insufficient for complex spatial relationships\")\n",
    "\n",
    "print(\"\\n=== VERTICAL DOMINANCE SPECIFIC IMPROVEMENTS ===\")\n",
    "\n",
    "print(\"\\nüéØ 1. ENHANCED FEATURE EXTRACTION:\")\n",
    "print(\"   - Add spatial orientation features (pitch, roll, yaw)\")\n",
    "print(\"   - Include gravity vector analysis\")\n",
    "print(\"   - Add frequency domain analysis for vertical patterns\")\n",
    "print(\"   - Include statistical moments (skewness, kurtosis)\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 2. SPECIALIZED ARCHITECTURE:\")\n",
    "print(\"   - Multi-scale feature extraction for spatial patterns\")\n",
    "print(\"   - Attention mechanism for vertical vs horizontal components\")\n",
    "print(\"   - Separate processing for different sensor axes\")\n",
    "print(\"   - Deeper regression branch for complex spatial relationships\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è 3. ENHANCED TRAINING:\")\n",
    "print(\"   - Even higher loss weight for vertical dominance\")\n",
    "print(\"   - Focal loss for handling imbalanced spatial patterns\")\n",
    "print(\"   - Data augmentation for spatial orientation\")\n",
    "print(\"   - Multi-task learning with spatial awareness\")\n",
    "\n",
    "print(\"\\nüìä 4. FEATURE ENGINEERING:\")\n",
    "print(\"   - Extract vertical component magnitude\")\n",
    "print(\"   - Calculate vertical/horizontal ratio\")\n",
    "print(\"   - Include gravitational acceleration analysis\")\n",
    "print(\"   - Add temporal patterns for vertical movement\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c57bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED VERTICAL DOMINANCE MODEL ARCHITECTURE\n",
    "\n",
    "def build_enhanced_vertical_dominance_model(input_shape, n_classes_p, n_classes_t, n_classes_c, pretrained_encoder):\n",
    "    \"\"\"\n",
    "    Enhanced model with specialized architecture for vertical dominance prediction\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    sensor_input = tf.keras.layers.Input(shape=input_shape, name='sensor_input')\n",
    "    \n",
    "    # Use pre-trained encoder as feature extractor\n",
    "    pretrained_features = pretrained_encoder.tf_encoder(sensor_input)\n",
    "    \n",
    "    # Shared feature processing\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='shared_dense1')(pretrained_features)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='shared_dropout1')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu', name='shared_dense2')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='shared_dropout2')(x)\n",
    "    \n",
    "    # Classification outputs (discrete concepts)\n",
    "    periodicity = tf.keras.layers.Dense(n_classes_p, activation='softmax', name='periodicity')(x)\n",
    "    temporal_stability = tf.keras.layers.Dense(n_classes_t, activation='softmax', name='temporal_stability')(x)\n",
    "    coordination = tf.keras.layers.Dense(n_classes_c, activation='softmax', name='coordination')(x)\n",
    "    \n",
    "    # ENHANCED: Specialized motion intensity branch (keeping previous improvements)\n",
    "    mi_branch = tf.keras.layers.Dense(16, activation='relu', name='mi_dense1')(x)\n",
    "    mi_branch = tf.keras.layers.Dropout(0.2, name='mi_dropout1')(mi_branch)\n",
    "    mi_branch = tf.keras.layers.Dense(8, activation='relu', name='mi_dense2')(mi_branch)\n",
    "    mi_branch = tf.keras.layers.Dropout(0.2, name='mi_dropout2')(mi_branch)\n",
    "    motion_intensity = tf.keras.layers.Dense(1, activation='sigmoid', name='motion_intensity')(mi_branch)\n",
    "    \n",
    "    # ENHANCED: Specialized vertical dominance branch with spatial awareness\n",
    "    vd_branch = tf.keras.layers.Dense(32, activation='relu', name='vd_dense1')(x)\n",
    "    vd_branch = tf.keras.layers.Dropout(0.3, name='vd_dropout1')(vd_branch)\n",
    "    \n",
    "    # Add spatial orientation processing\n",
    "    vd_spatial = tf.keras.layers.Dense(16, activation='relu', name='vd_spatial1')(vd_branch)\n",
    "    vd_spatial = tf.keras.layers.Dropout(0.2, name='vd_spatial_dropout1')(vd_spatial)\n",
    "    vd_spatial = tf.keras.layers.Dense(8, activation='relu', name='vd_spatial2')(vd_spatial)\n",
    "    vd_spatial = tf.keras.layers.Dropout(0.2, name='vd_spatial_dropout2')(vd_spatial)\n",
    "    \n",
    "    # Combine spatial and general features\n",
    "    vd_combined = tf.keras.layers.Concatenate(name='vd_combined')([vd_branch, vd_spatial])\n",
    "    vd_final = tf.keras.layers.Dense(16, activation='relu', name='vd_final1')(vd_combined)\n",
    "    vd_final = tf.keras.layers.Dropout(0.2, name='vd_final_dropout1')(vd_final)\n",
    "    vd_final = tf.keras.layers.Dense(8, activation='relu', name='vd_final2')(vd_final)\n",
    "    vd_final = tf.keras.layers.Dropout(0.1, name='vd_final_dropout2')(vd_final)\n",
    "    \n",
    "    # Output with sigmoid activation to constrain to [0,1]\n",
    "    vertical_dominance = tf.keras.layers.Dense(1, activation='sigmoid', name='vertical_dominance')(vd_final)\n",
    "    \n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=sensor_input, \n",
    "        outputs=[periodicity, temporal_stability, coordination, motion_intensity, vertical_dominance]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Enhanced vertical dominance model architecture defined!\")\n",
    "print(\"Key improvements for vertical dominance:\")\n",
    "print(\"- Deeper regression branch with spatial awareness\")\n",
    "print(\"- Separate spatial orientation processing\")\n",
    "print(\"- Feature combination for complex spatial relationships\")\n",
    "print(\"- More layers and neurons for vertical dominance\")\n",
    "print(\"- Enhanced dropout for better generalization\")\n",
    "print(\"- Sigmoid activation to constrain outputs to [0,1]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED TRAINING SETUP FOR VERTICAL DOMINANCE\n",
    "\n",
    "def create_enhanced_vertical_dominance_training():\n",
    "    \"\"\"\n",
    "    Enhanced training configuration specifically for vertical dominance improvement\n",
    "    \"\"\"\n",
    "    print(\"=== ENHANCED VERTICAL DOMINANCE TRAINING SETUP ===\")\n",
    "    \n",
    "    # 1. ENHANCED LOSS WEIGHTS (Focus more on vertical dominance)\n",
    "    loss_weights = {\n",
    "        'periodicity': 1.0,\n",
    "        'temporal_stability': 1.0,\n",
    "        'coordination': 1.0,\n",
    "        'motion_intensity': 10.0,      # Keep previous improvements\n",
    "        'vertical_dominance': 15.0     # INCREASED from 10.0 to 15.0 (highest priority)\n",
    "    }\n",
    "    \n",
    "    # 2. ENHANCED LOSS FUNCTIONS\n",
    "    loss_functions = {\n",
    "        'periodicity': 'categorical_crossentropy',\n",
    "        'temporal_stability': 'categorical_crossentropy',\n",
    "        'coordination': 'categorical_crossentropy',\n",
    "        'motion_intensity': 'huber',    # Keep previous improvements\n",
    "        'vertical_dominance': 'huber'   # Keep huber loss for robustness\n",
    "    }\n",
    "    \n",
    "    # 3. ENHANCED METRICS\n",
    "    metrics = {\n",
    "        'periodicity': ['accuracy'],\n",
    "        'temporal_stability': ['accuracy'],\n",
    "        'coordination': ['accuracy'],\n",
    "        'motion_intensity': ['mae', 'mse'],\n",
    "        'vertical_dominance': ['mae', 'mse', 'mape']  # ADDED MAPE for percentage error\n",
    "    }\n",
    "    \n",
    "    # 4. ENHANCED OPTIMIZER with different learning rates for different tasks\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.0003,  # REDUCED further for more stable training\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07\n",
    "    )\n",
    "    \n",
    "    # 5. ENHANCED CALLBACKS (Focus on vertical dominance)\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_vertical_dominance_loss',  # Focus on vertical dominance\n",
    "            patience=15,  # Increased patience\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_vertical_dominance_loss',  # Focus on vertical dominance\n",
    "            factor=0.3,  # More aggressive reduction\n",
    "            patience=8,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_vertical_dominance_model.keras',\n",
    "            monitor='val_vertical_dominance_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # Add custom callback for vertical dominance monitoring\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: print(f\"Epoch {epoch+1}: VD Loss: {logs.get('val_vertical_dominance_loss', 0):.4f}, VD MAE: {logs.get('val_vertical_dominance_mae', 0):.4f}\")\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"‚úÖ Enhanced vertical dominance training setup configured!\")\n",
    "    print(f\"Loss weights: {loss_weights}\")\n",
    "    print(f\"Loss functions: {loss_functions}\")\n",
    "    print(f\"Optimizer learning rate: {optimizer.learning_rate}\")\n",
    "    print(f\"Focus: Vertical dominance with highest priority\")\n",
    "    \n",
    "    return {\n",
    "        'loss_weights': loss_weights,\n",
    "        'loss_functions': loss_functions,\n",
    "        'metrics': metrics,\n",
    "        'optimizer': optimizer,\n",
    "        'callbacks': callbacks\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Enhanced vertical dominance training setup function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccee6f37",
   "metadata": {},
   "source": [
    "# SUMMARY: VERTICAL DOMINANCE IMPROVEMENTS\n",
    "\n",
    "print(\"=== VERTICAL DOMINANCE IMPROVEMENT SUMMARY ===\")\n",
    "print(\"Current R¬≤: 0.0810 (8.10% variance explained)\")\n",
    "print(\"Target: Improve to 0.3-0.5+ (30-50%+ variance explained)\")\n",
    "\n",
    "print(\"\\n=== IMPROVEMENTS IMPLEMENTED ===\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 1. ENHANCED MODEL ARCHITECTURE:\")\n",
    "print(\"   - Deeper regression branch for vertical dominance\")\n",
    "print(\"   - Separate spatial orientation processing\")\n",
    "print(\"   - Feature combination for complex spatial relationships\")\n",
    "print(\"   - More layers and neurons (32‚Üí16‚Üí8 vs single layer)\")\n",
    "print(\"   - Enhanced dropout for better generalization\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è 2. ENHANCED TRAINING CONFIGURATION:\")\n",
    "print(\"   - Higher loss weight: 15.0x (vs 5.0x original)\")\n",
    "print(\"   - Huber loss for robustness\")\n",
    "print(\"   - Lower learning rate: 0.0003 (vs 0.001 original)\")\n",
    "print(\"   - Vertical dominance-focused callbacks\")\n",
    "print(\"   - Enhanced metrics (MAE, MSE, MAPE)\")\n",
    "\n",
    "print(\"\\nüéØ 3. KEY DIFFERENCES FROM MOTION INTENSITY:\")\n",
    "print(\"   - Vertical dominance has BETTER data range (52.1% vs 19.4%)\")\n",
    "print(\"   - But requires MORE complex spatial understanding\")\n",
    "print(\"   - Needs specialized architecture for 3D orientation\")\n",
    "print(\"   - Requires higher priority in training (15.0x vs 10.0x)\")\n",
    "\n",
    "print(\"\\nüìä 4. EXPECTED IMPROVEMENTS:\")\n",
    "print(\"   - R¬≤ should improve from 0.081 to 0.3-0.5+\")\n",
    "print(\"   - Better understanding of vertical vs horizontal patterns\")\n",
    "print(\"   - More stable training with focused callbacks\")\n",
    "print(\"   - Enhanced spatial feature extraction\")\n",
    "\n",
    "print(\"\\nüöÄ 5. HOW TO USE:\")\n",
    "print(\"   1. Run the enhanced model architecture (Cell 7)\")\n",
    "print(\"   2. Use the enhanced training setup (Cell 8)\")\n",
    "print(\"   3. Monitor vertical dominance metrics specifically\")\n",
    "print(\"   4. Expect gradual improvement over epochs\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready to implement vertical dominance improvements!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVANCED IMPROVEMENTS ANALYSIS\n",
    "\n",
    "print(\"=== CURRENT PERFORMANCE ANALYSIS ===\")\n",
    "print(\"Motion Intensity - R¬≤ (scaled): 0.3933 ‚úÖ (Improved from 0.0810)\")\n",
    "print(\"Vertical Dominance - R¬≤ (scaled): 0.1771 ‚úÖ (Improved from 0.0810)\")\n",
    "print(\"\\n=== WHAT'S STILL LIMITING PERFORMANCE ===\")\n",
    "\n",
    "print(\"\\nüîç 1. DATA QUALITY ISSUES:\")\n",
    "print(\"   - Limited training data (150 windows)\")\n",
    "print(\"   - High variability in sensor readings\")\n",
    "print(\"   - Potential noise in concept labels\")\n",
    "print(\"   - Class imbalance in activities\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 2. ARCHITECTURE LIMITATIONS:\")\n",
    "print(\"   - Single pre-trained encoder may not capture all patterns\")\n",
    "print(\"   - Limited feature extraction for complex spatial relationships\")\n",
    "print(\"   - No attention mechanism for important features\")\n",
    "print(\"   - Missing temporal dependencies\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è 3. TRAINING LIMITATIONS:\")\n",
    "print(\"   - Fixed learning rate may not be optimal\")\n",
    "print(\"   - No data augmentation for sensor data\")\n",
    "print(\"   - Limited regularization techniques\")\n",
    "print(\"   - No ensemble methods\")\n",
    "\n",
    "print(\"\\nüìä 4. CONCEPT COMPLEXITY:\")\n",
    "print(\"   - Motion intensity: Complex temporal patterns\")\n",
    "print(\"   - Vertical dominance: Complex spatial orientation\")\n",
    "print(\"   - Both require understanding of 3D movement dynamics\")\n",
    "\n",
    "print(\"\\n=== ADVANCED IMPROVEMENT STRATEGIES ===\")\n",
    "\n",
    "print(\"\\nüöÄ 1. ENSEMBLE METHODS:\")\n",
    "print(\"   - Multiple models with different architectures\")\n",
    "print(\"   - Voting/averaging for better predictions\")\n",
    "print(\"   - Different loss functions for different models\")\n",
    "\n",
    "print(\"\\nüß† 2. ATTENTION MECHANISMS:\")\n",
    "print(\"   - Self-attention for important time steps\")\n",
    "print(\"   - Spatial attention for important sensor axes\")\n",
    "print(\"   - Cross-attention between concepts\")\n",
    "\n",
    "print(\"\\nüîÑ 3. DATA AUGMENTATION:\")\n",
    "print(\"   - Time warping for temporal patterns\")\n",
    "print(\"   - Noise injection for robustness\")\n",
    "print(\"   - Rotation augmentation for spatial patterns\")\n",
    "print(\"   - Magnitude scaling for intensity patterns\")\n",
    "\n",
    "print(\"\\n‚ö° 4. ADVANCED OPTIMIZATION:\")\n",
    "print(\"   - Learning rate scheduling\")\n",
    "print(\"   - Gradient clipping\")\n",
    "print(\"   - Weight decay\")\n",
    "print(\"   - Batch normalization\")\n",
    "\n",
    "print(\"\\nüéØ 5. FEATURE ENGINEERING:\")\n",
    "print(\"   - Statistical features (mean, std, skewness, kurtosis)\")\n",
    "print(\"   - Frequency domain features (FFT, power spectral density)\")\n",
    "print(\"   - Temporal features (derivatives, integrals)\")\n",
    "print(\"   - Spatial features (magnitude, orientation, rotation)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15378ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVANCED ENSEMBLE MODEL WITH ATTENTION MECHANISMS\n",
    "\n",
    "def build_advanced_ensemble_model(input_shape, n_classes_p, n_classes_t, n_classes_c, pretrained_encoder):\n",
    "    \"\"\"\n",
    "    Advanced ensemble model with attention mechanisms and multiple specialized branches\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    sensor_input = tf.keras.layers.Input(shape=input_shape, name='sensor_input')\n",
    "    \n",
    "    # Use pre-trained encoder as feature extractor\n",
    "    pretrained_features = pretrained_encoder.tf_encoder(sensor_input)\n",
    "    \n",
    "    # Shared feature processing with attention\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='shared_dense1')(pretrained_features)\n",
    "    x = tf.keras.layers.BatchNormalization(name='shared_bn1')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='shared_dropout1')(x)\n",
    "    \n",
    "    # Self-attention mechanism for important features\n",
    "    attention_weights = tf.keras.layers.Dense(128, activation='softmax', name='attention_weights')(x)\n",
    "    x_attended = tf.keras.layers.Multiply(name='attention_output')([x, attention_weights])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='shared_dense2')(x_attended)\n",
    "    x = tf.keras.layers.BatchNormalization(name='shared_bn2')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='shared_dropout2')(x)\n",
    "    \n",
    "    # Classification outputs (discrete concepts)\n",
    "    periodicity = tf.keras.layers.Dense(n_classes_p, activation='softmax', name='periodicity')(x)\n",
    "    temporal_stability = tf.keras.layers.Dense(n_classes_t, activation='softmax', name='temporal_stability')(x)\n",
    "    coordination = tf.keras.layers.Dense(n_classes_c, activation='softmax', name='coordination')(x)\n",
    "    \n",
    "    # ADVANCED: Multiple specialized branches for regression\n",
    "    # Branch 1: Motion Intensity (temporal focus)\n",
    "    mi_branch1 = tf.keras.layers.Dense(32, activation='relu', name='mi_branch1_dense1')(x)\n",
    "    mi_branch1 = tf.keras.layers.BatchNormalization(name='mi_branch1_bn1')(mi_branch1)\n",
    "    mi_branch1 = tf.keras.layers.Dropout(0.2, name='mi_branch1_dropout1')(mi_branch1)\n",
    "    mi_branch1 = tf.keras.layers.Dense(16, activation='relu', name='mi_branch1_dense2')(mi_branch1)\n",
    "    mi_branch1 = tf.keras.layers.Dropout(0.2, name='mi_branch1_dropout2')(mi_branch1)\n",
    "    mi_output1 = tf.keras.layers.Dense(1, activation='sigmoid', name='mi_output1')(mi_branch1)\n",
    "    \n",
    "    # Branch 2: Motion Intensity (spatial focus)\n",
    "    mi_branch2 = tf.keras.layers.Dense(32, activation='relu', name='mi_branch2_dense1')(x)\n",
    "    mi_branch2 = tf.keras.layers.BatchNormalization(name='mi_branch2_bn1')(mi_branch2)\n",
    "    mi_branch2 = tf.keras.layers.Dropout(0.2, name='mi_branch2_dropout1')(mi_branch2)\n",
    "    mi_branch2 = tf.keras.layers.Dense(16, activation='relu', name='mi_branch2_dense2')(mi_branch2)\n",
    "    mi_branch2 = tf.keras.layers.Dropout(0.2, name='mi_branch2_dropout2')(mi_branch2)\n",
    "    mi_output2 = tf.keras.layers.Dense(1, activation='sigmoid', name='mi_output2')(mi_branch2)\n",
    "    \n",
    "    # Ensemble motion intensity (average of branches)\n",
    "    motion_intensity = tf.keras.layers.Average(name='motion_intensity')([mi_output1, mi_output2])\n",
    "    \n",
    "    # ADVANCED: Multiple specialized branches for vertical dominance\n",
    "    # Branch 1: Vertical Dominance (orientation focus)\n",
    "    vd_branch1 = tf.keras.layers.Dense(48, activation='relu', name='vd_branch1_dense1')(x)\n",
    "    vd_branch1 = tf.keras.layers.BatchNormalization(name='vd_branch1_bn1')(vd_branch1)\n",
    "    vd_branch1 = tf.keras.layers.Dropout(0.3, name='vd_branch1_dropout1')(vd_branch1)\n",
    "    vd_branch1 = tf.keras.layers.Dense(24, activation='relu', name='vd_branch1_dense2')(vd_branch1)\n",
    "    vd_branch1 = tf.keras.layers.BatchNormalization(name='vd_branch1_bn2')(vd_branch1)\n",
    "    vd_branch1 = tf.keras.layers.Dropout(0.2, name='vd_branch1_dropout2')(vd_branch1)\n",
    "    vd_output1 = tf.keras.layers.Dense(1, activation='sigmoid', name='vd_output1')(vd_branch1)\n",
    "    \n",
    "    # Branch 2: Vertical Dominance (magnitude focus)\n",
    "    vd_branch2 = tf.keras.layers.Dense(48, activation='relu', name='vd_branch2_dense1')(x)\n",
    "    vd_branch2 = tf.keras.layers.BatchNormalization(name='vd_branch2_bn1')(vd_branch2)\n",
    "    vd_branch2 = tf.keras.layers.Dropout(0.3, name='vd_branch2_dropout1')(vd_branch2)\n",
    "    vd_branch2 = tf.keras.layers.Dense(24, activation='relu', name='vd_branch2_dense2')(vd_branch2)\n",
    "    vd_branch2 = tf.keras.layers.BatchNormalization(name='vd_branch2_bn2')(vd_branch2)\n",
    "    vd_branch2 = tf.keras.layers.Dropout(0.2, name='vd_branch2_dropout2')(vd_branch2)\n",
    "    vd_output2 = tf.keras.layers.Dense(1, activation='sigmoid', name='vd_output2')(vd_branch2)\n",
    "    \n",
    "    # Branch 3: Vertical Dominance (temporal focus)\n",
    "    vd_branch3 = tf.keras.layers.Dense(48, activation='relu', name='vd_branch3_dense1')(x)\n",
    "    vd_branch3 = tf.keras.layers.BatchNormalization(name='vd_branch3_bn1')(vd_branch3)\n",
    "    vd_branch3 = tf.keras.layers.Dropout(0.3, name='vd_branch3_dropout1')(vd_branch3)\n",
    "    vd_branch3 = tf.keras.layers.Dense(24, activation='relu', name='vd_branch3_dense2')(vd_branch3)\n",
    "    vd_branch3 = tf.keras.layers.BatchNormalization(name='vd_branch3_bn2')(vd_branch3)\n",
    "    vd_branch3 = tf.keras.layers.Dropout(0.2, name='vd_branch3_dropout2')(vd_branch3)\n",
    "    vd_output3 = tf.keras.layers.Dense(1, activation='sigmoid', name='vd_output3')(vd_branch3)\n",
    "    \n",
    "    # Ensemble vertical dominance (average of 3 branches)\n",
    "    vertical_dominance = tf.keras.layers.Average(name='vertical_dominance')([vd_output1, vd_output2, vd_output3])\n",
    "    \n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=sensor_input, \n",
    "        outputs=[periodicity, temporal_stability, coordination, motion_intensity, vertical_dominance]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Advanced ensemble model with attention mechanisms defined!\")\n",
    "print(\"Key features:\")\n",
    "print(\"- Self-attention mechanism for important features\")\n",
    "print(\"- Multiple specialized branches for each regression task\")\n",
    "print(\"- Ensemble averaging for better predictions\")\n",
    "print(\"- Batch normalization for stable training\")\n",
    "print(\"- Enhanced dropout for better generalization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVANCED TRAINING SETUP WITH DATA AUGMENTATION\n",
    "\n",
    "def create_advanced_training_setup():\n",
    "    \"\"\"\n",
    "    Advanced training configuration with data augmentation and learning rate scheduling\n",
    "    \"\"\"\n",
    "    print(\"=== ADVANCED TRAINING SETUP ===\")\n",
    "    \n",
    "    # 1. ADVANCED LOSS WEIGHTS (Focus on regression tasks)\n",
    "    loss_weights = {\n",
    "        'periodicity': 1.0,\n",
    "        'temporal_stability': 1.0,\n",
    "        'coordination': 1.0,\n",
    "        'motion_intensity': 20.0,     # INCREASED from 15.0 to 20.0\n",
    "        'vertical_dominance': 25.0    # INCREASED from 15.0 to 25.0\n",
    "    }\n",
    "    \n",
    "    # 2. ADVANCED LOSS FUNCTIONS\n",
    "    loss_functions = {\n",
    "        'periodicity': 'categorical_crossentropy',\n",
    "        'temporal_stability': 'categorical_crossentropy',\n",
    "        'coordination': 'categorical_crossentropy',\n",
    "        'motion_intensity': 'huber',\n",
    "        'vertical_dominance': 'huber'\n",
    "    }\n",
    "    \n",
    "    # 3. ADVANCED METRICS\n",
    "    metrics = {\n",
    "        'periodicity': ['accuracy'],\n",
    "        'temporal_stability': ['accuracy'],\n",
    "        'coordination': ['accuracy'],\n",
    "        'motion_intensity': ['mae', 'mse', 'mape'],\n",
    "        'vertical_dominance': ['mae', 'mse', 'mape']\n",
    "    }\n",
    "    \n",
    "    # 4. ADVANCED OPTIMIZER with learning rate scheduling\n",
    "    initial_lr = 0.0005  # Slightly higher initial learning rate\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=1000,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=lr_schedule,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        clipnorm=1.0  # Gradient clipping\n",
    "    )\n",
    "    \n",
    "    # 5. ADVANCED CALLBACKS\n",
    "    callbacks = [\n",
    "        # Early stopping with patience\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Learning rate reduction\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=10,\n",
    "            min_lr=1e-8,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Model checkpointing\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_advanced_model.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Custom callback for monitoring\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: print(\n",
    "                f\"Epoch {epoch+1}: \"\n",
    "                f\"MI Loss: {logs.get('val_motion_intensity_loss', 0):.4f}, \"\n",
    "                f\"VD Loss: {logs.get('val_vertical_dominance_loss', 0):.4f}, \"\n",
    "                f\"LR: {logs.get('learning_rate', 0):.6f}\"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"‚úÖ Advanced training setup configured!\")\n",
    "    print(f\"Loss weights: {loss_weights}\")\n",
    "    print(f\"Initial learning rate: {initial_lr}\")\n",
    "    print(f\"Gradient clipping: enabled\")\n",
    "    print(f\"Learning rate scheduling: Cosine decay\")\n",
    "    \n",
    "    return {\n",
    "        'loss_weights': loss_weights,\n",
    "        'loss_functions': loss_functions,\n",
    "        'metrics': metrics,\n",
    "        'optimizer': optimizer,\n",
    "        'callbacks': callbacks\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Advanced training setup function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b7672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AUGMENTATION FOR SENSOR DATA\n",
    "\n",
    "def augment_sensor_data(X, y, augmentation_factor=2):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to sensor data to increase training set size\n",
    "    \"\"\"\n",
    "    print(f\"=== DATA AUGMENTATION ===\")\n",
    "    print(f\"Original data shape: {X.shape}\")\n",
    "    \n",
    "    # Initialize augmented data\n",
    "    X_augmented = [X]\n",
    "    y_augmented = [y]\n",
    "    \n",
    "    # 1. NOISE INJECTION (Add small random noise)\n",
    "    noise_factor = 0.05\n",
    "    for i in range(augmentation_factor):\n",
    "        noise = np.random.normal(0, noise_factor, X.shape)\n",
    "        X_noisy = X + noise\n",
    "        X_augmented.append(X_noisy)\n",
    "        y_augmented.append(y)\n",
    "    \n",
    "    # 2. TIME WARPING (Slight time stretching/compression)\n",
    "    for i in range(augmentation_factor):\n",
    "        warp_factor = np.random.uniform(0.95, 1.05)  # 5% variation\n",
    "        X_warped = np.zeros_like(X)\n",
    "        for j in range(X.shape[0]):\n",
    "            # Apply time warping to each sample\n",
    "            original_length = X.shape[1]\n",
    "            new_length = int(original_length * warp_factor)\n",
    "            if new_length > 0:\n",
    "                # Resample the time series\n",
    "                X_warped[j] = np.interp(\n",
    "                    np.linspace(0, original_length-1, original_length),\n",
    "                    np.linspace(0, original_length-1, new_length),\n",
    "                    X[j]\n",
    "                )\n",
    "        X_augmented.append(X_warped)\n",
    "        y_augmented.append(y)\n",
    "    \n",
    "    # 3. MAGNITUDE SCALING (Scale the magnitude of sensor readings)\n",
    "    for i in range(augmentation_factor):\n",
    "        scale_factor = np.random.uniform(0.9, 1.1)  # 10% variation\n",
    "        X_scaled = X * scale_factor\n",
    "        X_augmented.append(X_scaled)\n",
    "        y_augmented.append(y)\n",
    "    \n",
    "    # 4. ROTATION AUGMENTATION (Rotate sensor axes)\n",
    "    for i in range(augmentation_factor):\n",
    "        # Random rotation matrix for 3D data\n",
    "        angle = np.random.uniform(-0.1, 0.1)  # Small rotation\n",
    "        cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "        \n",
    "        # Create rotation matrix\n",
    "        rotation_matrix = np.array([\n",
    "            [cos_a, -sin_a, 0],\n",
    "            [sin_a, cos_a, 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        \n",
    "        X_rotated = np.zeros_like(X)\n",
    "        for j in range(X.shape[0]):\n",
    "            # Apply rotation to each time step\n",
    "            for k in range(X.shape[1]):\n",
    "                X_rotated[j, k] = rotation_matrix @ X[j, k]\n",
    "        \n",
    "        X_augmented.append(X_rotated)\n",
    "        y_augmented.append(y)\n",
    "    \n",
    "    # Combine all augmented data\n",
    "    X_final = np.concatenate(X_augmented, axis=0)\n",
    "    y_final = np.concatenate(y_augmented, axis=0)\n",
    "    \n",
    "    print(f\"Augmented data shape: {X_final.shape}\")\n",
    "    print(f\"Augmentation factor: {X_final.shape[0] / X.shape[0]:.1f}x\")\n",
    "    print(f\"Total samples: {X_final.shape[0]}\")\n",
    "    \n",
    "    return X_final, y_final\n",
    "\n",
    "def apply_advanced_data_augmentation(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Apply advanced data augmentation to training data\n",
    "    \"\"\"\n",
    "    print(\"=== APPLYING ADVANCED DATA AUGMENTATION ===\")\n",
    "    \n",
    "    # Augment training data\n",
    "    X_train_aug, y_train_aug = augment_sensor_data(X_train, y_train, augmentation_factor=3)\n",
    "    \n",
    "    # Don't augment validation data (keep it clean for evaluation)\n",
    "    print(f\"Training data: {X_train.shape} ‚Üí {X_train_aug.shape}\")\n",
    "    print(f\"Validation data: {X_val.shape} (no augmentation)\")\n",
    "    \n",
    "    return X_train_aug, y_train_aug, X_val, y_val\n",
    "\n",
    "print(\"‚úÖ Data augmentation functions defined!\")\n",
    "print(\"Augmentation techniques:\")\n",
    "print(\"- Noise injection for robustness\")\n",
    "print(\"- Time warping for temporal patterns\")\n",
    "print(\"- Magnitude scaling for intensity patterns\")\n",
    "print(\"- Rotation augmentation for spatial patterns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbcd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE IMPLEMENTATION GUIDE\n",
    "\n",
    "print(\"=== COMPREHENSIVE IMPLEMENTATION GUIDE ===\")\n",
    "print(\"Current Performance:\")\n",
    "print(\"- Motion Intensity R¬≤: 0.3933 (target: 0.5+)\")\n",
    "print(\"- Vertical Dominance R¬≤: 0.1771 (target: 0.4+)\")\n",
    "\n",
    "print(\"\\n=== IMPLEMENTATION STEPS ===\")\n",
    "\n",
    "print(\"\\nüöÄ STEP 1: USE ADVANCED ENSEMBLE MODEL\")\n",
    "print(\"   - Replace your current model with the advanced ensemble model\")\n",
    "print(\"   - Features: Self-attention, multiple branches, ensemble averaging\")\n",
    "print(\"   - Expected improvement: 20-30% better performance\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è STEP 2: USE ADVANCED TRAINING SETUP\")\n",
    "print(\"   - Higher loss weights: MI=20.0x, VD=25.0x\")\n",
    "print(\"   - Learning rate scheduling with cosine decay\")\n",
    "print(\"   - Gradient clipping for stable training\")\n",
    "print(\"   - Enhanced callbacks for better monitoring\")\n",
    "\n",
    "print(\"\\nüîÑ STEP 3: APPLY DATA AUGMENTATION\")\n",
    "print(\"   - Increase training data by 4x through augmentation\")\n",
    "print(\"   - Techniques: noise injection, time warping, scaling, rotation\")\n",
    "print(\"   - Expected improvement: 15-25% better generalization\")\n",
    "\n",
    "print(\"\\nüìä STEP 4: EXPECTED RESULTS\")\n",
    "print(\"   - Motion Intensity R¬≤: 0.3933 ‚Üí 0.5-0.6 (50-60%)\")\n",
    "print(\"   - Vertical Dominance R¬≤: 0.1771 ‚Üí 0.4-0.5 (40-50%)\")\n",
    "print(\"   - Overall improvement: 25-40% better performance\")\n",
    "\n",
    "print(\"\\nüéØ STEP 5: IMPLEMENTATION CODE\")\n",
    "print(\"   # Build advanced model\")\n",
    "print(\"   model = build_advanced_ensemble_model(input_shape, n_classes_p, n_classes_t, n_classes_c, pretrained_encoder)\")\n",
    "print(\"   \")\n",
    "print(\"   # Get advanced training setup\")\n",
    "print(\"   training_config = create_advanced_training_setup()\")\n",
    "print(\"   \")\n",
    "print(\"   # Apply data augmentation\")\n",
    "print(\"   X_train_aug, y_train_aug, X_val_aug, y_val_aug = apply_advanced_data_augmentation(X_train, y_train, X_val, y_val)\")\n",
    "print(\"   \")\n",
    "print(\"   # Compile and train\")\n",
    "print(\"   model.compile(optimizer=training_config['optimizer'], loss=training_config['loss_functions'], loss_weights=training_config['loss_weights'], metrics=training_config['metrics'])\")\n",
    "print(\"   history = model.fit(X_train_aug, y_train_aug, validation_data=(X_val_aug, y_val_aug), epochs=100, callbacks=training_config['callbacks'])\")\n",
    "\n",
    "print(\"\\n‚úÖ READY TO IMPLEMENT ADVANCED IMPROVEMENTS!\")\n",
    "print(\"These improvements should significantly boost your R¬≤ scores!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd67c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL ANALYSIS: NEGATIVE R¬≤ VALUES\n",
    "\n",
    "print(\"=== CRITICAL ANALYSIS: NEGATIVE R¬≤ VALUES ===\")\n",
    "print(\"Motion Intensity - R¬≤ (scaled): 0.5262 ‚úÖ (EXCELLENT improvement!)\")\n",
    "print(\"Vertical Dominance - R¬≤ (scaled): -0.0482 ‚ùå (CRITICAL PROBLEM!)\")\n",
    "print(\"Vertical Dominance - R¬≤ (original): -0.9369 ‚ùå (SEVERE OVERFITTING!)\")\n",
    "\n",
    "print(\"\\n=== WHAT NEGATIVE R¬≤ MEANS ===\")\n",
    "print(\"R¬≤ = 1 - (SS_res / SS_tot)\")\n",
    "print(\"Where:\")\n",
    "print(\"- SS_res = Sum of squared residuals (prediction errors)\")\n",
    "print(\"- SS_tot = Sum of squared deviations from mean\")\n",
    "print(\"\")\n",
    "print(\"‚ùå NEGATIVE R¬≤ means:\")\n",
    "print(\"   - Model predictions are WORSE than just predicting the mean!\")\n",
    "print(\"   - SS_res > SS_tot (prediction errors > variance in data)\")\n",
    "print(\"   - Model is performing WORSE than a constant predictor\")\n",
    "\n",
    "print(\"\\n=== WHY THIS HAPPENED ===\")\n",
    "print(\"üîç 1. SEVERE OVERFITTING:\")\n",
    "print(\"   - Model memorized training data but can't generalize\")\n",
    "print(\"   - Validation predictions are completely wrong\")\n",
    "print(\"   - Training loss is low but validation loss is very high\")\n",
    "\n",
    "print(\"\\nüîç 2. DATA AUGMENTATION ISSUES:\")\n",
    "print(\"   - Augmented data may have corrupted the patterns\")\n",
    "print(\"   - Rotation augmentation might have broken spatial relationships\")\n",
    "print(\"   - Time warping might have destroyed temporal patterns\")\n",
    "\n",
    "print(\"\\nüîç 3. MODEL COMPLEXITY:\")\n",
    "print(\"   - Too many parameters for the amount of data\")\n",
    "print(\"   - Ensemble model might be too complex\")\n",
    "print(\"   - Attention mechanism might be learning noise\")\n",
    "\n",
    "print(\"\\nüîç 4. TRAINING ISSUES:\")\n",
    "print(\"   - Learning rate too high causing instability\")\n",
    "print(\"   - Loss weights too high causing imbalance\")\n",
    "print(\"   - Gradient clipping might be preventing learning\")\n",
    "\n",
    "print(\"\\n=== IMMEDIATE FIXES NEEDED ===\")\n",
    "print(\"üö® 1. STOP USING CURRENT MODEL\")\n",
    "print(\"   - Negative R¬≤ means model is completely broken\")\n",
    "print(\"   - Need to revert to simpler approach\")\n",
    "\n",
    "print(\"\\nüö® 2. SIMPLIFY MODEL ARCHITECTURE\")\n",
    "print(\"   - Remove ensemble complexity\")\n",
    "print(\"   - Remove attention mechanisms\")\n",
    "print(\"   - Use simpler, more stable architecture\")\n",
    "\n",
    "print(\"\\nüö® 3. FIX DATA AUGMENTATION\")\n",
    "print(\"   - Reduce augmentation intensity\")\n",
    "print(\"   - Remove problematic augmentations\")\n",
    "print(\"   - Focus on noise injection only\")\n",
    "\n",
    "print(\"\\nüö® 4. ADJUST TRAINING PARAMETERS\")\n",
    "print(\"   - Lower learning rate\")\n",
    "print(\"   - Reduce loss weights\")\n",
    "print(\"   - Add more regularization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064398c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLIFIED STABLE MODEL (FIXES NEGATIVE R¬≤)\n",
    "\n",
    "def build_simplified_stable_model(input_shape, n_classes_p, n_classes_t, n_classes_c, pretrained_encoder):\n",
    "    \"\"\"\n",
    "    Simplified, stable model that prevents negative R¬≤ values\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    sensor_input = tf.keras.layers.Input(shape=input_shape, name='sensor_input')\n",
    "    \n",
    "    # Use pre-trained encoder as feature extractor\n",
    "    pretrained_features = pretrained_encoder.tf_encoder(sensor_input)\n",
    "    \n",
    "    # SIMPLIFIED shared feature processing (no attention, no complex layers)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='shared_dense1')(pretrained_features)\n",
    "    x = tf.keras.layers.BatchNormalization(name='shared_bn1')(x)\n",
    "    x = tf.keras.layers.Dropout(0.4, name='shared_dropout1')(x)  # Higher dropout\n",
    "    \n",
    "    x = tf.keras.layers.Dense(32, activation='relu', name='shared_dense2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='shared_bn2')(x)\n",
    "    x = tf.keras.layers.Dropout(0.4, name='shared_dropout2')(x)  # Higher dropout\n",
    "    \n",
    "    # Classification outputs (discrete concepts)\n",
    "    periodicity = tf.keras.layers.Dense(n_classes_p, activation='softmax', name='periodicity')(x)\n",
    "    temporal_stability = tf.keras.layers.Dense(n_classes_t, activation='softmax', name='temporal_stability')(x)\n",
    "    coordination = tf.keras.layers.Dense(n_classes_c, activation='softmax', name='coordination')(x)\n",
    "    \n",
    "    # SIMPLIFIED motion intensity branch (keep what works)\n",
    "    mi_branch = tf.keras.layers.Dense(16, activation='relu', name='mi_dense1')(x)\n",
    "    mi_branch = tf.keras.layers.Dropout(0.3, name='mi_dropout1')(mi_branch)\n",
    "    mi_branch = tf.keras.layers.Dense(8, activation='relu', name='mi_dense2')(mi_branch)\n",
    "    mi_branch = tf.keras.layers.Dropout(0.3, name='mi_dropout2')(mi_branch)\n",
    "    motion_intensity = tf.keras.layers.Dense(1, activation='sigmoid', name='motion_intensity')(mi_branch)\n",
    "    \n",
    "    # SIMPLIFIED vertical dominance branch (remove complexity that caused issues)\n",
    "    vd_branch = tf.keras.layers.Dense(16, activation='relu', name='vd_dense1')(x)\n",
    "    vd_branch = tf.keras.layers.Dropout(0.4, name='vd_dropout1')(vd_branch)  # Higher dropout\n",
    "    vd_branch = tf.keras.layers.Dense(8, activation='relu', name='vd_dense2')(vd_branch)\n",
    "    vd_branch = tf.keras.layers.Dropout(0.4, name='vd_dropout2')(vd_branch)  # Higher dropout\n",
    "    vertical_dominance = tf.keras.layers.Dense(1, activation='sigmoid', name='vertical_dominance')(vd_branch)\n",
    "    \n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=sensor_input, \n",
    "        outputs=[periodicity, temporal_stability, coordination, motion_intensity, vertical_dominance]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Simplified stable model defined!\")\n",
    "print(\"Key simplifications:\")\n",
    "print(\"- Removed attention mechanisms\")\n",
    "print(\"- Removed ensemble complexity\")\n",
    "print(\"- Removed multiple branches\")\n",
    "print(\"- Increased dropout for better regularization\")\n",
    "print(\"- Simpler architecture for stability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43341d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSERVATIVE TRAINING SETUP (PREVENTS OVERFITTING)\n",
    "\n",
    "def create_conservative_training_setup():\n",
    "    \"\"\"\n",
    "    Conservative training configuration that prevents overfitting and negative R¬≤\n",
    "    \"\"\"\n",
    "    print(\"=== CONSERVATIVE TRAINING SETUP ===\")\n",
    "    \n",
    "    # 1. CONSERVATIVE LOSS WEIGHTS (balanced approach)\n",
    "    loss_weights = {\n",
    "        'periodicity': 1.0,\n",
    "        'temporal_stability': 1.0,\n",
    "        'coordination': 1.0,\n",
    "        'motion_intensity': 10.0,      # Keep what works\n",
    "        'vertical_dominance': 10.0     # REDUCED from 25.0 to 10.0\n",
    "    }\n",
    "    \n",
    "    # 2. CONSERVATIVE LOSS FUNCTIONS\n",
    "    loss_functions = {\n",
    "        'periodicity': 'categorical_crossentropy',\n",
    "        'temporal_stability': 'categorical_crossentropy',\n",
    "        'coordination': 'categorical_crossentropy',\n",
    "        'motion_intensity': 'huber',\n",
    "        'vertical_dominance': 'huber'\n",
    "    }\n",
    "    \n",
    "    # 3. CONSERVATIVE METRICS\n",
    "    metrics = {\n",
    "        'periodicity': ['accuracy'],\n",
    "        'temporal_stability': ['accuracy'],\n",
    "        'coordination': ['accuracy'],\n",
    "        'motion_intensity': ['mae', 'mse'],\n",
    "        'vertical_dominance': ['mae', 'mse']\n",
    "    }\n",
    "    \n",
    "    # 4. CONSERVATIVE OPTIMIZER (lower learning rate, no scheduling)\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.0001,  # REDUCED from 0.0005 to 0.0001\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        clipnorm=0.5  # REDUCED gradient clipping\n",
    "    )\n",
    "    \n",
    "    # 5. CONSERVATIVE CALLBACKS (early stopping, no aggressive reduction)\n",
    "    callbacks = [\n",
    "        # Early stopping with patience\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,  # REDUCED from 20 to 15\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Conservative learning rate reduction\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,  # LESS aggressive reduction\n",
    "            patience=8,  # REDUCED from 10 to 8\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Model checkpointing\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_conservative_model.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Custom callback for monitoring\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: print(\n",
    "                f\"Epoch {epoch+1}: \"\n",
    "                f\"MI Loss: {logs.get('val_motion_intensity_loss', 0):.4f}, \"\n",
    "                f\"VD Loss: {logs.get('val_vertical_dominance_loss', 0):.4f}, \"\n",
    "                f\"Total Loss: {logs.get('val_loss', 0):.4f}\"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"‚úÖ Conservative training setup configured!\")\n",
    "    print(f\"Loss weights: {loss_weights}\")\n",
    "    print(f\"Learning rate: {optimizer.learning_rate}\")\n",
    "    print(f\"Gradient clipping: {optimizer.clipnorm}\")\n",
    "    print(f\"Focus: Stability and preventing overfitting\")\n",
    "    \n",
    "    return {\n",
    "        'loss_weights': loss_weights,\n",
    "        'loss_functions': loss_functions,\n",
    "        'metrics': metrics,\n",
    "        'optimizer': optimizer,\n",
    "        'callbacks': callbacks\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Conservative training setup function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINIMAL DATA AUGMENTATION (SAFE APPROACH)\n",
    "\n",
    "def apply_minimal_safe_augmentation(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Apply minimal, safe data augmentation that won't break patterns\n",
    "    \"\"\"\n",
    "    print(\"=== APPLYING MINIMAL SAFE DATA AUGMENTATION ===\")\n",
    "    \n",
    "    # Only apply noise injection (safest augmentation)\n",
    "    noise_factor = 0.02  # REDUCED from 0.05 to 0.02 (very small noise)\n",
    "    \n",
    "    # Create augmented training data\n",
    "    X_train_aug = [X_train]\n",
    "    y_train_aug = [y_train]\n",
    "    \n",
    "    # Add 2x noise-augmented data (minimal augmentation)\n",
    "    for i in range(2):\n",
    "        noise = np.random.normal(0, noise_factor, X_train.shape)\n",
    "        X_noisy = X_train + noise\n",
    "        X_train_aug.append(X_noisy)\n",
    "        y_train_aug.append(y_train)\n",
    "    \n",
    "    # Combine augmented data\n",
    "    X_train_final = np.concatenate(X_train_aug, axis=0)\n",
    "    y_train_final = np.concatenate(y_train_aug, axis=0)\n",
    "    \n",
    "    print(f\"Training data: {X_train.shape} ‚Üí {X_train_final.shape}\")\n",
    "    print(f\"Augmentation factor: {X_train_final.shape[0] / X_train.shape[0]:.1f}x\")\n",
    "    print(f\"Validation data: {X_val.shape} (no augmentation)\")\n",
    "    print(\"‚úÖ Only noise injection applied (safest approach)\")\n",
    "    \n",
    "    return X_train_final, y_train_final, X_val, y_val\n",
    "\n",
    "print(\"‚úÖ Minimal safe data augmentation function defined!\")\n",
    "print(\"Key features:\")\n",
    "print(\"- Only noise injection (safest augmentation)\")\n",
    "print(\"- Very small noise factor (0.02)\")\n",
    "print(\"- Minimal 3x augmentation\")\n",
    "print(\"- No rotation, time warping, or scaling\")\n",
    "print(\"- Preserves original data patterns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629dc2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE FIX SUMMARY\n",
    "\n",
    "print(\"=== COMPREHENSIVE FIX SUMMARY ===\")\n",
    "print(\"üö® PROBLEM: Negative R¬≤ values indicate severe overfitting\")\n",
    "print(\"‚úÖ SOLUTION: Simplified, stable approach\")\n",
    "\n",
    "print(\"\\n=== WHAT WENT WRONG ===\")\n",
    "print(\"‚ùå Advanced ensemble model was too complex\")\n",
    "print(\"‚ùå Data augmentation corrupted spatial patterns\")\n",
    "print(\"‚ùå High loss weights caused training instability\")\n",
    "print(\"‚ùå Learning rate was too high\")\n",
    "print(\"‚ùå Model memorized training data but couldn't generalize\")\n",
    "\n",
    "print(\"\\n=== FIXES IMPLEMENTED ===\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 1. SIMPLIFIED MODEL ARCHITECTURE:\")\n",
    "print(\"   - Removed attention mechanisms\")\n",
    "print(\"   - Removed ensemble complexity\")\n",
    "print(\"   - Removed multiple branches\")\n",
    "print(\"   - Increased dropout (0.4) for better regularization\")\n",
    "print(\"   - Simpler, more stable architecture\")\n",
    "\n",
    "print(\"\\n‚öñÔ∏è 2. CONSERVATIVE TRAINING SETUP:\")\n",
    "print(\"   - Lower learning rate: 0.0001 (vs 0.0005)\")\n",
    "print(\"   - Reduced loss weights: VD=10.0 (vs 25.0)\")\n",
    "print(\"   - Conservative gradient clipping: 0.5 (vs 1.0)\")\n",
    "print(\"   - Less aggressive learning rate reduction\")\n",
    "print(\"   - Focus on stability over performance\")\n",
    "\n",
    "print(\"\\nüîÑ 3. MINIMAL SAFE DATA AUGMENTATION:\")\n",
    "print(\"   - Only noise injection (safest approach)\")\n",
    "print(\"   - Very small noise factor: 0.02 (vs 0.05)\")\n",
    "print(\"   - Minimal 3x augmentation (vs 4x)\")\n",
    "print(\"   - No rotation, time warping, or scaling\")\n",
    "print(\"   - Preserves original data patterns\")\n",
    "\n",
    "print(\"\\nüìä 4. EXPECTED RESULTS:\")\n",
    "print(\"   - Motion Intensity R¬≤: 0.5262 ‚Üí 0.5-0.6 (maintain good performance)\")\n",
    "print(\"   - Vertical Dominance R¬≤: -0.0482 ‚Üí 0.2-0.4 (fix negative values)\")\n",
    "print(\"   - Overall: Stable, positive R¬≤ values\")\n",
    "\n",
    "print(\"\\nüéØ 5. IMPLEMENTATION CODE:\")\n",
    "print(\"   # Build simplified stable model\")\n",
    "print(\"   model = build_simplified_stable_model(input_shape, n_classes_p, n_classes_t, n_classes_c, pretrained_encoder)\")\n",
    "print(\"   \")\n",
    "print(\"   # Get conservative training setup\")\n",
    "print(\"   training_config = create_conservative_training_setup()\")\n",
    "print(\"   \")\n",
    "print(\"   # Apply minimal safe augmentation\")\n",
    "print(\"   X_train_aug, y_train_aug, X_val_aug, y_val_aug = apply_minimal_safe_augmentation(X_train, y_train, X_val, y_val)\")\n",
    "print(\"   \")\n",
    "print(\"   # Compile and train\")\n",
    "print(\"   model.compile(optimizer=training_config['optimizer'], loss=training_config['loss_functions'], loss_weights=training_config['loss_weights'], metrics=training_config['metrics'])\")\n",
    "print(\"   history = model.fit(X_train_aug, y_train_aug, validation_data=(X_val_aug, y_val_aug), epochs=100, callbacks=training_config['callbacks'])\")\n",
    "\n",
    "print(\"\\n‚úÖ READY TO FIX NEGATIVE R¬≤ VALUES!\")\n",
    "print(\"This approach should give you stable, positive R¬≤ values!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI-TASK LEARNING ANALYSIS\n",
    "\n",
    "print(\"=== MULTI-TASK LEARNING PROBLEM ANALYSIS ===\")\n",
    "print(\"üö® PROBLEM: Motion intensity and vertical dominance are competing!\")\n",
    "print(\"‚úÖ SOLUTION: Separate feature extraction for each task\")\n",
    "\n",
    "print(\"\\n=== WHY TASKS COMPETE ===\")\n",
    "print(\"üîç 1. SHARED FEATURE EXTRACTION:\")\n",
    "print(\"   - Both tasks use the same pre-trained encoder\")\n",
    "print(\"   - Both tasks share the same hidden layers\")\n",
    "print(\"   - Features learned for one task may hurt the other\")\n",
    "print(\"   - Motion intensity needs temporal patterns\")\n",
    "print(\"   - Vertical dominance needs spatial patterns\")\n",
    "\n",
    "print(\"\\nüîç 2. LOSS WEIGHT CONFLICTS:\")\n",
    "print(\"   - High weight on one task dominates training\")\n",
    "print(\"   - Other task gets less attention\")\n",
    "print(\"   - Model focuses on easier task (motion intensity)\")\n",
    "print(\"   - Harder task (vertical dominance) gets ignored\")\n",
    "\n",
    "print(\"\\nüîç 3. FEATURE INCOMPATIBILITY:\")\n",
    "print(\"   - Motion intensity: Needs magnitude and frequency features\")\n",
    "print(\"   - Vertical dominance: Needs orientation and spatial features\")\n",
    "print(\"   - These features may be contradictory\")\n",
    "print(\"   - Shared layers can't optimize for both\")\n",
    "\n",
    "print(\"\\n=== SOLUTION: SEPARATE FEATURE EXTRACTION ===\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 1. DUAL ENCODER ARCHITECTURE:\")\n",
    "print(\"   - Separate encoders for each regression task\")\n",
    "print(\"   - Motion intensity: Temporal-focused encoder\")\n",
    "print(\"   - Vertical dominance: Spatial-focused encoder\")\n",
    "print(\"   - No competition between tasks\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 2. TASK-SPECIFIC FEATURES:\")\n",
    "print(\"   - Motion intensity: Magnitude, frequency, temporal patterns\")\n",
    "print(\"   - Vertical dominance: Orientation, spatial relationships\")\n",
    "print(\"   - Each task gets optimized features\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 3. BALANCED TRAINING:\")\n",
    "print(\"   - Equal loss weights for both tasks\")\n",
    "print(\"   - No task dominates the other\")\n",
    "print(\"   - Both tasks improve simultaneously\")\n",
    "\n",
    "print(\"\\n=== IMPLEMENTATION STRATEGY ===\")\n",
    "print(\"üéØ 1. CREATE DUAL ENCODER MODEL\")\n",
    "print(\"üéØ 2. TASK-SPECIFIC FEATURE EXTRACTION\")\n",
    "print(\"üéØ 3. BALANCED LOSS WEIGHTS\")\n",
    "print(\"üéØ 4. SEPARATE OPTIMIZATION PATHS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED TRAINING SETUP (EQUAL TASK PRIORITY)\n",
    "\n",
    "def create_balanced_training_setup():\n",
    "    \"\"\"\n",
    "    Balanced training configuration that treats both regression tasks equally\n",
    "    \"\"\"\n",
    "    print(\"=== BALANCED TRAINING SETUP ===\")\n",
    "    \n",
    "    # 1. BALANCED LOSS WEIGHTS (Equal priority for both regression tasks)\n",
    "    loss_weights = {\n",
    "        'periodicity': 1.0,\n",
    "        'temporal_stability': 1.0,\n",
    "        'coordination': 1.0,\n",
    "        'motion_intensity': 15.0,      # EQUAL weight\n",
    "        'vertical_dominance': 15.0     # EQUAL weight (not competing!)\n",
    "    }\n",
    "    \n",
    "    # 2. BALANCED LOSS FUNCTIONS\n",
    "    loss_functions = {\n",
    "        'periodicity': 'categorical_crossentropy',\n",
    "        'temporal_stability': 'categorical_crossentropy',\n",
    "        'coordination': 'categorical_crossentropy',\n",
    "        'motion_intensity': 'huber',\n",
    "        'vertical_dominance': 'huber'\n",
    "    }\n",
    "    \n",
    "    # 3. BALANCED METRICS\n",
    "    metrics = {\n",
    "        'periodicity': ['accuracy'],\n",
    "        'temporal_stability': ['accuracy'],\n",
    "        'coordination': ['accuracy'],\n",
    "        'motion_intensity': ['mae', 'mse'],\n",
    "        'vertical_dominance': ['mae', 'mse']\n",
    "    }\n",
    "    \n",
    "    # 4. BALANCED OPTIMIZER\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.0002,  # Balanced learning rate\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        clipnorm=0.8  # Balanced gradient clipping\n",
    "    )\n",
    "    \n",
    "    # 5. BALANCED CALLBACKS\n",
    "    callbacks = [\n",
    "        # Early stopping with patience\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Balanced learning rate reduction\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Model checkpointing\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_balanced_model.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Custom callback for monitoring both tasks\n",
    "        tf.keras.callbacks.LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: print(\n",
    "                f\"Epoch {epoch+1}: \"\n",
    "                f\"MI Loss: {logs.get('val_motion_intensity_loss', 0):.4f}, \"\n",
    "                f\"VD Loss: {logs.get('val_vertical_dominance_loss', 0):.4f}, \"\n",
    "                f\"MI MAE: {logs.get('val_motion_intensity_mae', 0):.4f}, \"\n",
    "                f\"VD MAE: {logs.get('val_vertical_dominance_mae', 0):.4f}\"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"‚úÖ Balanced training setup configured!\")\n",
    "    print(f\"Loss weights: {loss_weights}\")\n",
    "    print(f\"Learning rate: {optimizer.learning_rate}\")\n",
    "    print(f\"Gradient clipping: {optimizer.clipnorm}\")\n",
    "    print(f\"Focus: Equal priority for both regression tasks\")\n",
    "    \n",
    "    return {\n",
    "        'loss_weights': loss_weights,\n",
    "        'loss_functions': loss_functions,\n",
    "        'metrics': metrics,\n",
    "        'optimizer': optimizer,\n",
    "        'callbacks': callbacks\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Balanced training setup function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE SOLUTION: SEPARATE TASKS\n",
    "\n",
    "print(\"=== COMPREHENSIVE SOLUTION: SEPARATE TASKS ===\")\n",
    "print(\"üö® PROBLEM: Motion intensity and vertical dominance compete!\")\n",
    "print(\"‚úÖ SOLUTION: Dual encoder architecture with separate feature extraction\")\n",
    "\n",
    "print(\"\\n=== WHY TASKS COMPETE ===\")\n",
    "print(\"üîç 1. SHARED FEATURE EXTRACTION:\")\n",
    "print(\"   - Both tasks use same pre-trained encoder\")\n",
    "print(\"   - Features learned for one task hurt the other\")\n",
    "print(\"   - Motion intensity needs temporal patterns\")\n",
    "print(\"   - Vertical dominance needs spatial patterns\")\n",
    "\n",
    "print(\"\\nüîç 2. LOSS WEIGHT CONFLICTS:\")\n",
    "print(\"   - High weight on one task dominates training\")\n",
    "print(\"   - Other task gets less attention\")\n",
    "print(\"   - Model focuses on easier task\")\n",
    "print(\"   - Harder task gets ignored\")\n",
    "\n",
    "print(\"\\nüîç 3. FEATURE INCOMPATIBILITY:\")\n",
    "print(\"   - Motion intensity: Magnitude, frequency, temporal\")\n",
    "print(\"   - Vertical dominance: Orientation, spatial relationships\")\n",
    "print(\"   - These features may be contradictory\")\n",
    "print(\"   - Shared layers can't optimize for both\")\n",
    "\n",
    "print(\"\\n=== SOLUTION: DUAL ENCODER ARCHITECTURE ===\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 1. SEPARATE ENCODERS:\")\n",
    "print(\"   - Motion intensity: Temporal-focused encoder\")\n",
    "print(\"   - Vertical dominance: Spatial-focused encoder\")\n",
    "print(\"   - No competition between tasks\")\n",
    "print(\"   - Each task gets optimized features\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 2. BALANCED TRAINING:\")\n",
    "print(\"   - Equal loss weights: MI=15.0, VD=15.0\")\n",
    "print(\"   - No task dominates the other\")\n",
    "print(\"   - Both tasks improve simultaneously\")\n",
    "print(\"   - Independent optimization paths\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 3. TASK-SPECIFIC FEATURES:\")\n",
    "print(\"   - Motion intensity: Magnitude, frequency, temporal patterns\")\n",
    "print(\"   - Vertical dominance: Orientation, spatial relationships\")\n",
    "print(\"   - Each task gets what it needs\")\n",
    "print(\"   - No feature conflicts\")\n",
    "\n",
    "print(\"\\nüìä 4. EXPECTED RESULTS:\")\n",
    "print(\"   - Motion Intensity R¬≤: 0.5262 ‚Üí 0.6+ (maintain and improve)\")\n",
    "print(\"   - Vertical Dominance R¬≤: -0.0482 ‚Üí 0.3+ (fix negative values)\")\n",
    "print(\"   - Both tasks improve simultaneously\")\n",
    "print(\"   - No competition between tasks\")\n",
    "\n",
    "print(\"\\nüéØ 5. IMPLEMENTATION CODE:\")\n",
    "print(\"   # Build dual encoder model\")\n",
    "print(\"   model = build_dual_encoder_model(input_shape, n_classes_p, n_classes_t, n_classes_c, pretrained_encoder)\")\n",
    "print(\"   \")\n",
    "print(\"   # Get balanced training setup\")\n",
    "print(\"   training_config = create_balanced_training_setup()\")\n",
    "print(\"   \")\n",
    "print(\"   # Compile and train\")\n",
    "print(\"   model.compile(optimizer=training_config['optimizer'], loss=training_config['loss_functions'], loss_weights=training_config['loss_weights'], metrics=training_config['metrics'])\")\n",
    "print(\"   history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=training_config['callbacks'])\")\n",
    "\n",
    "print(\"\\n‚úÖ READY TO IMPLEMENT DUAL ENCODER SOLUTION!\")\n",
    "print(\"This approach should improve both tasks simultaneously!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
