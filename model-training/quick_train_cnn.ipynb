{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick CNN Training - Ultra Lightweight + Augmentation\n",
    "\n",
    "## Overview\n",
    "This notebook contains only the essential components for training the ultra-lightweight CNN with augmentation and random shuffle split.\n",
    "\n",
    "## Features\n",
    "- **7 Core Concepts**: periodicity, temporal_stability, coordination, motion_intensity, vertical_dominance, directional_variability, burstiness\n",
    "- **Data Augmentation**: Jitter, scaling, and rotation for robust training\n",
    "- **Contextual Learning**: Static posture context for motion concepts\n",
    "- **Optimized Architecture**: Lightweight CNN with enhanced parameters for 7 concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration\n",
    "\n",
    "**Purpose**: Load necessary libraries and contextual configuration for model training.\n",
    "\n",
    "**Key Components**:\n",
    "- TensorFlow/Keras for deep learning\n",
    "- Scikit-learn for data preprocessing\n",
    "- Contextual configuration for motion concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick CNN Training - Ultra Lightweight + Augmentation\n",
    "## Streamlined version for rapid iteration\n",
    "\n",
    "This notebook contains only the essential components for training the ultra-lightweight CNN with augmentation and random shuffle split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.11.3\n",
      "\n",
      "Loaded contextual configuration:\n",
      "  motion_intensity: Uses static posture context\n",
      "  vertical_dominance: Uses static posture context\n",
      "  periodicity: Independent\n",
      "  temporal_stability: Independent\n",
      "  coordination: Independent\n",
      "  directional_variability: Independent\n",
      "  burstiness: Independent\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# Load contextual configuration from rule definitions\n",
    "try:\n",
    "    with open('../rule_based_labeling/contextual_config.json', 'r') as f:\n",
    "        contextual_config = json.load(f)\n",
    "    print(f\"\\nLoaded contextual configuration:\")\n",
    "    for feature, uses_context in contextual_config.items():\n",
    "        print(f\"  {feature}: {'Uses static posture context' if uses_context else 'Independent'}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: contextual_config.json not found. Using default configuration.\")\n",
    "    contextual_config = {\n",
    "        'motion_intensity': True,\n",
    "        'vertical_dominance': True,\n",
    "        'periodicity': False,\n",
    "        'temporal_stability': False,\n",
    "        'coordination': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Discretization\n",
    "\n",
    "**Purpose**: Load sensor data and convert continuous concept values to discrete categories.\n",
    "\n",
    "**Process**:\n",
    "- Load raw sensor data and window labels\n",
    "- Convert continuous values to discrete (0.0, 0.5, 1.0) for all concepts\n",
    "- Apply discretization rules for motion_intensity and vertical_dominance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data: 8802 readings\n",
      "Manual labels: 150 windows\n",
      "\n",
      "Labeled windows:\n",
      "   window_idx  user activity  start_time  end_time  periodicity  \\\n",
      "0           0     3  Walking      957.75    960.75          1.0   \n",
      "1           1     3  Walking       42.00     45.00          1.0   \n",
      "2           2     3  Walking      871.50    874.50          0.5   \n",
      "3           3     3  Walking       63.00     66.00          1.0   \n",
      "4           4     3  Jogging      117.75    120.75          1.0   \n",
      "\n",
      "   temporal_stability  coordination  motion_intensity  vertical_dominance  \\\n",
      "0                 0.5           0.5          0.316815            0.221105   \n",
      "1                 0.5           0.5          0.302850            0.291116   \n",
      "2                 0.5           0.5          0.303036            0.181147   \n",
      "3                 0.5           0.5          0.313779            0.305797   \n",
      "4                 0.5           0.5          0.408648            0.262989   \n",
      "\n",
      "   static_posture  directional_variability  burstiness  \n",
      "0             0.0                 0.154414    0.489167  \n",
      "1             0.0                 0.070586    0.215654  \n",
      "2             0.0                 0.120062    0.442595  \n",
      "3             0.0                 0.087703    0.259150  \n",
      "4             0.0                 0.441992    0.342272  \n",
      "\n",
      "Available concepts: ['periodicity', 'temporal_stability', 'coordination', 'motion_intensity', 'vertical_dominance', 'static_posture', 'directional_variability', 'burstiness']\n",
      "\n",
      "=== BEFORE DISCRETIZATION ===\n",
      "Original motion_intensity range: 0.2772 to 0.4711\n",
      "Original vertical_dominance range: 0.0414 to 0.5620\n",
      "Original directional_variability range: 0.0001 to 0.6104\n",
      "Original burstiness range: 0.0029 to 0.4940\n",
      "\n",
      "=== APPLYING DISCRETIZATION ===\n",
      "\n",
      "=== AFTER DISCRETIZATION ===\n",
      "Discretized motion_intensity: motion_intensity\n",
      "0.0    118\n",
      "0.5     30\n",
      "1.0      2\n",
      "Name: count, dtype: int64\n",
      "Discretized vertical_dominance: vertical_dominance\n",
      "0.0     37\n",
      "0.5    100\n",
      "1.0     13\n",
      "Name: count, dtype: int64\n",
      "Discretized directional_variability: directional_variability\n",
      "0.0    66\n",
      "0.5    48\n",
      "1.0    36\n",
      "Name: count, dtype: int64\n",
      "Discretized burstiness: burstiness\n",
      "0.0    27\n",
      "0.5    37\n",
      "1.0    86\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== FINAL CONCEPT DISTRIBUTIONS ===\n",
      "  periodicity: {0.0: np.int64(90), 0.5: np.int64(35), 1.0: np.int64(25)}\n",
      "  temporal_stability: {0.0: np.int64(12), 0.5: np.int64(87), 1.0: np.int64(51)}\n",
      "  coordination: {0.0: np.int64(16), 0.5: np.int64(64), 1.0: np.int64(70)}\n",
      "  motion_intensity: {0.0: np.int64(118), 0.5: np.int64(30), 1.0: np.int64(2)}\n",
      "  vertical_dominance: {0.0: np.int64(37), 0.5: np.int64(100), 1.0: np.int64(13)}\n",
      "  static_posture: {0.0: np.int64(147), 1.0: np.int64(3)}\n",
      "  directional_variability: {0.0: np.int64(66), 0.5: np.int64(48), 1.0: np.int64(36)}\n",
      "  burstiness: {0.0: np.int64(27), 0.5: np.int64(37), 1.0: np.int64(86)}\n",
      "\n",
      "Discretization completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load data - CHANGE THESE PATHS AS NEEDED\n",
    "df_sensor = pd.read_csv('../rule_based_labeling/raw_with_features.csv')\n",
    "df_windows = pd.read_csv('../rule_based_labeling/window_with_features.csv') \n",
    "\n",
    "print(f\"Sensor data: {len(df_sensor)} readings\")\n",
    "print(f\"Manual labels: {len(df_windows)} windows\")\n",
    "print(f\"\\nLabeled windows:\")\n",
    "print(df_windows.head())\n",
    "\n",
    "# Check available concepts - UPDATED FOR 7 CONCEPTS\n",
    "concept_columns = ['periodicity', 'temporal_stability', 'coordination', 'motion_intensity', 'vertical_dominance', 'static_posture', 'directional_variability', 'burstiness']\n",
    "print(f\"\\nAvailable concepts: {concept_columns}\")\n",
    "\n",
    "# Debug: Check original values BEFORE discretization\n",
    "print(f\"\\n=== BEFORE DISCRETIZATION ===\")\n",
    "print(f\"Original motion_intensity range: {df_windows['motion_intensity'].min():.4f} to {df_windows['motion_intensity'].max():.4f}\")\n",
    "print(f\"Original vertical_dominance range: {df_windows['vertical_dominance'].min():.4f} to {df_windows['vertical_dominance'].max():.4f}\")\n",
    "print(f\"Original directional_variability range: {df_windows['directional_variability'].min():.4f} to {df_windows['directional_variability'].max():.4f}\")\n",
    "print(f\"Original burstiness range: {df_windows['burstiness'].min():.4f} to {df_windows['burstiness'].max():.4f}\")\n",
    "\n",
    "# Convert rule-based concepts to discrete labels (0, 0.5, 1.0)\n",
    "print(f\"\\n=== APPLYING DISCRETIZATION ===\")\n",
    "\n",
    "# Motion Intensity: Convert continuous values to discrete\n",
    "# NATURAL DISTRIBUTION - reflects real-world data patterns\n",
    "# Low (0.0): < 0.35, Medium (0.5): 0.35-0.45, High (1.0): > 0.45\n",
    "df_windows['motion_intensity'] = pd.cut(\n",
    "    df_windows['motion_intensity'], \n",
    "    bins=[-np.inf, 0.35, 0.45, np.inf], \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Vertical Dominance: Convert continuous values to discrete  \n",
    "# NATURAL DISTRIBUTION - reflects real-world data patterns\n",
    "# Low (0.0): < 0.2, Medium (0.5): 0.2-0.35, High (1.0): > 0.35\n",
    "df_windows['vertical_dominance'] = pd.cut(\n",
    "    df_windows['vertical_dominance'], \n",
    "    bins=[-np.inf, 0.2, 0.35, np.inf], \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Static Posture: Already binary (0.0 or 1.0), keep as is\n",
    "# No change needed for static_posture\n",
    "\n",
    "# Directional Variability: Convert continuous values to discrete\n",
    "# ORIGINAL WORKING THRESHOLDS (from your 75-78% performance)\n",
    "# Low (0.0): < 0.1, Medium (0.5): 0.1-0.2, High (1.0): > 0.2\n",
    "df_windows['directional_variability'] = pd.cut(\n",
    "    df_windows['directional_variability'], \n",
    "    bins=[-np.inf, 0.1, 0.2, np.inf], \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Burstiness: Convert continuous values to discrete\n",
    "# NATURAL DISTRIBUTION - reflects real-world data patterns\n",
    "# Low (0.0): < 0.15, Medium (0.5): 0.15-0.25, High (1.0): > 0.25\n",
    "df_windows['burstiness'] = pd.cut(\n",
    "    df_windows['burstiness'], \n",
    "    bins=[-np.inf, 0.15, 0.25, np.inf], \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Debug: Check discretized values\n",
    "print(f\"\\n=== AFTER DISCRETIZATION ===\")\n",
    "print(f\"Discretized motion_intensity: {df_windows['motion_intensity'].value_counts().sort_index()}\")\n",
    "print(f\"Discretized vertical_dominance: {df_windows['vertical_dominance'].value_counts().sort_index()}\")\n",
    "print(f\"Discretized directional_variability: {df_windows['directional_variability'].value_counts().sort_index()}\")\n",
    "print(f\"Discretized burstiness: {df_windows['burstiness'].value_counts().sort_index()}\")\n",
    "\n",
    "# Final check: Show all concept distributions\n",
    "print(f\"\\n=== FINAL CONCEPT DISTRIBUTIONS ===\")\n",
    "for concept in concept_columns:\n",
    "    if concept in df_windows.columns:\n",
    "        values = df_windows[concept].value_counts().sort_index()\n",
    "        print(f\"  {concept}: {dict(values)}\")\n",
    "\n",
    "print(f\"\\nDiscretization completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Window Extraction Functions\n",
    "\n",
    "**Purpose**: Extract sensor data windows with robust time matching and error handling.\n",
    "\n",
    "**Functions**:\n",
    "- `extract_window_robust()`: Extract single window with time tolerance\n",
    "- `extract_windows_robust()`: Extract all windows for 7 concepts\n",
    "- Handles missing data and time mismatches gracefully\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2662,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_window_robust(df_sensor, window_row, time_tolerance=0.5):\n",
    "    \"\"\"\n",
    "    Extract sensor data with time tolerance to handle mismatches.\n",
    "    \"\"\"\n",
    "    user = window_row['user']\n",
    "    activity = window_row['activity']\n",
    "    start_time = window_row['start_time']\n",
    "    end_time = window_row['end_time']\n",
    "    \n",
    "    # Get data for this user/activity\n",
    "    user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                  (df_sensor['activity'] == activity)].copy()\n",
    "    \n",
    "    if len(user_activity_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Find data within time window with tolerance\n",
    "    mask = ((user_activity_data['time_s'] >= start_time - time_tolerance) & \n",
    "            (user_activity_data['time_s'] <= end_time + time_tolerance))\n",
    "    \n",
    "    window_data = user_activity_data[mask]\n",
    "    \n",
    "    if len(window_data) < 10:  # Need minimum samples\n",
    "        return None\n",
    "    \n",
    "    # Extract sensor readings\n",
    "    sensor_data = window_data[['x-axis', 'y-axis', 'z-axis']].values\n",
    "    \n",
    "    # Pad or truncate to fixed length (e.g., 100 samples)\n",
    "    target_length = 100\n",
    "    if len(sensor_data) > target_length:\n",
    "        # Randomly sample if too long\n",
    "        indices = np.random.choice(len(sensor_data), target_length, replace=False)\n",
    "        sensor_data = sensor_data[indices]\n",
    "    elif len(sensor_data) < target_length:\n",
    "        # Pad with last value if too short\n",
    "        padding = np.tile(sensor_data[-1:], (target_length - len(sensor_data), 1))\n",
    "        sensor_data = np.vstack([sensor_data, padding])\n",
    "    \n",
    "    return sensor_data\n",
    "\n",
    "def extract_windows_robust(df_sensor, df_windows):\n",
    "    \"\"\"\n",
    "    Extract all windows with robust time matching for 7 concepts.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y_p = []  # periodicity\n",
    "    y_t = []  # temporal_stability\n",
    "    y_c = []  # coordination\n",
    "    y_mi = [] # motion_intensity\n",
    "    y_vd = [] # vertical_dominance\n",
    "    y_sp = [] # static_posture\n",
    "    y_dv = [] # directional_variability\n",
    "    y_b = []  # burstiness\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        window_data = extract_window_robust(df_sensor, window_row)\n",
    "        if window_data is not None:\n",
    "            X.append(window_data)\n",
    "            y_p.append(window_row['periodicity'])\n",
    "            y_t.append(window_row['temporal_stability'])\n",
    "            y_c.append(window_row['coordination'])\n",
    "            y_mi.append(window_row['motion_intensity'])\n",
    "            y_vd.append(window_row['vertical_dominance'])\n",
    "            y_sp.append(window_row['static_posture'])\n",
    "            y_dv.append(window_row['directional_variability'])\n",
    "            y_b.append(window_row['burstiness'])\n",
    "    \n",
    "    return np.array(X), np.array(y_p), np.array(y_t), np.array(y_c), np.array(y_mi), np.array(y_vd), np.array(y_sp), np.array(y_dv), np.array(y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation Functions\n",
    "\n",
    "**Purpose**: Create augmented versions of the dataset to improve model robustness.\n",
    "\n",
    "**Augmentation Types**:\n",
    "- **Jitter**: Add Gaussian noise to simulate sensor imperfections\n",
    "- **Scaling**: Scale magnitude to simulate different movement intensities  \n",
    "- **Rotation**: Rotate 3D data to simulate different phone orientations\n",
    "- **Factor**: 10x augmentation multiplier for robust training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2663,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_jitter(data, sigma=0.05):\n",
    "    \"\"\"Add random Gaussian noise to simulate sensor imperfections\"\"\"\n",
    "    return data + np.random.normal(0, sigma, data.shape)\n",
    "\n",
    "def augment_scaling(data, sigma=0.1):\n",
    "    \"\"\"Scale magnitude to simulate different movement intensities\"\"\"\n",
    "    # Handle different data shapes\n",
    "    if len(data.shape) == 3:\n",
    "        factor = np.random.normal(1.0, sigma, (data.shape[0], 1, data.shape[2]))\n",
    "    elif len(data.shape) == 2:\n",
    "        factor = np.random.normal(1.0, sigma, (data.shape[0], data.shape[1]))\n",
    "    else:\n",
    "        factor = np.random.normal(1.0, sigma, data.shape)\n",
    "    return data * factor\n",
    "\n",
    "def augment_rotation(data):\n",
    "    \"\"\"Rotate 3D data to simulate different phone orientations\"\"\"\n",
    "    angle = np.random.uniform(-np.pi/6, np.pi/6)  # ±30 degrees\n",
    "    cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_a, -sin_a, 0],\n",
    "        [sin_a, cos_a, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return np.dot(data, rotation_matrix.T)\n",
    "\n",
    "def augment_dataset(X, y_p, y_t, y_c, y_mi, y_vd, y_sp, y_dv, y_b, factor=10):\n",
    "    \"\"\"\n",
    "    Create augmented versions of the dataset for 7 concepts.\n",
    "    \n",
    "    Args:\n",
    "        X: Original data (n_samples, timesteps, 3)\n",
    "        y_p, y_t, y_c, y_mi, y_vd, y_sp, y_dv, y_b: Labels for seven concepts\n",
    "        factor: Augmentation multiplier (10 = 10x more data)\n",
    "    \n",
    "    Returns:\n",
    "        Augmented dataset with (factor+1) × original size\n",
    "    \"\"\"\n",
    "    n_original = len(X)\n",
    "    n_augmented = n_original * factor\n",
    "    \n",
    "    # Initialize augmented arrays\n",
    "    X_aug = np.zeros((n_augmented, X.shape[1], X.shape[2]))\n",
    "    y_p_aug = np.zeros(n_augmented)\n",
    "    y_t_aug = np.zeros(n_augmented)\n",
    "    y_c_aug = np.zeros(n_augmented)\n",
    "    y_mi_aug = np.zeros(n_augmented)\n",
    "    y_vd_aug = np.zeros(n_augmented)\n",
    "    y_sp_aug = np.zeros(n_augmented)\n",
    "    y_dv_aug = np.zeros(n_augmented)\n",
    "    y_b_aug = np.zeros(n_augmented)\n",
    "    \n",
    "    for i in range(n_augmented):\n",
    "        # Randomly select original sample\n",
    "        idx = np.random.randint(0, n_original)\n",
    "        \n",
    "        # Apply random augmentation\n",
    "        aug_type = np.random.choice(['jitter', 'scaling', 'rotation', 'none'])\n",
    "        \n",
    "        if aug_type == 'jitter':\n",
    "            X_aug[i] = augment_jitter(X[idx])\n",
    "        elif aug_type == 'scaling':\n",
    "            X_aug[i] = augment_scaling(X[idx])\n",
    "        elif aug_type == 'rotation':\n",
    "            X_aug[i] = augment_rotation(X[idx])\n",
    "        else:  # none\n",
    "            X_aug[i] = X[idx]\n",
    "        \n",
    "        # Copy labels\n",
    "        y_p_aug[i] = y_p[idx]\n",
    "        y_t_aug[i] = y_t[idx]\n",
    "        y_c_aug[i] = y_c[idx]\n",
    "        y_mi_aug[i] = y_mi[idx]\n",
    "        y_vd_aug[i] = y_vd[idx]\n",
    "        y_sp_aug[i] = y_sp[idx]\n",
    "        y_dv_aug[i] = y_dv[idx]\n",
    "        y_b_aug[i] = y_b[idx]\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    X_combined = np.vstack([X, X_aug])\n",
    "    y_p_combined = np.concatenate([y_p, y_p_aug])\n",
    "    y_t_combined = np.concatenate([y_t, y_t_aug])\n",
    "    y_c_combined = np.concatenate([y_c, y_c_aug])\n",
    "    y_mi_combined = np.concatenate([y_mi, y_mi_aug])\n",
    "    y_vd_combined = np.concatenate([y_vd, y_vd_aug])\n",
    "    y_sp_combined = np.concatenate([y_sp, y_sp_aug])\n",
    "    y_dv_combined = np.concatenate([y_dv, y_dv_aug])\n",
    "    y_b_combined = np.concatenate([y_b, y_b_aug])\n",
    "    \n",
    "    return X_combined, y_p_combined, y_t_combined, y_c_combined, y_mi_combined, y_vd_combined, y_sp_combined, y_dv_combined, y_b_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Architecture Definition\n",
    "\n",
    "**Purpose**: Define the optimized CNN architecture for 7 concepts.\n",
    "\n",
    "**Architecture**:\n",
    "- **2 Conv1D layers** (16 filters each) with Batch Normalization\n",
    "- **Global Average Pooling** for dimensionality reduction\n",
    "- **Dropout (0.4)** for regularization\n",
    "- **Contextual Learning**: Static posture context for motion concepts\n",
    "- **Multi-output heads** for each concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2664,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimized_cnn(input_shape, n_classes_p, n_classes_t, n_classes_c, n_classes_mi, n_classes_vd, n_classes_dv, n_classes_b, contextual_config):\n",
    "    \"\"\"\n",
    "    Optimized CNN using best parameters from grid search for 7 concepts:\n",
    "    - conv_filters_1: 16, conv_filters_2: 16\n",
    "    - dropout_rate: 0.4\n",
    "    - learning_rate: 0.001 (will be set in compile)\n",
    "    - batch_size: 32 (will be set in fit)\n",
    "    - Static posture used contextually based on contextual_config\n",
    "    \"\"\"\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Conv layer 1 (original: 16 filters)\n",
    "    x = layers.Conv1D(16, 3, activation='relu', padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    \n",
    "    # Conv layer 2 (original: 16 filters)\n",
    "    x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Dropout (original: 0.4)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Static posture context (binary feature)\n",
    "    static_context = layers.Dense(1, activation='sigmoid', name='static_context')(x)\n",
    "    \n",
    "    # Output heads for each concept - use contextual configuration\n",
    "    outputs = []\n",
    "    output_names = []\n",
    "    \n",
    "    # Independent concepts (don't use static context)\n",
    "    periodicity = layers.Dense(n_classes_p, activation='softmax', name='periodicity')(x)\n",
    "    temporal_stability = layers.Dense(n_classes_t, activation='softmax', name='temporal_stability')(x)\n",
    "    coordination = layers.Dense(n_classes_c, activation='softmax', name='coordination')(x)\n",
    "    directional_variability = layers.Dense(n_classes_dv, activation='softmax', name='directional_variability')(x)\n",
    "    burstiness = layers.Dense(n_classes_b, activation='softmax', name='burstiness')(x)\n",
    "    \n",
    "    outputs.extend([periodicity, temporal_stability, coordination, directional_variability, burstiness])\n",
    "    output_names.extend(['periodicity', 'temporal_stability', 'coordination', 'directional_variability', 'burstiness'])\n",
    "    \n",
    "    # Contextual concepts (use static context if configured)\n",
    "    if contextual_config.get('motion_intensity', False):\n",
    "        motion_intensity_input = layers.Concatenate()([x, static_context])\n",
    "        motion_intensity = layers.Dense(n_classes_mi, activation='softmax', name='motion_intensity')(motion_intensity_input)\n",
    "    else:\n",
    "        motion_intensity = layers.Dense(n_classes_mi, activation='softmax', name='motion_intensity')(x)\n",
    "    \n",
    "    if contextual_config.get('vertical_dominance', False):\n",
    "        vertical_dominance_input = layers.Concatenate()([x, static_context])\n",
    "        vertical_dominance = layers.Dense(n_classes_vd, activation='softmax', name='vertical_dominance')(vertical_dominance_input)\n",
    "    else:\n",
    "        vertical_dominance = layers.Dense(n_classes_vd, activation='softmax', name='vertical_dominance')(x)\n",
    "    \n",
    "    outputs.extend([motion_intensity, vertical_dominance])\n",
    "    output_names.extend(['motion_intensity', 'vertical_dominance'])\n",
    "    \n",
    "    # Add static context output\n",
    "    outputs.append(static_context)\n",
    "    output_names.append('static_context')\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=outputs)\n",
    "    \n",
    "    print(f\"Model architecture:\")\n",
    "    print(f\"  Independent concepts: {[name for name, uses_context in contextual_config.items() if not uses_context]}\")\n",
    "    print(f\"  Contextual concepts: {[name for name, uses_context in contextual_config.items() if uses_context]}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Extraction\n",
    "\n",
    "**Purpose**: Extract sensor windows for all 7 concepts with robust error handling.\n",
    "\n",
    "**Output**: \n",
    "- X: Sensor data (n_windows, timesteps, 3)\n",
    "- y_p, y_t, y_c, y_mi, y_vd, y_dv, y_b, y_sp: Labels for 7 concepts + static context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting windows...\n",
      "Extracted 150 windows\n",
      "Window shape: (150, 100, 3)\n",
      "Label distributions:\n",
      "  Periodicity: [125  25]\n",
      "  Temporal Stability: [99 51]\n",
      "  Coordination: [80 70]\n",
      "  Motion Intensity: [148   2]\n",
      "  Vertical Dominance: [137  13]\n",
      "  Static Posture: [147   3]\n",
      "  Directional Variability: [114  36]\n",
      "  Burstiness: [64 86]\n"
     ]
    }
   ],
   "source": [
    "# Extract windows\n",
    "print(\"Extracting windows...\")\n",
    "X, y_p, y_t, y_c, y_mi, y_vd, y_sp, y_dv, y_b = extract_windows_robust(df_sensor, df_windows)\n",
    "\n",
    "print(f\"Extracted {len(X)} windows\")\n",
    "print(f\"Window shape: {X.shape}\")\n",
    "print(f\"Label distributions:\")\n",
    "print(f\"  Periodicity: {np.bincount(y_p.astype(int))}\")\n",
    "print(f\"  Temporal Stability: {np.bincount(y_t.astype(int))}\")\n",
    "print(f\"  Coordination: {np.bincount(y_c.astype(int))}\")\n",
    "print(f\"  Motion Intensity: {np.bincount(y_mi.astype(int))}\")\n",
    "print(f\"  Vertical Dominance: {np.bincount(y_vd.astype(int))}\")\n",
    "print(f\"  Static Posture: {np.bincount(y_sp.astype(int))}\")\n",
    "print(f\"  Directional Variability: {np.bincount(y_dv.astype(int))}\")\n",
    "print(f\"  Burstiness: {np.bincount(y_b.astype(int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split\n",
    "\n",
    "**Purpose**: Split data into training and testing sets with proper stratification.\n",
    "\n",
    "**Split**: 75% training, 25% testing\n",
    "**Static Context**: Convert static posture to binary context labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Train: 112 windows\n",
      "Test: 38 windows\n",
      "Static context train: [110   2]\n",
      "Static context test: [37  1]\n"
     ]
    }
   ],
   "source": [
    "# Random shuffle split (75% train, 25% test)\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_p_train, y_p_test, y_t_train, y_t_test, y_c_train, y_c_test, y_mi_train, y_mi_test, y_vd_train, y_vd_test, y_sp_train, y_sp_test, y_dv_train, y_dv_test, y_b_train, y_b_test = train_test_split(\n",
    "    X, y_p, y_t, y_c, y_mi, y_vd, y_sp, y_dv, y_b, test_size=0.25, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "# Convert static posture to binary context (0.0 -> 0, 1.0 -> 1)\n",
    "y_sp_context_train = (y_sp_train > 0).astype(int)\n",
    "y_sp_context_test = (y_sp_test > 0).astype(int)\n",
    "\n",
    "print(f\"Train: {len(X_train)} windows\")\n",
    "print(f\"Test: {len(X_test)} windows\")\n",
    "print(f\"Static context train: {np.bincount(y_sp_context_train)}\")\n",
    "print(f\"Static context test: {np.bincount(y_sp_context_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Augmentation\n",
    "\n",
    "**Purpose**: Apply augmentation to training data to increase dataset size and robustness.\n",
    "\n",
    "**Process**:\n",
    "- Apply jitter, scaling, and rotation augmentations\n",
    "- 10x augmentation factor (1,232 total training samples)\n",
    "- Convert static posture to binary context for augmented data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training data...\n",
      "Original train: 112 windows\n",
      "Augmented train: 2352 windows\n",
      "Augmentation factor: 21.0x\n",
      "Static context train aug: [2309   43]\n"
     ]
    }
   ],
   "source": [
    "# Apply augmentation\n",
    "print(\"Augmenting training data...\")\n",
    "X_train_aug, y_p_train_aug, y_t_train_aug, y_c_train_aug, y_mi_train_aug, y_vd_train_aug, y_sp_train_aug, y_dv_train_aug, y_b_train_aug = augment_dataset(\n",
    "    X_train, y_p_train, y_t_train, y_c_train, y_mi_train, y_vd_train, y_sp_train, y_dv_train, y_b_train, factor=20\n",
    ")\n",
    "\n",
    "# Convert static posture to binary context for augmented data\n",
    "y_sp_context_train_aug = (y_sp_train_aug > 0).astype(int)\n",
    "\n",
    "print(f\"Original train: {len(X_train)} windows\")\n",
    "print(f\"Augmented train: {len(X_train_aug)} windows\")\n",
    "print(f\"Augmentation factor: {len(X_train_aug) / len(X_train):.1f}x\")\n",
    "print(f\"Static context train aug: {np.bincount(y_sp_context_train_aug)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Label Conversion to Categorical\n",
    "\n",
    "**Purpose**: Convert discrete labels to categorical format for multi-class classification.\n",
    "\n",
    "**Process**:\n",
    "- Convert all concept labels to 3-class categorical format\n",
    "- Static context remains as binary (0 or 1)\n",
    "- Prepare labels for model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels converted to categorical format\n",
      "Static context train shape: (2352,)\n",
      "Static context test shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to categorical\n",
    "y_p_train_cat = to_categorical(y_p_train_aug * 2, num_classes=3)\n",
    "y_t_train_cat = to_categorical(y_t_train_aug * 2, num_classes=3)\n",
    "y_c_train_cat = to_categorical(y_c_train_aug * 2, num_classes=3)\n",
    "y_mi_train_cat = to_categorical(y_mi_train_aug * 2, num_classes=3)\n",
    "y_vd_train_cat = to_categorical(y_vd_train_aug * 2, num_classes=3)\n",
    "y_dv_train_cat = to_categorical(y_dv_train_aug * 2, num_classes=3)\n",
    "y_b_train_cat = to_categorical(y_b_train_aug * 2, num_classes=3)\n",
    "\n",
    "y_p_test_cat = to_categorical(y_p_test * 2, num_classes=3)\n",
    "y_t_test_cat = to_categorical(y_t_test * 2, num_classes=3)\n",
    "y_c_test_cat = to_categorical(y_c_test * 2, num_classes=3)\n",
    "y_mi_test_cat = to_categorical(y_mi_test * 2, num_classes=3)\n",
    "y_vd_test_cat = to_categorical(y_vd_test * 2, num_classes=3)\n",
    "y_dv_test_cat = to_categorical(y_dv_test * 2, num_classes=3)\n",
    "y_b_test_cat = to_categorical(y_b_test * 2, num_classes=3)\n",
    "\n",
    "# Static context is already binary (0 or 1), no need for categorical conversion\n",
    "y_sp_context_train_cat = y_sp_context_train_aug.astype(float)\n",
    "y_sp_context_test_cat = y_sp_context_test.astype(float)\n",
    "\n",
    "print(\"Labels converted to categorical format\")\n",
    "print(f\"Static context train shape: {y_sp_context_train_cat.shape}\")\n",
    "print(f\"Static context test shape: {y_sp_context_test_cat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Building and Compilation\n",
    "\n",
    "**Purpose**: Build and compile the CNN model for 7 concepts.\n",
    "\n",
    "**Configuration**:\n",
    "- **Optimizer**: Adam (learning_rate=0.001)\n",
    "- **Loss Functions**: Categorical crossentropy for concepts, binary crossentropy for static context\n",
    "- **Loss Weights**: Balanced weights for all concepts\n",
    "- **Metrics**: Accuracy for all outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model architecture:\n",
      "  Independent concepts: ['periodicity', 'temporal_stability', 'coordination', 'directional_variability', 'burstiness']\n",
      "  Contextual concepts: ['motion_intensity', 'vertical_dominance']\n",
      "Model parameters: 1,452\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_163\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_163\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_163     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_326 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ input_layer_163[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_326[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_163   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_327 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │ max_pooling1d_16… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_327[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_172         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_context      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dropout_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_192     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ static_context[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_193     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ static_context[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ periodicity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ temporal_stability  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coordination        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ directional_variab… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ burstiness (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ motion_intensity    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │ concatenate_192[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vertical_dominance  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │ concatenate_193[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_163     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_326 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │        \u001b[38;5;34m160\u001b[0m │ input_layer_163[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_326[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_163   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_327 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │        \u001b[38;5;34m784\u001b[0m │ max_pooling1d_16… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m64\u001b[0m │ conv1d_327[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_172         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_context      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dropout_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_192     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ static_context[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_193     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ static_context[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ periodicity (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ temporal_stability  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coordination        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ directional_variab… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ burstiness (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ motion_intensity    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m54\u001b[0m │ concatenate_192[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vertical_dominance  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m54\u001b[0m │ concatenate_193[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,452</span> (5.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,452\u001b[0m (5.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,388</span> (5.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,388\u001b[0m (5.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build and compile model\n",
    "print(\"Building model...\")\n",
    "# Build model with contextual configuration\n",
    "model = build_optimized_cnn(\n",
    "    input_shape=(X_train_aug.shape[1], X_train_aug.shape[2]),\n",
    "    n_classes_p=3, n_classes_t=3, n_classes_c=3, n_classes_mi=3, n_classes_vd=3, n_classes_dv=3, n_classes_b=3,\n",
    "    contextual_config=contextual_config\n",
    ")\n",
    "\n",
    "# Compile with appropriate loss weights\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        'periodicity': 'categorical_crossentropy',\n",
    "        'temporal_stability': 'categorical_crossentropy',\n",
    "        'coordination': 'categorical_crossentropy',\n",
    "        'motion_intensity': 'categorical_crossentropy',\n",
    "        'vertical_dominance': 'categorical_crossentropy',\n",
    "        'directional_variability': 'categorical_crossentropy',\n",
    "        'burstiness': 'categorical_crossentropy',\n",
    "        'static_context': 'binary_crossentropy',\n",
    "    },\n",
    "    loss_weights={'periodicity': 1.0, 'temporal_stability': 1.0, 'coordination': 1.0, 'motion_intensity': 1.0, 'vertical_dominance': 1.0, 'directional_variability': 1.0, 'burstiness': 1.0, 'static_context': 0.5},\n",
    "    metrics={\n",
    "        'periodicity': ['accuracy'],\n",
    "        'temporal_stability': ['accuracy'],\n",
    "        'coordination': ['accuracy'],\n",
    "        'motion_intensity': ['accuracy'],\n",
    "        'vertical_dominance': ['accuracy'],\n",
    "        'directional_variability': ['accuracy'],\n",
    "        'burstiness': ['accuracy'],\n",
    "        'static_context': ['accuracy'],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {model.count_params():,}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Training\n",
    "\n",
    "**Purpose**: Train the CNN model with early stopping and learning rate reduction.\n",
    "\n",
    "**Training Configuration**:\n",
    "- **Epochs**: 200 (with early stopping)\n",
    "- **Batch Size**: 32\n",
    "- **Callbacks**: EarlyStopping (patience=10), ReduceLROnPlateau (patience=5)\n",
    "- **Validation**: 25% of data for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - burstiness_accuracy: 0.3916 - burstiness_loss: 1.1952 - coordination_accuracy: 0.5374 - coordination_loss: 0.9938 - directional_variability_accuracy: 0.5340 - directional_variability_loss: 0.9833 - loss: 7.9819 - motion_intensity_accuracy: 0.4817 - motion_intensity_loss: 1.0474 - periodicity_accuracy: 0.5047 - periodicity_loss: 1.0518 - static_context_accuracy: 0.5825 - static_context_loss: 0.7194 - temporal_stability_accuracy: 0.3491 - temporal_stability_loss: 1.2215 - vertical_dominance_accuracy: 0.4230 - vertical_dominance_loss: 1.1267 - val_burstiness_accuracy: 0.4474 - val_burstiness_loss: 0.9215 - val_coordination_accuracy: 0.4211 - val_coordination_loss: 1.1708 - val_directional_variability_accuracy: 0.3947 - val_directional_variability_loss: 1.2402 - val_loss: 8.1859 - val_motion_intensity_accuracy: 0.5263 - val_motion_intensity_loss: 0.9477 - val_periodicity_accuracy: 0.3158 - val_periodicity_loss: 1.1788 - val_static_context_accuracy: 0.1579 - val_static_context_loss: 0.9842 - val_temporal_stability_accuracy: 0.2632 - val_temporal_stability_loss: 1.0845 - val_vertical_dominance_accuracy: 0.6842 - val_vertical_dominance_loss: 0.8467 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.4762 - burstiness_loss: 1.0020 - coordination_accuracy: 0.6820 - coordination_loss: 0.8465 - directional_variability_accuracy: 0.7105 - directional_variability_loss: 0.7853 - loss: 6.4363 - motion_intensity_accuracy: 0.5634 - motion_intensity_loss: 0.8874 - periodicity_accuracy: 0.6403 - periodicity_loss: 0.8490 - static_context_accuracy: 0.7088 - static_context_loss: 0.6080 - temporal_stability_accuracy: 0.6327 - temporal_stability_loss: 0.8458 - vertical_dominance_accuracy: 0.5795 - vertical_dominance_loss: 0.9108 - val_burstiness_accuracy: 0.5789 - val_burstiness_loss: 0.8471 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.8392 - val_directional_variability_accuracy: 0.6842 - val_directional_variability_loss: 0.6672 - val_loss: 6.2019 - val_motion_intensity_accuracy: 0.6579 - val_motion_intensity_loss: 0.6700 - val_periodicity_accuracy: 0.6316 - val_periodicity_loss: 0.8005 - val_static_context_accuracy: 0.6053 - val_static_context_loss: 0.5974 - val_temporal_stability_accuracy: 0.5526 - val_temporal_stability_loss: 0.8174 - val_vertical_dominance_accuracy: 0.7632 - val_vertical_dominance_loss: 0.7088 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.5527 - burstiness_loss: 0.8987 - coordination_accuracy: 0.7181 - coordination_loss: 0.7604 - directional_variability_accuracy: 0.8227 - directional_variability_loss: 0.6394 - loss: 5.7142 - motion_intensity_accuracy: 0.5799 - motion_intensity_loss: 0.8572 - periodicity_accuracy: 0.6607 - periodicity_loss: 0.7761 - static_context_accuracy: 0.8282 - static_context_loss: 0.5171 - temporal_stability_accuracy: 0.7326 - temporal_stability_loss: 0.7107 - vertical_dominance_accuracy: 0.6543 - vertical_dominance_loss: 0.8050 - val_burstiness_accuracy: 0.6053 - val_burstiness_loss: 0.8367 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.7394 - val_directional_variability_accuracy: 0.8947 - val_directional_variability_loss: 0.4459 - val_loss: 5.4433 - val_motion_intensity_accuracy: 0.6842 - val_motion_intensity_loss: 0.5995 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.6537 - val_static_context_accuracy: 0.8684 - val_static_context_loss: 0.4554 - val_temporal_stability_accuracy: 0.6316 - val_temporal_stability_loss: 0.6642 - val_vertical_dominance_accuracy: 0.7368 - val_vertical_dominance_loss: 0.6992 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6059 - burstiness_loss: 0.8372 - coordination_accuracy: 0.7258 - coordination_loss: 0.7260 - directional_variability_accuracy: 0.8644 - directional_variability_loss: 0.5057 - loss: 5.2256 - motion_intensity_accuracy: 0.6118 - motion_intensity_loss: 0.8202 - periodicity_accuracy: 0.6624 - periodicity_loss: 0.7571 - static_context_accuracy: 0.8929 - static_context_loss: 0.4207 - temporal_stability_accuracy: 0.7789 - temporal_stability_loss: 0.6174 - vertical_dominance_accuracy: 0.6939 - vertical_dominance_loss: 0.7532 - val_burstiness_accuracy: 0.6053 - val_burstiness_loss: 0.7849 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.6989 - val_directional_variability_accuracy: 0.8421 - val_directional_variability_loss: 0.3362 - val_loss: 5.0763 - val_motion_intensity_accuracy: 0.6842 - val_motion_intensity_loss: 0.6059 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.5965 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.3354 - val_temporal_stability_accuracy: 0.6316 - val_temporal_stability_loss: 0.5882 - val_vertical_dominance_accuracy: 0.7632 - val_vertical_dominance_loss: 0.7495 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6293 - burstiness_loss: 0.7851 - coordination_accuracy: 0.7360 - coordination_loss: 0.7083 - directional_variability_accuracy: 0.8929 - directional_variability_loss: 0.4111 - loss: 4.8390 - motion_intensity_accuracy: 0.6156 - motion_intensity_loss: 0.7992 - periodicity_accuracy: 0.6705 - periodicity_loss: 0.7180 - static_context_accuracy: 0.9379 - static_context_loss: 0.3338 - temporal_stability_accuracy: 0.8129 - temporal_stability_loss: 0.5573 - vertical_dominance_accuracy: 0.7045 - vertical_dominance_loss: 0.6977 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.7409 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.6727 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2762 - val_loss: 4.7555 - val_motion_intensity_accuracy: 0.6842 - val_motion_intensity_loss: 0.6036 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.5335 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.2555 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.5231 - val_vertical_dominance_accuracy: 0.8421 - val_vertical_dominance_loss: 0.7155 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6352 - burstiness_loss: 0.7569 - coordination_accuracy: 0.7500 - coordination_loss: 0.6608 - directional_variability_accuracy: 0.8941 - directional_variability_loss: 0.3497 - loss: 4.5199 - motion_intensity_accuracy: 0.6531 - motion_intensity_loss: 0.7560 - periodicity_accuracy: 0.6952 - periodicity_loss: 0.6903 - static_context_accuracy: 0.9562 - static_context_loss: 0.2631 - temporal_stability_accuracy: 0.8304 - temporal_stability_loss: 0.5021 - vertical_dominance_accuracy: 0.7100 - vertical_dominance_loss: 0.6769 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.7142 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.6544 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2519 - val_loss: 4.6144 - val_motion_intensity_accuracy: 0.6579 - val_motion_intensity_loss: 0.6143 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.5141 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.1971 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.4959 - val_vertical_dominance_accuracy: 0.8684 - val_vertical_dominance_loss: 0.7160 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6501 - burstiness_loss: 0.7467 - coordination_accuracy: 0.7411 - coordination_loss: 0.6598 - directional_variability_accuracy: 0.9124 - directional_variability_loss: 0.2937 - loss: 4.3862 - motion_intensity_accuracy: 0.6577 - motion_intensity_loss: 0.7402 - periodicity_accuracy: 0.6986 - periodicity_loss: 0.6755 - static_context_accuracy: 0.9630 - static_context_loss: 0.2217 - temporal_stability_accuracy: 0.8333 - temporal_stability_loss: 0.4912 - vertical_dominance_accuracy: 0.7109 - vertical_dominance_loss: 0.6718 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6943 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.6385 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2475 - val_loss: 4.5107 - val_motion_intensity_accuracy: 0.6842 - val_motion_intensity_loss: 0.6186 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4972 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.1539 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.4717 - val_vertical_dominance_accuracy: 0.9211 - val_vertical_dominance_loss: 0.7267 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6433 - burstiness_loss: 0.7405 - coordination_accuracy: 0.7589 - coordination_loss: 0.6316 - directional_variability_accuracy: 0.9137 - directional_variability_loss: 0.2794 - loss: 4.2563 - motion_intensity_accuracy: 0.6777 - motion_intensity_loss: 0.7235 - periodicity_accuracy: 0.7096 - periodicity_loss: 0.6555 - static_context_accuracy: 0.9677 - static_context_loss: 0.1987 - temporal_stability_accuracy: 0.8308 - temporal_stability_loss: 0.4755 - vertical_dominance_accuracy: 0.7143 - vertical_dominance_loss: 0.6505 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6592 - val_coordination_accuracy: 0.5789 - val_coordination_loss: 0.6623 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2534 - val_loss: 4.5391 - val_motion_intensity_accuracy: 0.6842 - val_motion_intensity_loss: 0.6345 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4765 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.1282 - val_temporal_stability_accuracy: 0.6579 - val_temporal_stability_loss: 0.4717 - val_vertical_dominance_accuracy: 0.7368 - val_vertical_dominance_loss: 0.8104 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6446 - burstiness_loss: 0.7244 - coordination_accuracy: 0.7521 - coordination_loss: 0.6327 - directional_variability_accuracy: 0.9120 - directional_variability_loss: 0.2604 - loss: 4.1688 - motion_intensity_accuracy: 0.6913 - motion_intensity_loss: 0.6994 - periodicity_accuracy: 0.7079 - periodicity_loss: 0.6471 - static_context_accuracy: 0.9613 - static_context_loss: 0.1804 - temporal_stability_accuracy: 0.8346 - temporal_stability_loss: 0.4808 - vertical_dominance_accuracy: 0.7202 - vertical_dominance_loss: 0.6325 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6722 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.6596 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2434 - val_loss: 4.5145 - val_motion_intensity_accuracy: 0.6842 - val_motion_intensity_loss: 0.6256 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4755 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.1164 - val_temporal_stability_accuracy: 0.6579 - val_temporal_stability_loss: 0.4695 - val_vertical_dominance_accuracy: 0.8421 - val_vertical_dominance_loss: 0.8005 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6679 - burstiness_loss: 0.7043 - coordination_accuracy: 0.7466 - coordination_loss: 0.6135 - directional_variability_accuracy: 0.9162 - directional_variability_loss: 0.2601 - loss: 4.0662 - motion_intensity_accuracy: 0.6913 - motion_intensity_loss: 0.6923 - periodicity_accuracy: 0.7181 - periodicity_loss: 0.6297 - static_context_accuracy: 0.9681 - static_context_loss: 0.1578 - temporal_stability_accuracy: 0.8367 - temporal_stability_loss: 0.4612 - vertical_dominance_accuracy: 0.7113 - vertical_dominance_loss: 0.6240 - val_burstiness_accuracy: 0.7105 - val_burstiness_loss: 0.6560 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.6203 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2692 - val_loss: 4.4438 - val_motion_intensity_accuracy: 0.6842 - val_motion_intensity_loss: 0.6290 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4620 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0978 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4433 - val_vertical_dominance_accuracy: 0.8421 - val_vertical_dominance_loss: 0.8312 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6654 - burstiness_loss: 0.6964 - coordination_accuracy: 0.7521 - coordination_loss: 0.6147 - directional_variability_accuracy: 0.9188 - directional_variability_loss: 0.2436 - loss: 4.0299 - motion_intensity_accuracy: 0.7020 - motion_intensity_loss: 0.6901 - periodicity_accuracy: 0.7262 - periodicity_loss: 0.6245 - static_context_accuracy: 0.9685 - static_context_loss: 0.1535 - temporal_stability_accuracy: 0.8359 - temporal_stability_loss: 0.4528 - vertical_dominance_accuracy: 0.7134 - vertical_dominance_loss: 0.6344 - val_burstiness_accuracy: 0.7368 - val_burstiness_loss: 0.6333 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.6224 - val_directional_variability_accuracy: 0.8421 - val_directional_variability_loss: 0.2672 - val_loss: 4.4331 - val_motion_intensity_accuracy: 0.7105 - val_motion_intensity_loss: 0.6410 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4568 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0948 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.4548 - val_vertical_dominance_accuracy: 0.8947 - val_vertical_dominance_loss: 0.8097 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6679 - burstiness_loss: 0.6931 - coordination_accuracy: 0.7611 - coordination_loss: 0.5920 - directional_variability_accuracy: 0.9269 - directional_variability_loss: 0.2297 - loss: 3.9183 - motion_intensity_accuracy: 0.7117 - motion_intensity_loss: 0.6649 - periodicity_accuracy: 0.7228 - periodicity_loss: 0.6097 - static_context_accuracy: 0.9711 - static_context_loss: 0.1492 - temporal_stability_accuracy: 0.8440 - temporal_stability_loss: 0.4465 - vertical_dominance_accuracy: 0.7330 - vertical_dominance_loss: 0.6089 - val_burstiness_accuracy: 0.7105 - val_burstiness_loss: 0.6327 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.6023 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2586 - val_loss: 4.3378 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6256 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4630 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0868 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.4202 - val_vertical_dominance_accuracy: 0.8421 - val_vertical_dominance_loss: 0.8268 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6739 - burstiness_loss: 0.6825 - coordination_accuracy: 0.7674 - coordination_loss: 0.5806 - directional_variability_accuracy: 0.9260 - directional_variability_loss: 0.2246 - loss: 3.8752 - motion_intensity_accuracy: 0.7126 - motion_intensity_loss: 0.6507 - periodicity_accuracy: 0.7275 - periodicity_loss: 0.6149 - static_context_accuracy: 0.9707 - static_context_loss: 0.1369 - temporal_stability_accuracy: 0.8435 - temporal_stability_loss: 0.4379 - vertical_dominance_accuracy: 0.7351 - vertical_dominance_loss: 0.6116 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6540 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.6009 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2535 - val_loss: 4.3218 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6051 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4690 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0880 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.4173 - val_vertical_dominance_accuracy: 0.8421 - val_vertical_dominance_loss: 0.8152 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6781 - burstiness_loss: 0.6649 - coordination_accuracy: 0.7721 - coordination_loss: 0.5624 - directional_variability_accuracy: 0.9396 - directional_variability_loss: 0.2102 - loss: 3.7768 - motion_intensity_accuracy: 0.7296 - motion_intensity_loss: 0.6392 - periodicity_accuracy: 0.7338 - periodicity_loss: 0.6046 - static_context_accuracy: 0.9732 - static_context_loss: 0.1324 - temporal_stability_accuracy: 0.8452 - temporal_stability_loss: 0.4242 - vertical_dominance_accuracy: 0.7304 - vertical_dominance_loss: 0.6051 - val_burstiness_accuracy: 0.7368 - val_burstiness_loss: 0.6511 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.5786 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2657 - val_loss: 4.2894 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6178 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4641 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0818 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4116 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.8352 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6747 - burstiness_loss: 0.6757 - coordination_accuracy: 0.7683 - coordination_loss: 0.5641 - directional_variability_accuracy: 0.9354 - directional_variability_loss: 0.2116 - loss: 3.7765 - motion_intensity_accuracy: 0.7351 - motion_intensity_loss: 0.6361 - periodicity_accuracy: 0.7304 - periodicity_loss: 0.6107 - static_context_accuracy: 0.9745 - static_context_loss: 0.1285 - temporal_stability_accuracy: 0.8503 - temporal_stability_loss: 0.4213 - vertical_dominance_accuracy: 0.7372 - vertical_dominance_loss: 0.5979 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6486 - val_coordination_accuracy: 0.5789 - val_coordination_loss: 0.6639 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2520 - val_loss: 4.4336 - val_motion_intensity_accuracy: 0.7105 - val_motion_intensity_loss: 0.6459 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4720 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0799 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.4282 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.8961 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6807 - burstiness_loss: 0.6705 - coordination_accuracy: 0.7717 - coordination_loss: 0.5637 - directional_variability_accuracy: 0.9298 - directional_variability_loss: 0.2119 - loss: 3.7800 - motion_intensity_accuracy: 0.7398 - motion_intensity_loss: 0.6379 - periodicity_accuracy: 0.7313 - periodicity_loss: 0.6066 - static_context_accuracy: 0.9732 - static_context_loss: 0.1277 - temporal_stability_accuracy: 0.8431 - temporal_stability_loss: 0.4222 - vertical_dominance_accuracy: 0.7351 - vertical_dominance_loss: 0.6059 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6578 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.5674 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2520 - val_loss: 4.2341 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6161 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4585 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0791 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.3959 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.8643 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6718 - burstiness_loss: 0.6706 - coordination_accuracy: 0.7836 - coordination_loss: 0.5489 - directional_variability_accuracy: 0.9362 - directional_variability_loss: 0.2034 - loss: 3.7094 - motion_intensity_accuracy: 0.7304 - motion_intensity_loss: 0.6266 - periodicity_accuracy: 0.7266 - periodicity_loss: 0.6059 - static_context_accuracy: 0.9719 - static_context_loss: 0.1351 - temporal_stability_accuracy: 0.8597 - temporal_stability_loss: 0.3963 - vertical_dominance_accuracy: 0.7496 - vertical_dominance_loss: 0.5901 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6429 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.6267 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2112 - val_loss: 4.2106 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6266 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4554 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0741 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.3860 - val_vertical_dominance_accuracy: 0.8421 - val_vertical_dominance_loss: 0.8752 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6722 - burstiness_loss: 0.6733 - coordination_accuracy: 0.7840 - coordination_loss: 0.5510 - directional_variability_accuracy: 0.9281 - directional_variability_loss: 0.2068 - loss: 3.7192 - motion_intensity_accuracy: 0.7419 - motion_intensity_loss: 0.6320 - periodicity_accuracy: 0.7432 - periodicity_loss: 0.5820 - static_context_accuracy: 0.9741 - static_context_loss: 0.1237 - temporal_stability_accuracy: 0.8546 - temporal_stability_loss: 0.4159 - vertical_dominance_accuracy: 0.7385 - vertical_dominance_loss: 0.5946 - val_burstiness_accuracy: 0.7105 - val_burstiness_loss: 0.6339 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5450 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2492 - val_loss: 4.1918 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6109 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4701 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0748 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3963 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.8673 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6794 - burstiness_loss: 0.6556 - coordination_accuracy: 0.7798 - coordination_loss: 0.5422 - directional_variability_accuracy: 0.9307 - directional_variability_loss: 0.2047 - loss: 3.6598 - motion_intensity_accuracy: 0.7440 - motion_intensity_loss: 0.6225 - periodicity_accuracy: 0.7440 - periodicity_loss: 0.5819 - static_context_accuracy: 0.9707 - static_context_loss: 0.1284 - temporal_stability_accuracy: 0.8576 - temporal_stability_loss: 0.4017 - vertical_dominance_accuracy: 0.7398 - vertical_dominance_loss: 0.5858 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6597 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.6027 - val_directional_variability_accuracy: 0.8421 - val_directional_variability_loss: 0.2568 - val_loss: 4.3331 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6513 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.4722 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0742 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4079 - val_vertical_dominance_accuracy: 0.8158 - val_vertical_dominance_loss: 0.9157 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6667 - burstiness_loss: 0.6627 - coordination_accuracy: 0.7866 - coordination_loss: 0.5316 - directional_variability_accuracy: 0.9379 - directional_variability_loss: 0.1929 - loss: 3.6334 - motion_intensity_accuracy: 0.7330 - motion_intensity_loss: 0.6165 - periodicity_accuracy: 0.7266 - periodicity_loss: 0.5904 - static_context_accuracy: 0.9690 - static_context_loss: 0.1275 - temporal_stability_accuracy: 0.8605 - temporal_stability_loss: 0.3919 - vertical_dominance_accuracy: 0.7496 - vertical_dominance_loss: 0.5904 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6610 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5738 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2283 - val_loss: 4.2213 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6372 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4789 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0727 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3806 - val_vertical_dominance_accuracy: 0.8421 - val_vertical_dominance_loss: 0.9014 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6803 - burstiness_loss: 0.6536 - coordination_accuracy: 0.7955 - coordination_loss: 0.5003 - directional_variability_accuracy: 0.9315 - directional_variability_loss: 0.2017 - loss: 3.5671 - motion_intensity_accuracy: 0.7526 - motion_intensity_loss: 0.6100 - periodicity_accuracy: 0.7415 - periodicity_loss: 0.5726 - static_context_accuracy: 0.9724 - static_context_loss: 0.1223 - temporal_stability_accuracy: 0.8605 - temporal_stability_loss: 0.3862 - vertical_dominance_accuracy: 0.7445 - vertical_dominance_loss: 0.5824 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6562 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5726 - val_directional_variability_accuracy: 0.8421 - val_directional_variability_loss: 0.2337 - val_loss: 4.2819 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6621 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4578 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0710 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4005 - val_vertical_dominance_accuracy: 0.8158 - val_vertical_dominance_loss: 0.9410 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6875 - burstiness_loss: 0.6572 - coordination_accuracy: 0.7968 - coordination_loss: 0.5002 - directional_variability_accuracy: 0.9273 - directional_variability_loss: 0.2005 - loss: 3.5683 - motion_intensity_accuracy: 0.7445 - motion_intensity_loss: 0.6148 - periodicity_accuracy: 0.7474 - periodicity_loss: 0.5759 - static_context_accuracy: 0.9724 - static_context_loss: 0.1192 - temporal_stability_accuracy: 0.8639 - temporal_stability_loss: 0.3778 - vertical_dominance_accuracy: 0.7415 - vertical_dominance_loss: 0.5848 - val_burstiness_accuracy: 0.6316 - val_burstiness_loss: 0.6745 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.5835 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2423 - val_loss: 4.2477 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6567 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4284 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0672 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3759 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9107 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6841 - burstiness_loss: 0.6400 - coordination_accuracy: 0.8010 - coordination_loss: 0.4951 - directional_variability_accuracy: 0.9349 - directional_variability_loss: 0.1784 - loss: 3.5189 - motion_intensity_accuracy: 0.7594 - motion_intensity_loss: 0.5987 - periodicity_accuracy: 0.7381 - periodicity_loss: 0.5825 - static_context_accuracy: 0.9732 - static_context_loss: 0.1170 - temporal_stability_accuracy: 0.8652 - temporal_stability_loss: 0.3774 - vertical_dominance_accuracy: 0.7457 - vertical_dominance_loss: 0.5870 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6482 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.6242 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2213 - val_loss: 4.2523 - val_motion_intensity_accuracy: 0.7895 - val_motion_intensity_loss: 0.6424 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4379 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0666 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.3967 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9541 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6820 - burstiness_loss: 0.6601 - coordination_accuracy: 0.8074 - coordination_loss: 0.4842 - directional_variability_accuracy: 0.9375 - directional_variability_loss: 0.1796 - loss: 3.5004 - motion_intensity_accuracy: 0.7628 - motion_intensity_loss: 0.5997 - periodicity_accuracy: 0.7428 - periodicity_loss: 0.5741 - static_context_accuracy: 0.9736 - static_context_loss: 0.1182 - temporal_stability_accuracy: 0.8750 - temporal_stability_loss: 0.3681 - vertical_dominance_accuracy: 0.7462 - vertical_dominance_loss: 0.5777 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6764 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5729 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2155 - val_loss: 4.1616 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6365 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4297 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0701 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.3794 - val_vertical_dominance_accuracy: 0.8421 - val_vertical_dominance_loss: 0.8899 - learning_rate: 5.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6824 - burstiness_loss: 0.6406 - coordination_accuracy: 0.8019 - coordination_loss: 0.4940 - directional_variability_accuracy: 0.9413 - directional_variability_loss: 0.1752 - loss: 3.4559 - motion_intensity_accuracy: 0.7623 - motion_intensity_loss: 0.5893 - periodicity_accuracy: 0.7577 - periodicity_loss: 0.5621 - static_context_accuracy: 0.9745 - static_context_loss: 0.1175 - temporal_stability_accuracy: 0.8673 - temporal_stability_loss: 0.3653 - vertical_dominance_accuracy: 0.7368 - vertical_dominance_loss: 0.5759 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6507 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.6300 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2277 - val_loss: 4.2900 - val_motion_intensity_accuracy: 0.7632 - val_motion_intensity_loss: 0.6595 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4415 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0655 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3900 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9755 - learning_rate: 5.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6884 - burstiness_loss: 0.6431 - coordination_accuracy: 0.8091 - coordination_loss: 0.4902 - directional_variability_accuracy: 0.9447 - directional_variability_loss: 0.1704 - loss: 3.4380 - motion_intensity_accuracy: 0.7602 - motion_intensity_loss: 0.5865 - periodicity_accuracy: 0.7479 - periodicity_loss: 0.5656 - static_context_accuracy: 0.9749 - static_context_loss: 0.1142 - temporal_stability_accuracy: 0.8631 - temporal_stability_loss: 0.3691 - vertical_dominance_accuracy: 0.7594 - vertical_dominance_loss: 0.5615 - val_burstiness_accuracy: 0.6842 - val_burstiness_loss: 0.6601 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.6055 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2370 - val_loss: 4.2137 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6433 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4328 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0668 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3635 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9298 - learning_rate: 5.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6939 - burstiness_loss: 0.6355 - coordination_accuracy: 0.8185 - coordination_loss: 0.4776 - directional_variability_accuracy: 0.9426 - directional_variability_loss: 0.1720 - loss: 3.4446 - motion_intensity_accuracy: 0.7581 - motion_intensity_loss: 0.5881 - periodicity_accuracy: 0.7555 - periodicity_loss: 0.5692 - static_context_accuracy: 0.9694 - static_context_loss: 0.1192 - temporal_stability_accuracy: 0.8678 - temporal_stability_loss: 0.3727 - vertical_dominance_accuracy: 0.7530 - vertical_dominance_loss: 0.5728 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6286 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5644 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2298 - val_loss: 4.2092 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6428 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4481 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0680 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.3727 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9203 - learning_rate: 5.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6866 - burstiness_loss: 0.6380 - coordination_accuracy: 0.8087 - coordination_loss: 0.4933 - directional_variability_accuracy: 0.9362 - directional_variability_loss: 0.1707 - loss: 3.4549 - motion_intensity_accuracy: 0.7564 - motion_intensity_loss: 0.5934 - periodicity_accuracy: 0.7432 - periodicity_loss: 0.5657 - static_context_accuracy: 0.9732 - static_context_loss: 0.1150 - temporal_stability_accuracy: 0.8699 - temporal_stability_loss: 0.3670 - vertical_dominance_accuracy: 0.7517 - vertical_dominance_loss: 0.5730 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6505 - val_coordination_accuracy: 0.5789 - val_coordination_loss: 0.5877 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2172 - val_loss: 4.2135 - val_motion_intensity_accuracy: 0.7632 - val_motion_intensity_loss: 0.6470 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4427 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0671 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.3683 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9553 - learning_rate: 5.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.7007 - burstiness_loss: 0.6259 - coordination_accuracy: 0.8125 - coordination_loss: 0.4821 - directional_variability_accuracy: 0.9452 - directional_variability_loss: 0.1708 - loss: 3.3710 - motion_intensity_accuracy: 0.7594 - motion_intensity_loss: 0.5877 - periodicity_accuracy: 0.7491 - periodicity_loss: 0.5558 - static_context_accuracy: 0.9758 - static_context_loss: 0.1125 - temporal_stability_accuracy: 0.8729 - temporal_stability_loss: 0.3513 - vertical_dominance_accuracy: 0.7628 - vertical_dominance_loss: 0.5462 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6449 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.6135 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2337 - val_loss: 4.3093 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6801 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4368 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0641 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3836 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9669 - learning_rate: 5.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.7015 - burstiness_loss: 0.6245 - coordination_accuracy: 0.8168 - coordination_loss: 0.4692 - directional_variability_accuracy: 0.9413 - directional_variability_loss: 0.1683 - loss: 3.3656 - motion_intensity_accuracy: 0.7679 - motion_intensity_loss: 0.5835 - periodicity_accuracy: 0.7500 - periodicity_loss: 0.5664 - static_context_accuracy: 0.9732 - static_context_loss: 0.1146 - temporal_stability_accuracy: 0.8797 - temporal_stability_loss: 0.3481 - vertical_dominance_accuracy: 0.7662 - vertical_dominance_loss: 0.5518 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6402 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5837 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2203 - val_loss: 4.2390 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6696 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4343 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0648 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.3764 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9752 - learning_rate: 2.5000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.6849 - burstiness_loss: 0.6282 - coordination_accuracy: 0.8210 - coordination_loss: 0.4553 - directional_variability_accuracy: 0.9379 - directional_variability_loss: 0.1812 - loss: 3.3643 - motion_intensity_accuracy: 0.7611 - motion_intensity_loss: 0.5902 - periodicity_accuracy: 0.7572 - periodicity_loss: 0.5452 - static_context_accuracy: 0.9728 - static_context_loss: 0.1094 - temporal_stability_accuracy: 0.8737 - temporal_stability_loss: 0.3462 - vertical_dominance_accuracy: 0.7598 - vertical_dominance_loss: 0.5604 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6627 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5663 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2251 - val_loss: 4.2373 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6587 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4388 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0663 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.3808 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9436 - learning_rate: 2.5000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.7049 - burstiness_loss: 0.6272 - coordination_accuracy: 0.8240 - coordination_loss: 0.4685 - directional_variability_accuracy: 0.9469 - directional_variability_loss: 0.1729 - loss: 3.3903 - motion_intensity_accuracy: 0.7666 - motion_intensity_loss: 0.5853 - periodicity_accuracy: 0.7551 - periodicity_loss: 0.5576 - static_context_accuracy: 0.9724 - static_context_loss: 0.1148 - temporal_stability_accuracy: 0.8648 - temporal_stability_loss: 0.3654 - vertical_dominance_accuracy: 0.7504 - vertical_dominance_loss: 0.5587 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6613 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5704 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2383 - val_loss: 4.2965 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6819 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4423 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0659 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3868 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9682 - learning_rate: 2.5000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.7037 - burstiness_loss: 0.6200 - coordination_accuracy: 0.8163 - coordination_loss: 0.4680 - directional_variability_accuracy: 0.9464 - directional_variability_loss: 0.1652 - loss: 3.3499 - motion_intensity_accuracy: 0.7645 - motion_intensity_loss: 0.5739 - periodicity_accuracy: 0.7509 - periodicity_loss: 0.5488 - static_context_accuracy: 0.9724 - static_context_loss: 0.1214 - temporal_stability_accuracy: 0.8776 - temporal_stability_loss: 0.3437 - vertical_dominance_accuracy: 0.7538 - vertical_dominance_loss: 0.5657 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6422 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5736 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2284 - val_loss: 4.2227 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6610 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4268 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0657 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3736 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9510 - learning_rate: 2.5000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - burstiness_accuracy: 0.7011 - burstiness_loss: 0.6258 - coordination_accuracy: 0.8138 - coordination_loss: 0.4531 - directional_variability_accuracy: 0.9430 - directional_variability_loss: 0.1680 - loss: 3.3301 - motion_intensity_accuracy: 0.7615 - motion_intensity_loss: 0.5701 - periodicity_accuracy: 0.7568 - periodicity_loss: 0.5426 - static_context_accuracy: 0.9728 - static_context_loss: 0.1092 - temporal_stability_accuracy: 0.8724 - temporal_stability_loss: 0.3501 - vertical_dominance_accuracy: 0.7547 - vertical_dominance_loss: 0.5607 - val_burstiness_accuracy: 0.6579 - val_burstiness_loss: 0.6542 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5680 - val_directional_variability_accuracy: 0.8684 - val_directional_variability_loss: 0.2423 - val_loss: 4.2664 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.6701 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4399 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.0684 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.3833 - val_vertical_dominance_accuracy: 0.7895 - val_vertical_dominance_loss: 0.9382 - learning_rate: 2.5000e-04\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train model with enhanced parameters for 7 concepts\n",
    "print(\"Training model...\")\n",
    "history = model.fit(\n",
    "    X_train_aug,\n",
    "    [y_p_train_cat, y_t_train_cat, y_c_train_cat, y_mi_train_cat, y_vd_train_cat, y_dv_train_cat, y_b_train_cat, y_sp_context_train_cat],\n",
    "    validation_data=(X_test, [y_p_test_cat, y_t_test_cat, y_c_test_cat, y_mi_test_cat, y_vd_test_cat, y_dv_test_cat, y_b_test_cat, y_sp_context_test_cat]),\n",
    "    epochs=200,\n",
    "    batch_size=32,  # Optimized parameter from grid search\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Evaluation\n",
    "\n",
    "**Purpose**: Evaluate model performance on test data and calculate individual concept accuracies.\n",
    "\n",
    "**Metrics**:\n",
    "- Individual accuracy for each of the 7 concepts\n",
    "- Overall accuracy across all concepts\n",
    "- Performance analysis and recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracies for all 7 concepts...\n",
      "\n",
      "=== MODEL PERFORMANCE ===\n",
      "Periodicity Accuracy: 76.3%\n",
      "Temporal Stability Accuracy: 71.1%\n",
      "Coordination Accuracy: 65.8%\n",
      "Motion Intensity Accuracy: 86.8%\n",
      "Vertical Dominance Accuracy: 68.4%\n",
      "Directional Variability Accuracy: 73.7%\n",
      "Burstiness Accuracy: 84.2%\n",
      "\n",
      "Overall Accuracy (7 concepts): 75.2%\n",
      "\n",
      "Note: Static context is used internally to help motion concepts but is not evaluated as a separate concept.\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model...\")\n",
    "results = model.evaluate(X_test, [y_p_test_cat, y_t_test_cat, y_c_test_cat, y_mi_test_cat, y_vd_test_cat, y_dv_test_cat, y_b_test_cat, y_sp_context_test_cat], verbose=0)\n",
    "\n",
    "# Get predictions and calculate accuracy manually for all 7 concepts\n",
    "print(\"Calculating accuracies for all 7 concepts...\")\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Extract predictions for each concept\n",
    "periodicity_pred = np.argmax(predictions[0], axis=1)\n",
    "temporal_stability_pred = np.argmax(predictions[1], axis=1)\n",
    "coordination_pred = np.argmax(predictions[2], axis=1)\n",
    "motion_intensity_pred = np.argmax(predictions[3], axis=1)\n",
    "vertical_dominance_pred = np.argmax(predictions[4], axis=1)\n",
    "directional_variability_pred = np.argmax(predictions[5], axis=1)\n",
    "burstiness_pred = np.argmax(predictions[6], axis=1)\n",
    "\n",
    "# Get true labels\n",
    "periodicity_true = np.argmax(y_p_test_cat, axis=1)\n",
    "temporal_stability_true = np.argmax(y_t_test_cat, axis=1)\n",
    "coordination_true = np.argmax(y_c_test_cat, axis=1)\n",
    "motion_intensity_true = np.argmax(y_mi_test_cat, axis=1)\n",
    "vertical_dominance_true = np.argmax(y_vd_test_cat, axis=1)\n",
    "directional_variability_true = np.argmax(y_dv_test_cat, axis=1)\n",
    "burstiness_true = np.argmax(y_b_test_cat, axis=1)\n",
    "\n",
    "# Calculate accuracies for all 7 main concepts\n",
    "periodicity_acc = accuracy_score(periodicity_true, periodicity_pred)\n",
    "temporal_stability_acc = accuracy_score(temporal_stability_true, temporal_stability_pred)\n",
    "coordination_acc = accuracy_score(coordination_true, coordination_pred)\n",
    "motion_intensity_acc = accuracy_score(motion_intensity_true, motion_intensity_pred)\n",
    "vertical_dominance_acc = accuracy_score(vertical_dominance_true, vertical_dominance_pred)\n",
    "directional_variability_acc = accuracy_score(directional_variability_true, directional_variability_pred)\n",
    "burstiness_acc = accuracy_score(burstiness_true, burstiness_pred)\n",
    "\n",
    "# Calculate overall accuracy for all 7 concepts\n",
    "overall_acc = (periodicity_acc + temporal_stability_acc + coordination_acc + motion_intensity_acc + \n",
    "               vertical_dominance_acc + directional_variability_acc + burstiness_acc) / 7\n",
    "\n",
    "print(f\"\\n=== MODEL PERFORMANCE ===\")\n",
    "print(f\"Periodicity Accuracy: {periodicity_acc*100:.1f}%\")\n",
    "print(f\"Temporal Stability Accuracy: {temporal_stability_acc*100:.1f}%\")\n",
    "print(f\"Coordination Accuracy: {coordination_acc*100:.1f}%\")\n",
    "print(f\"Motion Intensity Accuracy: {motion_intensity_acc*100:.1f}%\")\n",
    "print(f\"Vertical Dominance Accuracy: {vertical_dominance_acc*100:.1f}%\")\n",
    "print(f\"Directional Variability Accuracy: {directional_variability_acc*100:.1f}%\")\n",
    "print(f\"Burstiness Accuracy: {burstiness_acc*100:.1f}%\")\n",
    "print(f\"\\nOverall Accuracy (7 concepts): {overall_acc*100:.1f}%\")\n",
    "print(f\"\\nNote: Static context is used internally to help motion concepts but is not evaluated as a separate concept.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Training Visualization\n",
    "\n",
    "**Purpose**: Visualize training progress and concept-specific performance.\n",
    "\n",
    "**Visualizations**:\n",
    "- Training and validation loss curves\n",
    "- Individual concept accuracy over epochs\n",
    "- Final training accuracy summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
