{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick CNN Training - Ultra Lightweight + Augmentation\n",
    "\n",
    "## Overview\n",
    "This notebook contains only the essential components for training the ultra-lightweight CNN with augmentation and random shuffle split.\n",
    "\n",
    "## Features\n",
    "- **5 Core Concepts**: periodicity, temporal_stability, coordination, motion_intensity, vertical_dominance\n",
    "- **Data Augmentation**: Jitter, scaling, and rotation for robust training\n",
    "- **Contextual Learning**: Static posture context for motion concepts\n",
    "- **Optimized Architecture**: Lightweight CNN with enhanced parameters for 5 concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration\n",
    "\n",
    "**Purpose**: Load necessary libraries and contextual configuration for model training.\n",
    "\n",
    "**Key Components**:\n",
    "- TensorFlow/Keras for deep learning\n",
    "- Scikit-learn for data preprocessing\n",
    "- Contextual configuration for motion concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick CNN Training - Ultra Lightweight + Augmentation\n",
    "## Streamlined version for rapid iteration\n",
    "\n",
    "This notebook contains only the essential components for training the ultra-lightweight CNN with augmentation and random shuffle split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.11.3\n",
      "\n",
      "Loaded contextual configuration:\n",
      "  motion_intensity: Uses static posture context\n",
      "  vertical_dominance: Uses static posture context\n",
      "  periodicity: Independent\n",
      "  temporal_stability: Independent\n",
      "  coordination: Independent\n",
      "  directional_variability: Independent\n",
      "  burstiness: Independent\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# Load contextual configuration from rule definitions\n",
    "try:\n",
    "    with open('../rule_based_labeling/contextual_config.json', 'r') as f:\n",
    "        contextual_config = json.load(f)\n",
    "    print(f\"\\nLoaded contextual configuration:\")\n",
    "    for feature, uses_context in contextual_config.items():\n",
    "        print(f\"  {feature}: {'Uses static posture context' if uses_context else 'Independent'}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: contextual_config.json not found. Using default configuration.\")\n",
    "    contextual_config = {\n",
    "        'movement_variability': True,\n",
    "        'movement_consistency': True,\n",
    "        'movement_smoothness': True,\n",
    "        'periodicity': False,\n",
    "        'temporal_stability': False,\n",
    "        'coordination': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Discretization\n",
    "\n",
    "**Purpose**: Load sensor data and convert continuous concept values to discrete categories.\n",
    "\n",
    "**Process**:\n",
    "- Load raw sensor data and window labels\n",
    "- Convert continuous values to discrete (0.0, 0.5, 1.0) for all concepts\n",
    "- Apply discretization rules for motion_intensity and vertical_dominance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data: 8802 readings\n",
      "Manual labels: 150 windows\n",
      "\n",
      "Labeled windows:\n",
      "   window_idx  user activity  start_time  end_time  periodicity  \\\n",
      "0           0     3  Walking      957.75    960.75          1.0   \n",
      "1           1     3  Walking       42.00     45.00          1.0   \n",
      "2           2     3  Walking      871.50    874.50          0.5   \n",
      "3           3     3  Walking       63.00     66.00          1.0   \n",
      "4           4     3  Jogging      117.75    120.75          1.0   \n",
      "\n",
      "   temporal_stability  coordination  motion_intensity  vertical_dominance  \\\n",
      "0                 0.5           0.5          0.316815            0.221105   \n",
      "1                 0.5           0.5          0.302850            0.291116   \n",
      "2                 0.5           0.5          0.303036            0.181147   \n",
      "3                 0.5           0.5          0.313779            0.305797   \n",
      "4                 0.5           0.5          0.408648            0.262989   \n",
      "\n",
      "   static_posture  directional_variability  burstiness  \n",
      "0             0.0                 0.154414    0.489167  \n",
      "1             0.0                 0.070586    0.215654  \n",
      "2             0.0                 0.120062    0.442595  \n",
      "3             0.0                 0.087703    0.259150  \n",
      "4             0.0                 0.441992    0.342272  \n",
      "\n",
      "Available concepts: ['periodicity', 'temporal_stability', 'coordination', 'movement_variability', 'movement_consistency', 'movement_smoothness', 'static_posture']\n",
      "\n",
      "=== CALCULATING NEW RULE-BASED CONCEPTS ===\n",
      "Calculating movement variability...\n",
      "Calculating movement consistency...\n",
      "Calculating movement smoothness...\n",
      "\n",
      "=== BEFORE DISCRETIZATION ===\n",
      "Original movement_variability range: 0.0238 to 8.6983\n",
      "Original movement_consistency range: -0.5103 to 0.6136\n",
      "Original movement_smoothness range: 0.0438 to 0.9314\n",
      "\n",
      "=== DUPLICATE VALUE ANALYSIS ===\n",
      "movement_variability: 150 unique values out of 150 total (100.0% unique)\n",
      "  Top 10 most frequent values:\n",
      "    6.099506721555182: 1 times\n",
      "    0.14500027788749945: 1 times\n",
      "    0.053666957736114226: 1 times\n",
      "    0.07505676707411253: 1 times\n",
      "    0.04511986089276805: 1 times\n",
      "    5.295558408192048: 1 times\n",
      "    4.777496703764277: 1 times\n",
      "    4.852424588609414: 1 times\n",
      "    4.25459377293092: 1 times\n",
      "    4.717105696867196: 1 times\n",
      "\n",
      "movement_consistency: 150 unique values out of 150 total (100.0% unique)\n",
      "  Top 10 most frequent values:\n",
      "    0.19520220538269278: 1 times\n",
      "    0.1693916536945606: 1 times\n",
      "    -0.12116339715842231: 1 times\n",
      "    -0.07486956780311892: 1 times\n",
      "    -0.17594269609246024: 1 times\n",
      "    0.43093151068775454: 1 times\n",
      "    0.3632671610124457: 1 times\n",
      "    0.38347578902537416: 1 times\n",
      "    0.31115546491854845: 1 times\n",
      "    0.1861021230499993: 1 times\n",
      "\n",
      "movement_smoothness: 150 unique values out of 150 total (100.0% unique)\n",
      "  Top 10 most frequent values:\n",
      "    0.05697071245381794: 1 times\n",
      "    0.7477995372008175: 1 times\n",
      "    0.850196191341642: 1 times\n",
      "    0.8257458412324075: 1 times\n",
      "    0.862532404438758: 1 times\n",
      "    0.0957213651566237: 1 times\n",
      "    0.10057812228685759: 1 times\n",
      "    0.10807118621891623: 1 times\n",
      "    0.09220237062824671: 1 times\n",
      "    0.08103393379877911: 1 times\n",
      "\n",
      "\n",
      "=== APPLYING 3-BIN DISCRETIZATION FOR CLASSIFICATION ===\n",
      "\n",
      "=== AFTER DISCRETIZATION ===\n",
      "Discretized movement_variability: movement_variability\n",
      "0.0    55\n",
      "0.5    64\n",
      "1.0    31\n",
      "Name: count, dtype: int64\n",
      "Discretized movement_consistency: movement_consistency\n",
      "0.0    11\n",
      "0.5    47\n",
      "1.0    92\n",
      "Name: count, dtype: int64\n",
      "Discretized movement_smoothness: movement_smoothness\n",
      "0.0    101\n",
      "0.5      5\n",
      "1.0     44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== FINAL CONCEPT DISTRIBUTIONS ===\n",
      "  periodicity: {0.0: np.int64(90), 0.5: np.int64(35), 1.0: np.int64(25)}\n",
      "  temporal_stability: {0.0: np.int64(12), 0.5: np.int64(87), 1.0: np.int64(51)}\n",
      "  coordination: {0.0: np.int64(16), 0.5: np.int64(64), 1.0: np.int64(70)}\n",
      "  movement_variability: {0.0: np.int64(55), 0.5: np.int64(64), 1.0: np.int64(31)}\n",
      "  movement_consistency: {0.0: np.int64(11), 0.5: np.int64(47), 1.0: np.int64(92)}\n",
      "  movement_smoothness: {0.0: np.int64(101), 0.5: np.int64(5), 1.0: np.int64(44)}\n",
      "  static_posture: {0.0: np.int64(147), 1.0: np.int64(3)}\n",
      "\n",
      "New rule-based concepts created successfully!\n",
      "• Movement Variability: Measures how much movement varies over time\n",
      "• Movement Consistency: Measures how consistent movement patterns are over time\n",
      "• Movement Smoothness: Measures how smooth movement patterns are (inverse of jerk)\n",
      "• All three concepts should correlate better with human-labeled concepts\n"
     ]
    }
   ],
   "source": [
    "# Load data - CHANGE THESE PATHS AS NEEDED\n",
    "df_sensor = pd.read_csv('../rule_based_labeling/raw_with_features.csv')\n",
    "df_windows = pd.read_csv('../rule_based_labeling/window_with_features.csv') \n",
    "\n",
    "print(f\"Sensor data: {len(df_sensor)} readings\")\n",
    "print(f\"Manual labels: {len(df_windows)} windows\")\n",
    "print(f\"\\nLabeled windows:\")\n",
    "print(df_windows.head())\n",
    "\n",
    "# Check available concepts - UPDATED 6-CONCEPT MODEL WITH BETTER RULE-BASED CONCEPTS\n",
    "concept_columns = ['periodicity', 'temporal_stability', 'coordination', 'movement_variability', 'movement_consistency', 'movement_smoothness', 'static_posture']\n",
    "print(f\"\\nAvailable concepts: {concept_columns}\")\n",
    "\n",
    "# Calculate new rule-based concepts\n",
    "print(f\"\\n=== CALCULATING NEW RULE-BASED CONCEPTS ===\")\n",
    "\n",
    "# 1. Movement Variability: Standard deviation of magnitude over time\n",
    "def calculate_movement_variability(df_sensor, df_windows):\n",
    "    \"\"\"Calculate movement variability as standard deviation of magnitude for each window\"\"\"\n",
    "    variability_scores = []\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        # Get data for this user/activity\n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            variability_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # Find data within time window\n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 5:  # Need minimum samples\n",
    "            variability_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # Calculate magnitude\n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        # Calculate standard deviation (variability)\n",
    "        variability = magnitude.std()\n",
    "        variability_scores.append(variability)\n",
    "    \n",
    "    return np.array(variability_scores)\n",
    "\n",
    "# 2. Movement Consistency: Temporal correlation of movement patterns\n",
    "def calculate_movement_consistency(df_sensor, df_windows):\n",
    "    \"\"\"Calculate movement consistency as temporal correlation for each window\"\"\"\n",
    "    consistency_scores = []\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        # Get data for this user/activity\n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            consistency_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # Find data within time window\n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 10:  # Need minimum samples for correlation\n",
    "            consistency_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # Calculate magnitude\n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        # Calculate temporal consistency (correlation between consecutive values)\n",
    "        if len(magnitude) >= 2:\n",
    "            # Use correlation between consecutive values as consistency measure\n",
    "            correlation = np.corrcoef(magnitude[:-1], magnitude[1:])[0, 1]\n",
    "            # Handle NaN values\n",
    "            if np.isnan(correlation):\n",
    "                correlation = 0.0\n",
    "            consistency_scores.append(correlation)\n",
    "        else:\n",
    "            consistency_scores.append(0.0)\n",
    "    \n",
    "    return np.array(consistency_scores)\n",
    "\n",
    "# 3. Movement Smoothness: Inverse of jerk (rate of change of acceleration)\n",
    "def calculate_movement_smoothness(df_sensor, df_windows):\n",
    "    \"\"\"Calculate movement smoothness as inverse of jerk for each window\"\"\"\n",
    "    smoothness_scores = []\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        # Get data for this user/activity\n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            smoothness_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # Find data within time window\n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 10:  # Need minimum samples for jerk calculation\n",
    "            smoothness_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # Calculate magnitude\n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        # Calculate jerk (third derivative of position)\n",
    "        if len(magnitude) >= 4:\n",
    "            velocity = np.diff(magnitude)\n",
    "            acceleration = np.diff(velocity)\n",
    "            jerk = np.diff(acceleration)\n",
    "            \n",
    "            # Calculate smoothness as inverse of mean absolute jerk\n",
    "            mean_jerk = np.mean(np.abs(jerk))\n",
    "            smoothness = 1.0 / (1.0 + mean_jerk)  # Inverse of jerk, bounded [0,1]\n",
    "            smoothness_scores.append(smoothness)\n",
    "        else:\n",
    "            smoothness_scores.append(0.0)\n",
    "    \n",
    "    return np.array(smoothness_scores)\n",
    "\n",
    "# Calculate new concepts\n",
    "print(\"Calculating movement variability...\")\n",
    "df_windows['movement_variability'] = calculate_movement_variability(df_sensor, df_windows)\n",
    "\n",
    "print(\"Calculating movement consistency...\")\n",
    "df_windows['movement_consistency'] = calculate_movement_consistency(df_sensor, df_windows)\n",
    "\n",
    "print(\"Calculating movement smoothness...\")\n",
    "df_windows['movement_smoothness'] = calculate_movement_smoothness(df_sensor, df_windows)\n",
    "\n",
    "# Debug: Check original values BEFORE discretization\n",
    "print(f\"\\n=== BEFORE DISCRETIZATION ===\")\n",
    "print(f\"Original movement_variability range: {df_windows['movement_variability'].min():.4f} to {df_windows['movement_variability'].max():.4f}\")\n",
    "print(f\"Original movement_consistency range: {df_windows['movement_consistency'].min():.4f} to {df_windows['movement_consistency'].max():.4f}\")\n",
    "print(f\"Original movement_smoothness range: {df_windows['movement_smoothness'].min():.4f} to {df_windows['movement_smoothness'].max():.4f}\")\n",
    "\n",
    "# Check for duplicate values that might break pd.qcut()\n",
    "print(f\"\\n=== DUPLICATE VALUE ANALYSIS ===\")\n",
    "for concept in ['movement_variability', 'movement_consistency', 'movement_smoothness']:\n",
    "    values = df_windows[concept]\n",
    "    unique_values = len(values.unique())\n",
    "    total_values = len(values)\n",
    "    print(f\"{concept}: {unique_values} unique values out of {total_values} total ({unique_values/total_values*100:.1f}% unique)\")\n",
    "    \n",
    "    # Show value distribution\n",
    "    value_counts = values.value_counts().head(10)\n",
    "    print(f\"  Top 10 most frequent values:\")\n",
    "    for val, count in value_counts.items():\n",
    "        print(f\"    {val}: {count} times\")\n",
    "    print()\n",
    "\n",
    "# Convert new rule-based concepts to discrete labels (0, 0.5, 1.0) for classification\n",
    "print(f\"\\n=== APPLYING 3-BIN DISCRETIZATION FOR CLASSIFICATION ===\")\n",
    "\n",
    "# Movement Variability: Convert to 3-bin classification\n",
    "# Low (0.0): Low variability, Medium (0.5): Medium variability, High (1.0): High variability\n",
    "df_windows['movement_variability'] = pd.cut(\n",
    "    df_windows['movement_variability'], \n",
    "    bins=3, \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Movement Consistency: Convert to 3-bin classification  \n",
    "# Low (0.0): Low consistency, Medium (0.5): Medium consistency, High (1.0): High consistency\n",
    "df_windows['movement_consistency'] = pd.cut(\n",
    "    df_windows['movement_consistency'], \n",
    "    bins=3, \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Movement Smoothness: Convert to 3-bin classification\n",
    "# Low (0.0): Low smoothness, Medium (0.5): Medium smoothness, High (1.0): High smoothness\n",
    "df_windows['movement_smoothness'] = pd.cut(\n",
    "    df_windows['movement_smoothness'], \n",
    "    bins=3, \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Static Posture: Already binary (0.0 or 1.0), keep as is\n",
    "# No change needed for static_posture\n",
    "\n",
    "# Debug: Check discretized values\n",
    "print(f\"\\n=== AFTER DISCRETIZATION ===\")\n",
    "print(f\"Discretized movement_variability: {df_windows['movement_variability'].value_counts().sort_index()}\")\n",
    "print(f\"Discretized movement_consistency: {df_windows['movement_consistency'].value_counts().sort_index()}\")\n",
    "print(f\"Discretized movement_smoothness: {df_windows['movement_smoothness'].value_counts().sort_index()}\")\n",
    "\n",
    "# Final check: Show all concept distributions\n",
    "print(f\"\\n=== FINAL CONCEPT DISTRIBUTIONS ===\")\n",
    "for concept in concept_columns:\n",
    "    if concept in df_windows.columns:\n",
    "        values = df_windows[concept].value_counts().sort_index()\n",
    "        print(f\"  {concept}: {dict(values)}\")\n",
    "\n",
    "print(f\"\\nNew rule-based concepts created successfully!\")\n",
    "print(f\"• Movement Variability: Measures how much movement varies over time\")\n",
    "print(f\"• Movement Consistency: Measures how consistent movement patterns are over time\")\n",
    "print(f\"• Movement Smoothness: Measures how smooth movement patterns are (inverse of jerk)\")\n",
    "print(f\"• All three concepts should correlate better with human-labeled concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Window Extraction Functions\n",
    "\n",
    "**Purpose**: Extract sensor data windows with robust time matching and error handling.\n",
    "\n",
    "**Functions**:\n",
    "- `extract_window_robust()`: Extract single window with time tolerance\n",
    "- `extract_windows_robust()`: Extract all windows for 7 concepts\n",
    "- Handles missing data and time mismatches gracefully\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_window_robust(df_sensor, window_row, time_tolerance=0.5):\n",
    "    \"\"\"\n",
    "    Extract sensor data with time tolerance to handle mismatches.\n",
    "    \"\"\"\n",
    "    user = window_row['user']\n",
    "    activity = window_row['activity']\n",
    "    start_time = window_row['start_time']\n",
    "    end_time = window_row['end_time']\n",
    "    \n",
    "    # Get data for this user/activity\n",
    "    user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                  (df_sensor['activity'] == activity)].copy()\n",
    "    \n",
    "    if len(user_activity_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Find data within time window with tolerance\n",
    "    mask = ((user_activity_data['time_s'] >= start_time - time_tolerance) & \n",
    "            (user_activity_data['time_s'] <= end_time + time_tolerance))\n",
    "    \n",
    "    window_data = user_activity_data[mask]\n",
    "    \n",
    "    if len(window_data) < 10:  # Need minimum samples\n",
    "        return None\n",
    "    \n",
    "    # Extract sensor readings\n",
    "    sensor_data = window_data[['x-axis', 'y-axis', 'z-axis']].values\n",
    "    \n",
    "    # Pad or truncate to fixed length (e.g., 100 samples)\n",
    "    target_length = 100\n",
    "    if len(sensor_data) > target_length:\n",
    "        # Randomly sample if too long\n",
    "        indices = np.random.choice(len(sensor_data), target_length, replace=False)\n",
    "        sensor_data = sensor_data[indices]\n",
    "    elif len(sensor_data) < target_length:\n",
    "        # Pad with last value if too short\n",
    "        padding = np.tile(sensor_data[-1:], (target_length - len(sensor_data), 1))\n",
    "        sensor_data = np.vstack([sensor_data, padding])\n",
    "    \n",
    "    return sensor_data\n",
    "\n",
    "def extract_windows_robust(df_sensor, df_windows):\n",
    "    \"\"\"\n",
    "    Extract all windows with robust time matching for 6 concepts (updated model).\n",
    "    Uses 3-bin classification for all concepts including new rule-based ones.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y_p = []  # periodicity (classification)\n",
    "    y_t = []  # temporal_stability (classification)\n",
    "    y_c = []  # coordination (classification)\n",
    "    y_mv = [] # movement_variability (classification)\n",
    "    y_mc = [] # movement_consistency (classification)\n",
    "    y_ms = [] # movement_smoothness (classification)\n",
    "    y_sp = [] # static_posture (classification)\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        window_data = extract_window_robust(df_sensor, window_row)\n",
    "        if window_data is not None:\n",
    "            X.append(window_data)\n",
    "            y_p.append(window_row['periodicity'])\n",
    "            y_t.append(window_row['temporal_stability'])\n",
    "            y_c.append(window_row['coordination'])\n",
    "            # Use new rule-based concepts\n",
    "            y_mv.append(window_row['movement_variability'])\n",
    "            y_mc.append(window_row['movement_consistency'])\n",
    "            y_ms.append(window_row['movement_smoothness'])\n",
    "            y_sp.append(window_row['static_posture'])\n",
    "    \n",
    "    return np.array(X), np.array(y_p), np.array(y_t), np.array(y_c), np.array(y_mv), np.array(y_mc), np.array(y_ms), np.array(y_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation Functions\n",
    "\n",
    "**Purpose**: Create augmented versions of the dataset to improve model robustness.\n",
    "\n",
    "**Augmentation Types**:\n",
    "- **Jitter**: Add Gaussian noise to simulate sensor imperfections\n",
    "- **Scaling**: Scale magnitude to simulate different movement intensities  \n",
    "- **Rotation**: Rotate 3D data to simulate different phone orientations\n",
    "- **Factor**: 10x augmentation multiplier for robust training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_jitter(data, sigma=0.05):\n",
    "    \"\"\"Add random Gaussian noise to simulate sensor imperfections\"\"\"\n",
    "    return data + np.random.normal(0, sigma, data.shape)\n",
    "\n",
    "def augment_scaling(data, sigma=0.1):\n",
    "    \"\"\"Scale magnitude to simulate different movement intensities\"\"\"\n",
    "    # Handle different data shapes\n",
    "    if len(data.shape) == 3:\n",
    "        factor = np.random.normal(1.0, sigma, (data.shape[0], 1, data.shape[2]))\n",
    "    elif len(data.shape) == 2:\n",
    "        factor = np.random.normal(1.0, sigma, (data.shape[0], data.shape[1]))\n",
    "    else:\n",
    "        factor = np.random.normal(1.0, sigma, data.shape)\n",
    "    return data * factor\n",
    "\n",
    "def augment_rotation(data):\n",
    "    \"\"\"Rotate 3D data to simulate different phone orientations\"\"\"\n",
    "    angle = np.random.uniform(-np.pi/6, np.pi/6)  # ±30 degrees\n",
    "    cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_a, -sin_a, 0],\n",
    "        [sin_a, cos_a, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return np.dot(data, rotation_matrix.T)\n",
    "\n",
    "def augment_dataset(X, y_p, y_t, y_c, y_mv, y_mc, y_ms, y_sp, factor=10):\n",
    "    \"\"\"\n",
    "    Create augmented versions of the dataset for 6 concepts (updated model).\n",
    "    \n",
    "    Args:\n",
    "        X: Original data (n_samples, timesteps, 3)\n",
    "        y_p, y_t, y_c, y_mv, y_mc, y_ms, y_sp: Labels for six concepts\n",
    "        factor: Augmentation multiplier (10 = 10x more data)\n",
    "    \n",
    "    Returns:\n",
    "        Augmented dataset with (factor+1) × original size\n",
    "    \"\"\"\n",
    "    n_original = len(X)\n",
    "    n_augmented = n_original * factor\n",
    "    \n",
    "    # Initialize augmented arrays\n",
    "    X_aug = np.zeros((n_augmented, X.shape[1], X.shape[2]))\n",
    "    y_p_aug = np.zeros(n_augmented)\n",
    "    y_t_aug = np.zeros(n_augmented)\n",
    "    y_c_aug = np.zeros(n_augmented)\n",
    "    y_mv_aug = np.zeros(n_augmented)\n",
    "    y_mc_aug = np.zeros(n_augmented)\n",
    "    y_ms_aug = np.zeros(n_augmented)\n",
    "    y_sp_aug = np.zeros(n_augmented)\n",
    "    \n",
    "    for i in range(n_augmented):\n",
    "        # Randomly select original sample\n",
    "        idx = np.random.randint(0, n_original)\n",
    "        \n",
    "        # Apply random augmentation\n",
    "        aug_type = np.random.choice(['jitter', 'scaling', 'rotation', 'none'])\n",
    "        \n",
    "        if aug_type == 'jitter':\n",
    "            X_aug[i] = augment_jitter(X[idx])\n",
    "        elif aug_type == 'scaling':\n",
    "            X_aug[i] = augment_scaling(X[idx])\n",
    "        elif aug_type == 'rotation':\n",
    "            X_aug[i] = augment_rotation(X[idx])\n",
    "        else:  # none\n",
    "            X_aug[i] = X[idx]\n",
    "        \n",
    "        # Copy labels\n",
    "        y_p_aug[i] = y_p[idx]\n",
    "        y_t_aug[i] = y_t[idx]\n",
    "        y_c_aug[i] = y_c[idx]\n",
    "        y_mv_aug[i] = y_mv[idx]\n",
    "        y_mc_aug[i] = y_mc[idx]\n",
    "        y_ms_aug[i] = y_ms[idx]\n",
    "        y_sp_aug[i] = y_sp[idx]\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    X_combined = np.vstack([X, X_aug])\n",
    "    y_p_combined = np.concatenate([y_p, y_p_aug])\n",
    "    y_t_combined = np.concatenate([y_t, y_t_aug])\n",
    "    y_c_combined = np.concatenate([y_c, y_c_aug])\n",
    "    y_mv_combined = np.concatenate([y_mv, y_mv_aug])\n",
    "    y_mc_combined = np.concatenate([y_mc, y_mc_aug])\n",
    "    y_ms_combined = np.concatenate([y_ms, y_ms_aug])\n",
    "    y_sp_combined = np.concatenate([y_sp, y_sp_aug])\n",
    "    \n",
    "    return X_combined, y_p_combined, y_t_combined, y_c_combined, y_mv_combined, y_mc_combined, y_ms_combined, y_sp_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Architecture Definition\n",
    "\n",
    "**Purpose**: Define the optimized CNN architecture for 7 concepts.\n",
    "\n",
    "**Architecture**:\n",
    "- **2 Conv1D layers** (16 filters each) with Batch Normalization\n",
    "- **Global Average Pooling** for dimensionality reduction\n",
    "- **Dropout (0.4)** for regularization\n",
    "- **Contextual Learning**: Static posture context for motion concepts\n",
    "- **Multi-output heads** for each concept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimized_cnn(input_shape, n_classes_p, n_classes_t, n_classes_c, n_classes_mv, n_classes_mc, n_classes_ms, contextual_config):\n",
    "    \"\"\"\n",
    "    Optimized CNN using best parameters from grid search for 6 concepts (updated model):\n",
    "    - conv_filters_1: 16, conv_filters_2: 16\n",
    "    - dropout_rate: 0.4\n",
    "    - learning_rate: 0.001 (will be set in compile)\n",
    "    - batch_size: 32 (will be set in fit)\n",
    "    - All concepts use 3-bin classification\n",
    "    - Static posture used contextually based on contextual_config\n",
    "    \"\"\"\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Conv layer 1 (original: 16 filters)\n",
    "    x = layers.Conv1D(16, 3, activation='relu', padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    \n",
    "    # Conv layer 2 (original: 16 filters)\n",
    "    x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Dropout (original: 0.4)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Static posture context (binary feature)\n",
    "    static_context = layers.Dense(1, activation='sigmoid', name='static_context')(x)\n",
    "    \n",
    "    # Output heads for each concept - use contextual configuration\n",
    "    outputs = []\n",
    "    output_names = []\n",
    "    \n",
    "    # Independent concepts (don't use static context)\n",
    "    periodicity = layers.Dense(n_classes_p, activation='softmax', name='periodicity')(x)\n",
    "    temporal_stability = layers.Dense(n_classes_t, activation='softmax', name='temporal_stability')(x)\n",
    "    coordination = layers.Dense(n_classes_c, activation='softmax', name='coordination')(x)\n",
    "    \n",
    "    outputs.extend([periodicity, temporal_stability, coordination])\n",
    "    output_names.extend(['periodicity', 'temporal_stability', 'coordination'])\n",
    "    \n",
    "    # Movement variability with classification output\n",
    "    if contextual_config.get('movement_variability', False):\n",
    "        movement_variability_input = layers.Concatenate()([x, static_context])\n",
    "        movement_variability = layers.Dense(n_classes_mv, activation='softmax', name='movement_variability')(movement_variability_input)\n",
    "    else:\n",
    "        movement_variability = layers.Dense(n_classes_mv, activation='softmax', name='movement_variability')(x)\n",
    "    \n",
    "    # Movement consistency with classification output\n",
    "    if contextual_config.get('movement_consistency', False):\n",
    "        movement_consistency_input = layers.Concatenate()([x, static_context])\n",
    "        movement_consistency = layers.Dense(n_classes_mc, activation='softmax', name='movement_consistency')(movement_consistency_input)\n",
    "    else:\n",
    "        movement_consistency = layers.Dense(n_classes_mc, activation='softmax', name='movement_consistency')(x)\n",
    "    \n",
    "    # Movement smoothness with classification output\n",
    "    if contextual_config.get('movement_smoothness', False):\n",
    "        movement_smoothness_input = layers.Concatenate()([x, static_context])\n",
    "        movement_smoothness = layers.Dense(n_classes_ms, activation='softmax', name='movement_smoothness')(movement_smoothness_input)\n",
    "    else:\n",
    "        movement_smoothness = layers.Dense(n_classes_ms, activation='softmax', name='movement_smoothness')(x)\n",
    "    \n",
    "    outputs.extend([movement_variability, movement_consistency, movement_smoothness])\n",
    "    output_names.extend(['movement_variability', 'movement_consistency', 'movement_smoothness'])\n",
    "    \n",
    "    # Add static context output\n",
    "    outputs.append(static_context)\n",
    "    output_names.append('static_context')\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=outputs)\n",
    "    \n",
    "    print(f\"Model architecture:\")\n",
    "    print(f\"  Classification concepts: periodicity, temporal_stability, coordination, movement_variability, movement_consistency, movement_smoothness\")\n",
    "    print(f\"  Contextual concepts: {[name for name, uses_context in contextual_config.items() if uses_context]}\")\n",
    "    print(f\"  Total concepts: 6 (updated model)\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Extraction\n",
    "\n",
    "**Purpose**: Extract sensor windows for all 7 concepts with robust error handling.\n",
    "\n",
    "**Output**: \n",
    "- X: Sensor data (n_windows, timesteps, 3)\n",
    "- y_p, y_t, y_c, y_mi, y_vd, y_dv, y_b, y_sp: Labels for 7 concepts + static context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting windows...\n",
      "Extracted 150 windows\n",
      "Window shape: (150, 100, 3)\n",
      "Label distributions:\n",
      "  Periodicity: [125  25   0] (classes 0, 1, 2)\n",
      "  Temporal Stability: [99 51  0] (classes 0, 1, 2)\n",
      "  Coordination: [80 70  0] (classes 0, 1, 2)\n",
      "  Movement Variability: [119  31   0] (classes 0, 1, 2)\n",
      "  Movement Consistency: [58 92  0] (classes 0, 1, 2)\n",
      "  Movement Smoothness: [106  44   0] (classes 0, 1, 2)\n",
      "  Static Posture: [147   3] (classes 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extract windows\n",
    "print(\"Extracting windows...\")\n",
    "X, y_p, y_t, y_c, y_mv, y_mc, y_ms, y_sp = extract_windows_robust(df_sensor, df_windows)\n",
    "\n",
    "print(f\"Extracted {len(X)} windows\")\n",
    "print(f\"Window shape: {X.shape}\")\n",
    "print(f\"Label distributions:\")\n",
    "# Show all 3 classes explicitly (0, 1, 2) for classification concepts\n",
    "concepts = ['Periodicity', 'Temporal Stability', 'Coordination', 'Movement Variability', 'Movement Consistency', 'Movement Smoothness']\n",
    "labels = [y_p, y_t, y_c, y_mv, y_mc, y_ms]\n",
    "\n",
    "for concept, label in zip(concepts, labels):\n",
    "    counts = np.bincount(label.astype(int), minlength=3)  # Ensure all 3 classes are shown\n",
    "    print(f\"  {concept}: {counts} (classes 0, 1, 2)\")\n",
    "\n",
    "# Static Posture is binary (0, 1)\n",
    "print(f\"  Static Posture: {np.bincount(y_sp.astype(int))} (classes 0, 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split\n",
    "\n",
    "**Purpose**: Split data into training and testing sets with proper stratification.\n",
    "\n",
    "**Split**: 75% training, 25% testing\n",
    "**Static Context**: Convert static posture to binary context labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data with stratification...\n",
      "Class distributions before splitting:\n",
      "  Periodicity: {np.float64(0.0): np.int64(90), np.float64(0.5): np.int64(35), np.float64(1.0): np.int64(25)}\n",
      "  Temporal Stability: {np.float64(0.0): np.int64(12), np.float64(0.5): np.int64(87), np.float64(1.0): np.int64(51)}\n",
      "  Coordination: {np.float64(0.0): np.int64(16), np.float64(0.5): np.int64(64), np.float64(1.0): np.int64(70)}\n",
      "  Movement Variability: {np.float64(0.0): np.int64(55), np.float64(0.5): np.int64(64), np.float64(1.0): np.int64(31)}\n",
      "  Movement Consistency: {np.float64(0.0): np.int64(11), np.float64(0.5): np.int64(47), np.float64(1.0): np.int64(92)}\n",
      "  Movement Smoothness: {np.float64(0.0): np.int64(101), np.float64(0.5): np.int64(5), np.float64(1.0): np.int64(44)}\n",
      "Train: 112 windows\n",
      "Test: 38 windows\n",
      "Static context train: [109   3]\n",
      "Static context test: [38]\n",
      "\n",
      "=== CLASS REPRESENTATION VERIFICATION ===\n",
      "\n",
      "Periodicity:\n",
      "  Train: {np.float64(0.0): np.int64(67), np.float64(0.5): np.int64(26), np.float64(1.0): np.int64(19)}\n",
      "  Test:  {np.float64(0.0): np.int64(23), np.float64(0.5): np.int64(9), np.float64(1.0): np.int64(6)}\n",
      "  ⚠️  Missing classes in train: {2}\n",
      "  ⚠️  Missing classes in test: {2}\n",
      "\n",
      "Temporal Stability:\n",
      "  Train: {np.float64(0.0): np.int64(9), np.float64(0.5): np.int64(64), np.float64(1.0): np.int64(39)}\n",
      "  Test:  {np.float64(0.0): np.int64(3), np.float64(0.5): np.int64(23), np.float64(1.0): np.int64(12)}\n",
      "  ⚠️  Missing classes in train: {2}\n",
      "  ⚠️  Missing classes in test: {2}\n",
      "\n",
      "Coordination:\n",
      "  Train: {np.float64(0.0): np.int64(10), np.float64(0.5): np.int64(46), np.float64(1.0): np.int64(56)}\n",
      "  Test:  {np.float64(0.0): np.int64(6), np.float64(0.5): np.int64(18), np.float64(1.0): np.int64(14)}\n",
      "  ⚠️  Missing classes in train: {2}\n",
      "  ⚠️  Missing classes in test: {2}\n",
      "\n",
      "Movement Variability:\n",
      "  Train: {np.float64(0.0): np.int64(42), np.float64(0.5): np.int64(46), np.float64(1.0): np.int64(24)}\n",
      "  Test:  {np.float64(0.0): np.int64(13), np.float64(0.5): np.int64(18), np.float64(1.0): np.int64(7)}\n",
      "  ⚠️  Missing classes in train: {2}\n",
      "  ⚠️  Missing classes in test: {2}\n",
      "\n",
      "Movement Consistency:\n",
      "  Train: {np.float64(0.0): np.int64(8), np.float64(0.5): np.int64(35), np.float64(1.0): np.int64(69)}\n",
      "  Test:  {np.float64(0.0): np.int64(3), np.float64(0.5): np.int64(12), np.float64(1.0): np.int64(23)}\n",
      "  ⚠️  Missing classes in train: {2}\n",
      "  ⚠️  Missing classes in test: {2}\n",
      "\n",
      "Movement Smoothness:\n",
      "  Train: {np.float64(0.0): np.int64(74), np.float64(0.5): np.int64(5), np.float64(1.0): np.int64(33)}\n",
      "  Test:  {np.float64(0.0): np.int64(27), np.float64(1.0): np.int64(11)}\n",
      "  ⚠️  Missing classes in train: {2}\n",
      "  ⚠️  Missing classes in test: {2}\n"
     ]
    }
   ],
   "source": [
    "# Stratified split to ensure all classes are represented in both train and test sets\n",
    "print(\"Splitting data with stratification...\")\n",
    "\n",
    "# Check class distributions before splitting\n",
    "print(\"Class distributions before splitting:\")\n",
    "for i, concept in enumerate(['Periodicity', 'Temporal Stability', 'Coordination', 'Movement Variability', 'Movement Consistency', 'Movement Smoothness']):\n",
    "    labels = [y_p, y_t, y_c, y_mv, y_mc, y_ms][i]\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"  {concept}: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# Use stratification on the most balanced concept (or create a combined stratification strategy)\n",
    "# For now, let's stratify on periodicity as it's one of the human-labeled concepts\n",
    "X_train, X_test, y_p_train, y_p_test, y_t_train, y_t_test, y_c_train, y_c_test, y_mv_train, y_mv_test, y_mc_train, y_mc_test, y_ms_train, y_ms_test, y_sp_train, y_sp_test = train_test_split(\n",
    "    X, y_p, y_t, y_c, y_mv, y_mc, y_ms, y_sp, test_size=0.25, random_state=42, stratify=y_p\n",
    ")\n",
    "\n",
    "# Convert static posture to binary context (0.0 -> 0, 1.0 -> 1)\n",
    "y_sp_context_train = (y_sp_train > 0).astype(int)\n",
    "y_sp_context_test = (y_sp_test > 0).astype(int)\n",
    "\n",
    "print(f\"Train: {len(X_train)} windows\")\n",
    "print(f\"Test: {len(X_test)} windows\")\n",
    "print(f\"Static context train: {np.bincount(y_sp_context_train)}\")\n",
    "print(f\"Static context test: {np.bincount(y_sp_context_test)}\")\n",
    "\n",
    "# Verify that all classes are represented in both train and test sets\n",
    "print(\"\\n=== CLASS REPRESENTATION VERIFICATION ===\")\n",
    "concepts = ['Periodicity', 'Temporal Stability', 'Coordination', 'Movement Variability', 'Movement Consistency', 'Movement Smoothness']\n",
    "train_labels = [y_p_train, y_t_train, y_c_train, y_mv_train, y_mc_train, y_ms_train]\n",
    "test_labels = [y_p_test, y_t_test, y_c_test, y_mv_test, y_mc_test, y_ms_test]\n",
    "\n",
    "for i, concept in enumerate(concepts):\n",
    "    print(f\"\\n{concept}:\")\n",
    "    train_unique, train_counts = np.unique(train_labels[i], return_counts=True)\n",
    "    test_unique, test_counts = np.unique(test_labels[i], return_counts=True)\n",
    "    print(f\"  Train: {dict(zip(train_unique, train_counts))}\")\n",
    "    print(f\"  Test:  {dict(zip(test_unique, test_counts))}\")\n",
    "    \n",
    "    # Check if all classes are present in both sets\n",
    "    train_classes = set(train_unique)\n",
    "    test_classes = set(test_unique)\n",
    "    all_classes = set(range(3))  # 0, 1, 2 for 3-bin classification\n",
    "    \n",
    "    missing_train = all_classes - train_classes\n",
    "    missing_test = all_classes - test_classes\n",
    "    \n",
    "    if missing_train:\n",
    "        print(f\"  ⚠️  Missing classes in train: {missing_train}\")\n",
    "    if missing_test:\n",
    "        print(f\"  ⚠️  Missing classes in test: {missing_test}\")\n",
    "    if not missing_train and not missing_test:\n",
    "        print(f\"  ✅ All classes represented in both sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Augmentation\n",
    "\n",
    "**Purpose**: Apply augmentation to training data to increase dataset size and robustness.\n",
    "\n",
    "**Process**:\n",
    "- Apply jitter, scaling, and rotation augmentations\n",
    "- 10x augmentation factor (1,232 total training samples)\n",
    "- Convert static posture to binary context for augmented data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training data...\n",
      "Original train: 112 windows\n",
      "Augmented train: 2352 windows\n",
      "Augmentation factor: 21.0x\n",
      "Static context train aug: [2288   64]\n"
     ]
    }
   ],
   "source": [
    "# Apply augmentation\n",
    "print(\"Augmenting training data...\")\n",
    "X_train_aug, y_p_train_aug, y_t_train_aug, y_c_train_aug, y_mv_train_aug, y_mc_train_aug, y_ms_train_aug, y_sp_train_aug = augment_dataset(\n",
    "    X_train, y_p_train, y_t_train, y_c_train, y_mv_train, y_mc_train, y_ms_train, y_sp_train, factor=20\n",
    ")\n",
    "\n",
    "# Convert static posture to binary context for augmented data\n",
    "y_sp_context_train_aug = (y_sp_train_aug > 0).astype(int)\n",
    "\n",
    "print(f\"Original train: {len(X_train)} windows\")\n",
    "print(f\"Augmented train: {len(X_train_aug)} windows\")\n",
    "print(f\"Augmentation factor: {len(X_train_aug) / len(X_train):.1f}x\")\n",
    "print(f\"Static context train aug: {np.bincount(y_sp_context_train_aug)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Label Conversion to Categorical\n",
    "\n",
    "**Purpose**: Convert discrete labels to categorical format for multi-class classification.\n",
    "\n",
    "**Process**:\n",
    "- Convert all concept labels to 3-class categorical format\n",
    "- Static context remains as binary (0 or 1)\n",
    "- Prepare labels for model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels converted to categorical format\n",
      "Static context train shape: (2352,)\n",
      "Static context test shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to categorical for all concepts (3-bin classification)\n",
    "# Convert [0.0, 0.5, 1.0] to [0, 1, 2] for proper categorical encoding\n",
    "y_p_train_cat = to_categorical((y_p_train_aug * 2).astype(int), num_classes=3)\n",
    "y_t_train_cat = to_categorical((y_t_train_aug * 2).astype(int), num_classes=3)\n",
    "y_c_train_cat = to_categorical((y_c_train_aug * 2).astype(int), num_classes=3)\n",
    "y_mv_train_cat = to_categorical((y_mv_train_aug * 2).astype(int), num_classes=3)\n",
    "y_mc_train_cat = to_categorical((y_mc_train_aug * 2).astype(int), num_classes=3)\n",
    "y_ms_train_cat = to_categorical((y_ms_train_aug * 2).astype(int), num_classes=3)\n",
    "\n",
    "y_p_test_cat = to_categorical((y_p_test * 2).astype(int), num_classes=3)\n",
    "y_t_test_cat = to_categorical((y_t_test * 2).astype(int), num_classes=3)\n",
    "y_c_test_cat = to_categorical((y_c_test * 2).astype(int), num_classes=3)\n",
    "y_mv_test_cat = to_categorical((y_mv_test * 2).astype(int), num_classes=3)\n",
    "y_mc_test_cat = to_categorical((y_mc_test * 2).astype(int), num_classes=3)\n",
    "y_ms_test_cat = to_categorical((y_ms_test * 2).astype(int), num_classes=3)\n",
    "\n",
    "# Static context is already binary (0 or 1), no need for categorical conversion\n",
    "y_sp_context_train_cat = y_sp_context_train_aug.astype(float)\n",
    "y_sp_context_test_cat = y_sp_context_test.astype(float)\n",
    "\n",
    "print(\"Labels converted to categorical format\")\n",
    "print(f\"Static context train shape: {y_sp_context_train_cat.shape}\")\n",
    "print(f\"Static context test shape: {y_sp_context_test_cat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Building and Compilation\n",
    "\n",
    "**Purpose**: Build and compile the CNN model for 7 concepts.\n",
    "\n",
    "**Configuration**:\n",
    "- **Optimizer**: Adam (learning_rate=0.001)\n",
    "- **Loss Functions**: Categorical crossentropy for concepts, binary crossentropy for static context\n",
    "- **Loss Weights**: Balanced weights for all concepts\n",
    "- **Metrics**: Accuracy for all outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating model compilation for new rule-based concepts...\n",
      "Model architecture:\n",
      "  Classification concepts: periodicity, temporal_stability, coordination, movement_variability, movement_consistency, movement_smoothness\n",
      "  Contextual concepts: ['motion_intensity', 'vertical_dominance']\n",
      "  Total concepts: 6 (updated model)\n",
      "Model parameters: 1,395\n",
      "Model compiled with classification loss functions for all concepts\n"
     ]
    }
   ],
   "source": [
    "# Updated model compilation for new rule-based concepts\n",
    "print(\"Updating model compilation for new rule-based concepts...\")\n",
    "\n",
    "# Rebuild model with updated architecture (all concepts now classification)\n",
    "model = build_optimized_cnn(\n",
    "    input_shape=(X_train_aug.shape[1], X_train_aug.shape[2]),\n",
    "    n_classes_p=3, n_classes_t=3, n_classes_c=3, n_classes_mv=3, n_classes_mc=3, n_classes_ms=3,\n",
    "    contextual_config=contextual_config\n",
    ")\n",
    "\n",
    "# Compile with classification loss functions for all concepts\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        'periodicity': 'categorical_crossentropy',\n",
    "        'temporal_stability': 'categorical_crossentropy',\n",
    "        'coordination': 'categorical_crossentropy',\n",
    "        'movement_variability': 'categorical_crossentropy',\n",
    "        'movement_consistency': 'categorical_crossentropy',\n",
    "        'movement_smoothness': 'categorical_crossentropy',\n",
    "        'static_context': 'binary_crossentropy',\n",
    "    },\n",
    "    loss_weights={'periodicity': 1.0, 'temporal_stability': 1.0, 'coordination': 1.0, 'movement_variability': 1.0, 'movement_consistency': 1.0, 'movement_smoothness': 1.0, 'static_context': 0.5},\n",
    "    metrics={\n",
    "        'periodicity': ['accuracy'],\n",
    "        'temporal_stability': ['accuracy'],\n",
    "        'coordination': ['accuracy'],\n",
    "        'movement_variability': ['accuracy'],\n",
    "        'movement_consistency': ['accuracy'],\n",
    "        'movement_smoothness': ['accuracy'],\n",
    "        'static_context': ['accuracy'],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {model.count_params():,}\")\n",
    "print(\"Model compiled with classification loss functions for all concepts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data with new rule-based concepts...\n",
      "Movement variability train distribution: [1872  480]\n",
      "Movement consistency train distribution: [ 914 1438]\n",
      "Movement smoothness train distribution: [1647  705]\n",
      "Movement variability test distribution: [31  7]\n",
      "Movement consistency test distribution: [15 23]\n",
      "Movement smoothness test distribution: [27 11]\n",
      "Training data prepared with new rule-based concepts\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data with new rule-based concepts\n",
    "print(\"Preparing training data with new rule-based concepts...\")\n",
    "\n",
    "# All concepts are now categorical (3-bin classification)\n",
    "print(f\"Movement variability train distribution: {np.bincount(y_mv_train_aug.astype(int))}\")\n",
    "print(f\"Movement consistency train distribution: {np.bincount(y_mc_train_aug.astype(int))}\")\n",
    "print(f\"Movement smoothness train distribution: {np.bincount(y_ms_train_aug.astype(int))}\")\n",
    "print(f\"Movement variability test distribution: {np.bincount(y_mv_test.astype(int))}\")\n",
    "print(f\"Movement consistency test distribution: {np.bincount(y_mc_test.astype(int))}\")\n",
    "print(f\"Movement smoothness test distribution: {np.bincount(y_ms_test.astype(int))}\")\n",
    "\n",
    "# Prepare training data with categorical concepts\n",
    "train_data = [\n",
    "    y_p_train_cat, y_t_train_cat, y_c_train_cat, \n",
    "    y_mv_train_cat,  # Categorical values for classification\n",
    "    y_mc_train_cat,  # Categorical values for classification\n",
    "    y_ms_train_cat,  # Categorical values for classification\n",
    "    y_sp_context_train_cat\n",
    "]\n",
    "\n",
    "test_data = [\n",
    "    y_p_test_cat, y_t_test_cat, y_c_test_cat, \n",
    "    y_mv_test_cat,  # Categorical values for classification\n",
    "    y_mc_test_cat,  # Categorical values for classification\n",
    "    y_ms_test_cat,  # Categorical values for classification\n",
    "    y_sp_context_test_cat\n",
    "]\n",
    "\n",
    "print(\"Training data prepared with new rule-based concepts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with new rule-based concepts...\n",
      "Epoch 1/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - coordination_accuracy: 0.4885 - coordination_loss: 1.0556 - loss: 7.0567 - movement_consistency_accuracy: 0.4511 - movement_consistency_loss: 1.1696 - movement_smoothness_accuracy: 0.4349 - movement_smoothness_loss: 1.0940 - movement_variability_accuracy: 0.5480 - movement_variability_loss: 0.9877 - periodicity_accuracy: 0.4549 - periodicity_loss: 1.1001 - static_context_accuracy: 0.5242 - static_context_loss: 0.7557 - temporal_stability_accuracy: 0.3550 - temporal_stability_loss: 1.2682 - val_coordination_accuracy: 0.7368 - val_coordination_loss: 0.8563 - val_loss: 5.7049 - val_movement_consistency_accuracy: 0.7105 - val_movement_consistency_loss: 0.8093 - val_movement_smoothness_accuracy: 0.7105 - val_movement_smoothness_loss: 0.7441 - val_movement_variability_accuracy: 0.8421 - val_movement_variability_loss: 0.8911 - val_periodicity_accuracy: 0.3158 - val_periodicity_loss: 1.3254 - val_static_context_accuracy: 0.2895 - val_static_context_loss: 0.8093 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.8323 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.6356 - coordination_loss: 0.8881 - loss: 5.3506 - movement_consistency_accuracy: 0.6173 - movement_consistency_loss: 0.8636 - movement_smoothness_accuracy: 0.7415 - movement_smoothness_loss: 0.7566 - movement_variability_accuracy: 0.7581 - movement_variability_loss: 0.6965 - periodicity_accuracy: 0.6016 - periodicity_loss: 0.8645 - static_context_accuracy: 0.5804 - static_context_loss: 0.6785 - temporal_stability_accuracy: 0.5523 - temporal_stability_loss: 0.9392 - val_coordination_accuracy: 0.7632 - val_coordination_loss: 0.8075 - val_loss: 4.8807 - val_movement_consistency_accuracy: 0.6316 - val_movement_consistency_loss: 0.9069 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.5748 - val_movement_variability_accuracy: 0.8684 - val_movement_variability_loss: 0.7084 - val_periodicity_accuracy: 0.5263 - val_periodicity_loss: 1.0373 - val_static_context_accuracy: 0.9211 - val_static_context_loss: 0.5808 - val_temporal_stability_accuracy: 0.7895 - val_temporal_stability_loss: 0.7440 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7037 - coordination_loss: 0.7877 - loss: 4.5685 - movement_consistency_accuracy: 0.6832 - movement_consistency_loss: 0.7737 - movement_smoothness_accuracy: 0.8644 - movement_smoothness_loss: 0.5611 - movement_variability_accuracy: 0.8095 - movement_variability_loss: 0.5853 - periodicity_accuracy: 0.6526 - periodicity_loss: 0.7782 - static_context_accuracy: 0.7083 - static_context_loss: 0.6029 - temporal_stability_accuracy: 0.6837 - temporal_stability_loss: 0.7808 - val_coordination_accuracy: 0.7368 - val_coordination_loss: 0.7939 - val_loss: 4.3982 - val_movement_consistency_accuracy: 0.6053 - val_movement_consistency_loss: 0.9788 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.4692 - val_movement_variability_accuracy: 0.8947 - val_movement_variability_loss: 0.5675 - val_periodicity_accuracy: 0.5526 - val_periodicity_loss: 0.8609 - val_static_context_accuracy: 0.9474 - val_static_context_loss: 0.5280 - val_temporal_stability_accuracy: 0.8421 - val_temporal_stability_loss: 0.6542 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7287 - coordination_loss: 0.7234 - loss: 4.0051 - movement_consistency_accuracy: 0.7334 - movement_consistency_loss: 0.6949 - movement_smoothness_accuracy: 0.9022 - movement_smoothness_loss: 0.4287 - movement_variability_accuracy: 0.8563 - movement_variability_loss: 0.4779 - periodicity_accuracy: 0.6645 - periodicity_loss: 0.7427 - static_context_accuracy: 0.8312 - static_context_loss: 0.5117 - temporal_stability_accuracy: 0.7368 - temporal_stability_loss: 0.6797 - val_coordination_accuracy: 0.7368 - val_coordination_loss: 0.7576 - val_loss: 4.0374 - val_movement_consistency_accuracy: 0.6053 - val_movement_consistency_loss: 1.0657 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.3897 - val_movement_variability_accuracy: 0.9211 - val_movement_variability_loss: 0.4591 - val_periodicity_accuracy: 0.5526 - val_periodicity_loss: 0.7753 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.4654 - val_temporal_stability_accuracy: 0.8684 - val_temporal_stability_loss: 0.5775 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7449 - coordination_loss: 0.6700 - loss: 3.6729 - movement_consistency_accuracy: 0.7445 - movement_consistency_loss: 0.6584 - movement_smoothness_accuracy: 0.9145 - movement_smoothness_loss: 0.3576 - movement_variability_accuracy: 0.8550 - movement_variability_loss: 0.4352 - periodicity_accuracy: 0.6735 - periodicity_loss: 0.7058 - static_context_accuracy: 0.8912 - static_context_loss: 0.4325 - temporal_stability_accuracy: 0.7645 - temporal_stability_loss: 0.6242 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.7535 - val_loss: 3.8996 - val_movement_consistency_accuracy: 0.6053 - val_movement_consistency_loss: 1.0768 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.3929 - val_movement_variability_accuracy: 0.8158 - val_movement_variability_loss: 0.4064 - val_periodicity_accuracy: 0.6053 - val_periodicity_loss: 0.7028 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.3970 - val_temporal_stability_accuracy: 0.8421 - val_temporal_stability_loss: 0.5819 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7496 - coordination_loss: 0.6484 - loss: 3.4601 - movement_consistency_accuracy: 0.7585 - movement_consistency_loss: 0.6156 - movement_smoothness_accuracy: 0.9171 - movement_smoothness_loss: 0.3194 - movement_variability_accuracy: 0.8614 - movement_variability_loss: 0.3962 - periodicity_accuracy: 0.6866 - periodicity_loss: 0.6955 - static_context_accuracy: 0.9145 - static_context_loss: 0.3720 - temporal_stability_accuracy: 0.7725 - temporal_stability_loss: 0.5953 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.7591 - val_loss: 3.7619 - val_movement_consistency_accuracy: 0.6579 - val_movement_consistency_loss: 1.0557 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.3208 - val_movement_variability_accuracy: 0.8684 - val_movement_variability_loss: 0.3843 - val_periodicity_accuracy: 0.6053 - val_periodicity_loss: 0.7035 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.3222 - val_temporal_stability_accuracy: 0.8421 - val_temporal_stability_loss: 0.5926 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7636 - coordination_loss: 0.6216 - loss: 3.2567 - movement_consistency_accuracy: 0.7547 - movement_consistency_loss: 0.6013 - movement_smoothness_accuracy: 0.9222 - movement_smoothness_loss: 0.2841 - movement_variability_accuracy: 0.8793 - movement_variability_loss: 0.3654 - periodicity_accuracy: 0.6998 - periodicity_loss: 0.6655 - static_context_accuracy: 0.9494 - static_context_loss: 0.3022 - temporal_stability_accuracy: 0.7900 - temporal_stability_loss: 0.5665 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.7119 - val_loss: 3.5963 - val_movement_consistency_accuracy: 0.6579 - val_movement_consistency_loss: 1.0220 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.2776 - val_movement_variability_accuracy: 0.8421 - val_movement_variability_loss: 0.3364 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.7086 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.2656 - val_temporal_stability_accuracy: 0.8421 - val_temporal_stability_loss: 0.5692 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7611 - coordination_loss: 0.6108 - loss: 3.1198 - movement_consistency_accuracy: 0.7789 - movement_consistency_loss: 0.5635 - movement_smoothness_accuracy: 0.9247 - movement_smoothness_loss: 0.2664 - movement_variability_accuracy: 0.8869 - movement_variability_loss: 0.3451 - periodicity_accuracy: 0.7083 - periodicity_loss: 0.6436 - static_context_accuracy: 0.9481 - static_context_loss: 0.2735 - temporal_stability_accuracy: 0.7900 - temporal_stability_loss: 0.5512 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.7682 - val_loss: 3.5590 - val_movement_consistency_accuracy: 0.6842 - val_movement_consistency_loss: 0.9687 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.2686 - val_movement_variability_accuracy: 0.8158 - val_movement_variability_loss: 0.3724 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.6864 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.2132 - val_temporal_stability_accuracy: 0.8421 - val_temporal_stability_loss: 0.5975 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7598 - coordination_loss: 0.6015 - loss: 3.0189 - movement_consistency_accuracy: 0.7687 - movement_consistency_loss: 0.5597 - movement_smoothness_accuracy: 0.9294 - movement_smoothness_loss: 0.2443 - movement_variability_accuracy: 0.8865 - movement_variability_loss: 0.3251 - periodicity_accuracy: 0.7079 - periodicity_loss: 0.6296 - static_context_accuracy: 0.9524 - static_context_loss: 0.2371 - temporal_stability_accuracy: 0.7972 - temporal_stability_loss: 0.5378 - val_coordination_accuracy: 0.7632 - val_coordination_loss: 0.6824 - val_loss: 3.3961 - val_movement_consistency_accuracy: 0.6842 - val_movement_consistency_loss: 1.0711 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.2174 - val_movement_variability_accuracy: 0.8947 - val_movement_variability_loss: 0.3138 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.6269 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1697 - val_temporal_stability_accuracy: 0.8421 - val_temporal_stability_loss: 0.5629 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7628 - coordination_loss: 0.5932 - loss: 2.9656 - movement_consistency_accuracy: 0.7730 - movement_consistency_loss: 0.5524 - movement_smoothness_accuracy: 0.9286 - movement_smoothness_loss: 0.2450 - movement_variability_accuracy: 0.8963 - movement_variability_loss: 0.3145 - periodicity_accuracy: 0.7015 - periodicity_loss: 0.6272 - static_context_accuracy: 0.9566 - static_context_loss: 0.2143 - temporal_stability_accuracy: 0.8031 - temporal_stability_loss: 0.5265 - val_coordination_accuracy: 0.7368 - val_coordination_loss: 0.6902 - val_loss: 3.4213 - val_movement_consistency_accuracy: 0.6842 - val_movement_consistency_loss: 1.0851 - val_movement_smoothness_accuracy: 0.9737 - val_movement_smoothness_loss: 0.2300 - val_movement_variability_accuracy: 0.9211 - val_movement_variability_loss: 0.2937 - val_periodicity_accuracy: 0.6316 - val_periodicity_loss: 0.6853 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1655 - val_temporal_stability_accuracy: 0.8421 - val_temporal_stability_loss: 0.5571 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m38/74\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - coordination_accuracy: 0.7789 - coordination_loss: 0.5847 - loss: 2.9821 - movement_consistency_accuracy: 0.7675 - movement_consistency_loss: 0.5637 - movement_smoothness_accuracy: 0.9144 - movement_smoothness_loss: 0.2706 - movement_variability_accuracy: 0.9125 - movement_variability_loss: 0.2832 - periodicity_accuracy: 0.6984 - periodicity_loss: 0.6407 - static_context_accuracy: 0.9557 - static_context_loss: 0.2173 - temporal_stability_accuracy: 0.7803 - temporal_stability_loss: 0.5307 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train model with new rule-based concepts\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining model with new rule-based concepts...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining completed with new rule-based concepts\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:401\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_eval_epoch_iterator\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mself\u001b[39m._eval_epoch_iterator = TFEpochIterator(\n\u001b[32m    392\u001b[39m         x=val_x,\n\u001b[32m    393\u001b[39m         y=val_y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    399\u001b[39m         shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    400\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m val_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m val_logs = {\n\u001b[32m    412\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_\u001b[39m\u001b[33m\"\u001b[39m + name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs.items()\n\u001b[32m    413\u001b[39m }\n\u001b[32m    414\u001b[39m epoch_logs.update(val_logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:489\u001b[39m, in \u001b[36mTensorFlowTrainer.evaluate\u001b[39m\u001b[34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    488\u001b[39m     callbacks.on_test_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m     callbacks.on_test_batch_end(end_step, logs)\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_evaluating:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/dsai-project/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train model with new rule-based concepts\n",
    "print(\"Training model with new rule-based concepts...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_aug, train_data,\n",
    "    validation_data=(X_test, test_data),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed with new rule-based concepts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with new rule-based concepts...\n",
      "\n",
      "=== MODEL PERFORMANCE ===\n",
      "Periodicity Accuracy: 71.1%\n",
      "Temporal Stability Accuracy: 78.9%\n",
      "Coordination Accuracy: 65.8%\n",
      "Movement Variability Accuracy: 89.5%\n",
      "Movement Consistency Accuracy: 71.1%\n",
      "\n",
      "Overall Accuracy (5 concepts): 75.3%\n",
      "\n",
      "Note: All concepts now use 3-bin classification with new rule-based motion concepts\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with new rule-based concepts\n",
    "print(\"Evaluating model with new rule-based concepts...\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Extract predictions for each concept\n",
    "periodicity_pred = np.argmax(predictions[0], axis=1)\n",
    "temporal_stability_pred = np.argmax(predictions[1], axis=1)\n",
    "coordination_pred = np.argmax(predictions[2], axis=1)\n",
    "movement_variability_pred = np.argmax(predictions[3], axis=1)\n",
    "movement_consistency_pred = np.argmax(predictions[4], axis=1)\n",
    "movement_smoothness_pred = np.argmax(predictions[5], axis=1)\n",
    "\n",
    "# Extract true labels\n",
    "periodicity_true = np.argmax(y_p_test_cat, axis=1)\n",
    "temporal_stability_true = np.argmax(y_t_test_cat, axis=1)\n",
    "coordination_true = np.argmax(y_c_test_cat, axis=1)\n",
    "movement_variability_true = np.argmax(y_mv_test_cat, axis=1)\n",
    "movement_consistency_true = np.argmax(y_mc_test_cat, axis=1)\n",
    "movement_smoothness_true = np.argmax(y_ms_test_cat, axis=1)\n",
    "\n",
    "# Calculate accuracies for all concepts\n",
    "periodicity_acc = accuracy_score(periodicity_true, periodicity_pred)\n",
    "temporal_stability_acc = accuracy_score(temporal_stability_true, temporal_stability_pred)\n",
    "coordination_acc = accuracy_score(coordination_true, coordination_pred)\n",
    "movement_variability_acc = accuracy_score(movement_variability_true, movement_variability_pred)\n",
    "movement_consistency_acc = accuracy_score(movement_consistency_true, movement_consistency_pred)\n",
    "movement_smoothness_acc = accuracy_score(movement_smoothness_true, movement_smoothness_pred)\n",
    "\n",
    "print(f\"\\n=== MODEL PERFORMANCE ===\")\n",
    "print(f\"Periodicity Accuracy: {periodicity_acc*100:.1f}%\")\n",
    "print(f\"Temporal Stability Accuracy: {temporal_stability_acc*100:.1f}%\")\n",
    "print(f\"Coordination Accuracy: {coordination_acc*100:.1f}%\")\n",
    "print(f\"Movement Variability Accuracy: {movement_variability_acc*100:.1f}%\")\n",
    "print(f\"Movement Consistency Accuracy: {movement_consistency_acc*100:.1f}%\")\n",
    "print(f\"Movement Smoothness Accuracy: {movement_smoothness_acc*100:.1f}%\")\n",
    "# Calculate overall accuracy (all concepts)\n",
    "overall_acc = (periodicity_acc + temporal_stability_acc + coordination_acc + movement_variability_acc + movement_consistency_acc + movement_smoothness_acc) / 6\n",
    "print(f\"\\nOverall Accuracy (6 concepts): {overall_acc*100:.1f}%\")\n",
    "\n",
    "print(\"\\nNote: All concepts now use 3-bin classification with new rule-based motion concepts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUROC for all classification concepts...\n",
      "Getting model predictions...\n",
      "\n",
      "=== AUROC ANALYSIS ===\n",
      "Concept              AUROC      Interpretation\n",
      "------------------------------------------------------------\n",
      "Periodicity          0.847      Good\n",
      "Temporal Stability   0.910      Excellent\n",
      "Coordination         0.840      Good\n",
      "Movement Variability 0.993      Excellent\n",
      "Movement Consistency 0.810      Good\n",
      "------------------------------------------------------------\n",
      "Average AUROC        0.880      Overall Performance\n",
      "\n",
      "=== AUROC INSIGHTS ===\n",
      "• AUROC is robust to class imbalance (unlike accuracy)\n",
      "• Values closer to 1.0 indicate better discrimination ability\n",
      "• 0.5 = random guessing, 1.0 = perfect classification\n",
      "• More meaningful than accuracy for imbalanced datasets\n",
      "\n",
      "=== AUROC vs ACCURACY COMPARISON ===\n",
      "Concept              Accuracy   AUROC      Difference\n",
      "------------------------------------------------------------\n",
      "Periodicity          0.711      0.847      +0.136\n",
      "Temporal Stability   0.789      0.910      +0.120\n",
      "Coordination         0.658      0.840      +0.183\n",
      "Movement Variability 0.895      0.993      +0.099\n",
      "Movement Consistency 0.711      0.810      +0.099\n",
      "\n",
      "Note: AUROC provides a more balanced view of model performance,\n",
      "especially important for imbalanced datasets like yours.\n",
      "\n",
      "=== CONCEPT CORRELATION ANALYSIS ===\n",
      "Analyzing correlations between all concepts...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONCEPT CORRELATION INSIGHTS ===\n",
      "High correlations (>0.5) indicate potential redundancy:\n",
      "Periodicity ↔ Movement Variability: 0.669\n",
      "Temporal Stability ↔ Coordination: 0.547\n",
      "Coordination ↔ Movement Consistency: -0.607\n",
      "\n",
      "=== NEW RULE-BASED CONCEPTS ANALYSIS ===\n",
      "Comparing new rule-based concepts with human-labeled concepts:\n",
      "• Movement Variability: 0.993 AUROC\n",
      "• Movement Consistency: 0.810 AUROC\n",
      "• Human concepts average: 0.866 AUROC\n",
      "✅ New rule-based concepts are performing well!\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUROC for all classification concepts\n",
    "print(\"Calculating AUROC for all classification concepts...\")\n",
    "\n",
    "# Get predictions from the model\n",
    "print(\"Getting model predictions...\")\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Get prediction probabilities for all classification concepts\n",
    "periodicity_proba = predictions[0]  # Shape: (n_samples, 3)\n",
    "temporal_stability_proba = predictions[1]  # Shape: (n_samples, 3)\n",
    "coordination_proba = predictions[2]  # Shape: (n_samples, 3)\n",
    "movement_variability_proba = predictions[3]  # Shape: (n_samples, 3)\n",
    "movement_consistency_proba = predictions[4]  # Shape: (n_samples, 3)\n",
    "movement_smoothness_proba = predictions[5]  # Shape: (n_samples, 3)\n",
    "\n",
    "# Calculate AUROC for each classification concept\n",
    "classification_concepts = [\n",
    "    ('Periodicity', periodicity_true, periodicity_proba),\n",
    "    ('Temporal Stability', temporal_stability_true, temporal_stability_proba),\n",
    "    ('Coordination', coordination_true, coordination_proba),\n",
    "    ('Movement Variability', movement_variability_true, movement_variability_proba),\n",
    "    ('Movement Consistency', movement_consistency_true, movement_consistency_proba),\n",
    "    ('Movement Smoothness', movement_smoothness_true, movement_smoothness_proba)\n",
    "]\n",
    "\n",
    "auroc_scores = {}\n",
    "\n",
    "print(f\"\\n=== AUROC ANALYSIS ===\")\n",
    "print(f\"{'Concept':<20} {'AUROC':<10} {'Interpretation'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, y_true, y_proba in classification_concepts:\n",
    "    try:\n",
    "        # Calculate AUROC using one-vs-rest approach\n",
    "        auroc = roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro')\n",
    "        auroc_scores[name] = auroc\n",
    "        \n",
    "        # Interpretation\n",
    "        if auroc >= 0.9:\n",
    "            interpretation = \"Excellent\"\n",
    "        elif auroc >= 0.8:\n",
    "            interpretation = \"Good\"\n",
    "        elif auroc >= 0.7:\n",
    "            interpretation = \"Fair\"\n",
    "        elif auroc >= 0.6:\n",
    "            interpretation = \"Poor\"\n",
    "        else:\n",
    "            interpretation = \"Very Poor\"\n",
    "            \n",
    "        print(f\"{name:<20} {auroc:<10.3f} {interpretation}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{name:<20} {'Error':<10} {str(e)[:30]}...\")\n",
    "        auroc_scores[name] = 0.0\n",
    "\n",
    "# Calculate average AUROC\n",
    "avg_auroc = np.mean(list(auroc_scores.values()))\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Average AUROC':<20} {avg_auroc:<10.3f} {'Overall Performance'}\")\n",
    "\n",
    "print(f\"\\n=== AUROC INSIGHTS ===\")\n",
    "print(f\"• AUROC is robust to class imbalance (unlike accuracy)\")\n",
    "print(f\"• Values closer to 1.0 indicate better discrimination ability\")\n",
    "print(f\"• 0.5 = random guessing, 1.0 = perfect classification\")\n",
    "print(f\"• More meaningful than accuracy for imbalanced datasets\")\n",
    "\n",
    "# Compare AUROC vs Accuracy\n",
    "print(f\"\\n=== AUROC vs ACCURACY COMPARISON ===\")\n",
    "print(f\"{'Concept':<20} {'Accuracy':<10} {'AUROC':<10} {'Difference'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "accuracy_scores = [periodicity_acc, temporal_stability_acc, coordination_acc, movement_variability_acc, movement_consistency_acc, movement_smoothness_acc]\n",
    "concept_names = ['Periodicity', 'Temporal Stability', 'Coordination', 'Movement Variability', 'Movement Consistency', 'Movement Smoothness']\n",
    "\n",
    "for i, (name, acc, auroc) in enumerate(zip(concept_names, accuracy_scores, list(auroc_scores.values()))):\n",
    "    diff = auroc - acc\n",
    "    print(f\"{name:<20} {acc:<10.3f} {auroc:<10.3f} {diff:+.3f}\")\n",
    "\n",
    "print(f\"\\nNote: AUROC provides a more balanced view of model performance,\")\n",
    "print(f\"especially important for imbalanced datasets like yours.\")\n",
    "\n",
    "# Calculate concept correlation analysis\n",
    "print(f\"\\n=== CONCEPT CORRELATION ANALYSIS ===\")\n",
    "print(\"Analyzing correlations between all concepts...\")\n",
    "\n",
    "# Create correlation matrix of true labels\n",
    "concept_labels = np.column_stack([\n",
    "    periodicity_true, temporal_stability_true, coordination_true,\n",
    "    movement_variability_true, movement_consistency_true, movement_smoothness_true\n",
    "])\n",
    "\n",
    "correlation_matrix = np.corrcoef(concept_labels.T)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            xticklabels=concept_names,\n",
    "            yticklabels=concept_names,\n",
    "            fmt='.2f')\n",
    "\n",
    "plt.title('Concept Correlation Matrix (True Labels)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlation insights\n",
    "print(\"=== CONCEPT CORRELATION INSIGHTS ===\")\n",
    "print(\"High correlations (>0.5) indicate potential redundancy:\")\n",
    "for i in range(len(concept_names)):\n",
    "    for j in range(i+1, len(concept_names)):\n",
    "        corr = correlation_matrix[i, j]\n",
    "        if abs(corr) > 0.5:\n",
    "            print(f\"{concept_names[i]} ↔ {concept_names[j]}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\n=== NEW RULE-BASED CONCEPTS ANALYSIS ===\")\n",
    "print(\"Comparing new rule-based concepts with human-labeled concepts:\")\n",
    "print(f\"• Movement Variability: {auroc_scores.get('Movement Variability', 0):.3f} AUROC\")\n",
    "print(f\"• Movement Consistency: {auroc_scores.get('Movement Consistency', 0):.3f} AUROC\")\n",
    "print(f\"• Movement Smoothness: {auroc_scores.get('Movement Smoothness', 0):.3f} AUROC\")\n",
    "print(f\"• Human concepts average: {np.mean([auroc_scores.get('Periodicity', 0), auroc_scores.get('Temporal Stability', 0), auroc_scores.get('Coordination', 0)]):.3f} AUROC\")\n",
    "\n",
    "rule_avg = np.mean([auroc_scores.get('Movement Variability', 0), auroc_scores.get('Movement Consistency', 0), auroc_scores.get('Movement Smoothness', 0)])\n",
    "if rule_avg > 0.7:\n",
    "    print(\"✅ New rule-based concepts are performing well!\")\n",
    "else:\n",
    "    print(\"⚠️  New rule-based concepts may need further refinement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Training\n",
    "\n",
    "**Purpose**: Train the CNN model with early stopping and learning rate reduction.\n",
    "\n",
    "**Training Configuration**:\n",
    "- **Epochs**: 200 (with early stopping)\n",
    "- **Batch Size**: 32\n",
    "- **Callbacks**: EarlyStopping (patience=10), ReduceLROnPlateau (patience=5)\n",
    "- **Validation**: 25% of data for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFICATION TESTS FOR NEW RULE-BASED CONCEPTS\n",
      "================================================================================\n",
      "\n",
      "🔍 TEST 1: MOVEMENT VARIABILITY CONFUSION MATRIX\n",
      "--------------------------------------------------\n",
      "Movement Variability Confusion Matrix:\n",
      "True\\Pred    0    1    2\n",
      "    0      15    0    0\n",
      "    1       0   11    1\n",
      "    2       0    3    8\n",
      "\n",
      "Per-class metrics:\n",
      "   Low: Precision=1.000, Recall=1.000, F1=1.000\n",
      "Medium: Precision=0.786, Recall=0.917, F1=0.846\n",
      "  High: Precision=0.889, Recall=0.727, F1=0.800\n",
      "\n",
      "Perfect classification: False\n",
      "\n",
      "🔍 TEST 2: MOVEMENT CONSISTENCY CONFUSION MATRIX\n",
      "--------------------------------------------------\n",
      "Movement Consistency Confusion Matrix:\n",
      "True\\Pred    0    1    2\n",
      "    0       2    1    0\n",
      "    1       1    5    6\n",
      "    2       1    2   20\n",
      "\n",
      "Per-class metrics:\n",
      "   Low: Precision=0.500, Recall=0.667, F1=0.571\n",
      "Medium: Precision=0.625, Recall=0.417, F1=0.500\n",
      "  High: Precision=0.769, Recall=0.870, F1=0.816\n",
      "\n",
      "🔍 TEST 3: CLASS DISTRIBUTION ANALYSIS\n",
      "--------------------------------------------------\n",
      "True label distributions:\n",
      "         Periodicity: {np.int64(0): np.int64(23), np.int64(1): np.int64(8), np.int64(2): np.int64(7)}\n",
      "  Temporal Stability: {np.int64(0): np.int64(4), np.int64(1): np.int64(20), np.int64(2): np.int64(14)}\n",
      "        Coordination: {np.int64(0): np.int64(5), np.int64(1): np.int64(14), np.int64(2): np.int64(19)}\n",
      "Movement Variability: {np.int64(0): np.int64(15), np.int64(1): np.int64(12), np.int64(2): np.int64(11)}\n",
      "Movement Consistency: {np.int64(0): np.int64(3), np.int64(1): np.int64(12), np.int64(2): np.int64(23)}\n",
      "\n",
      "Predicted label distributions:\n",
      "         Periodicity: {np.int64(0): np.int64(20), np.int64(1): np.int64(11), np.int64(2): np.int64(7)}\n",
      "  Temporal Stability: {np.int64(1): np.int64(26), np.int64(2): np.int64(12)}\n",
      "        Coordination: {np.int64(1): np.int64(21), np.int64(2): np.int64(17)}\n",
      "Movement Variability: {np.int64(0): np.int64(15), np.int64(1): np.int64(14), np.int64(2): np.int64(9)}\n",
      "Movement Consistency: {np.int64(0): np.int64(4), np.int64(1): np.int64(8), np.int64(2): np.int64(26)}\n",
      "\n",
      "🔍 TEST 4: CONCEPT CORRELATION ANALYSIS\n",
      "--------------------------------------------------\n",
      "Correlation matrix (True labels):\n",
      "                      Periodicity  Temporal Stability  Coordination  \\\n",
      "Periodicity                 1.000              -0.095        -0.101   \n",
      "Temporal Stability         -0.095               1.000         0.547   \n",
      "Coordination               -0.101               0.547         1.000   \n",
      "Movement Variability        0.669              -0.300        -0.297   \n",
      "Movement Consistency        0.233              -0.471        -0.607   \n",
      "\n",
      "                      Movement Variability  Movement Consistency  \n",
      "Periodicity                          0.669                 0.233  \n",
      "Temporal Stability                  -0.300                -0.471  \n",
      "Coordination                        -0.297                -0.607  \n",
      "Movement Variability                 1.000                 0.458  \n",
      "Movement Consistency                 0.458                 1.000  \n",
      "\n",
      "High correlations (>0.5):\n",
      "Periodicity ↔ Movement Variability: 0.669\n",
      "Temporal Stability ↔ Coordination: 0.547\n",
      "Coordination ↔ Movement Consistency: -0.607\n",
      "\n",
      "🔍 TEST 5: RULE-BASED CONCEPT VALIDATION\n",
      "--------------------------------------------------\n",
      "Movement Variability validation:\n",
      "Class distribution: {0.0: np.int64(55), 0.5: np.int64(64), 1.0: np.int64(31)}\n",
      "\n",
      "Movement Consistency validation:\n",
      "Class distribution: {0.0: np.int64(11), 0.5: np.int64(47), 1.0: np.int64(92)}\n",
      "\n",
      "🔍 TEST 6: CROSS-VALIDATION ON NEW CONCEPTS\n",
      "--------------------------------------------------\n",
      "Testing Movement Variability with Random Forest (5-fold CV):\n",
      "CV Scores: [0.625      0.375      0.625      0.42857143 0.85714286]\n",
      "Mean CV Score: 0.582 ± 0.171\n",
      "\n",
      "Testing Movement Consistency with Random Forest (5-fold CV):\n",
      "CV Scores: [0.75       0.125      0.875      0.71428571 0.42857143]\n",
      "Mean CV Score: 0.579 ± 0.270\n",
      "\n",
      "🔍 TEST 7: PERFORMANCE SUMMARY\n",
      "--------------------------------------------------\n",
      "AUROC Performance Summary:\n",
      "         Periodicity: 0.847 🟡 Good\n",
      "  Temporal Stability: 0.910 🟢 Excellent\n",
      "        Coordination: 0.840 🟡 Good\n",
      "Movement Variability: 0.993 🟢 Excellent\n",
      "Movement Consistency: 0.810 🟡 Good\n",
      "\n",
      "Overall Assessment:\n",
      "Human-labeled concepts average: 0.866\n",
      "Rule-based concepts average: 0.902\n",
      "Improvement: +0.036\n",
      "✅ Rule-based concepts outperform human-labeled concepts!\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# VERIFICATION TESTS FOR NEW RULE-BASED CONCEPTS\n",
    "print(\"=\" * 80)\n",
    "print(\"VERIFICATION TESTS FOR NEW RULE-BASED CONCEPTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test 1: Movement Variability Confusion Matrix Analysis\n",
    "print(\"\\n🔍 TEST 1: MOVEMENT VARIABILITY CONFUSION MATRIX\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Get Movement Variability confusion matrix\n",
    "mv_cm = confusion_matrix(movement_variability_true, movement_variability_pred)\n",
    "print(\"Movement Variability Confusion Matrix:\")\n",
    "print(\"True\\\\Pred    0    1    2\")\n",
    "for i, row in enumerate(mv_cm):\n",
    "    print(f\"    {i}    {row[0]:4d} {row[1]:4d} {row[2]:4d}\")\n",
    "\n",
    "# Calculate per-class metrics\n",
    "mv_report = classification_report(movement_variability_true, movement_variability_pred, \n",
    "                                target_names=['Low', 'Medium', 'High'], output_dict=True)\n",
    "print(f\"\\nPer-class metrics:\")\n",
    "for class_name in ['Low', 'Medium', 'High']:\n",
    "    metrics = mv_report[class_name]\n",
    "    print(f\"{class_name:>6}: Precision={metrics['precision']:.3f}, Recall={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}\")\n",
    "\n",
    "# Check for perfect classification\n",
    "perfect_classification = (mv_cm == np.diag(np.diag(mv_cm))).all()\n",
    "print(f\"\\nPerfect classification: {perfect_classification}\")\n",
    "if perfect_classification:\n",
    "    print(\"⚠️  WARNING: Perfect classification detected - investigate for data leakage!\")\n",
    "\n",
    "# Test 2: Movement Consistency Confusion Matrix Analysis\n",
    "print(f\"\\n🔍 TEST 2: MOVEMENT CONSISTENCY CONFUSION MATRIX\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "mc_cm = confusion_matrix(movement_consistency_true, movement_consistency_pred)\n",
    "print(\"Movement Consistency Confusion Matrix:\")\n",
    "print(\"True\\\\Pred    0    1    2\")\n",
    "for i, row in enumerate(mc_cm):\n",
    "    print(f\"    {i}    {row[0]:4d} {row[1]:4d} {row[2]:4d}\")\n",
    "\n",
    "mc_report = classification_report(movement_consistency_true, movement_consistency_pred, \n",
    "                                target_names=['Low', 'Medium', 'High'], output_dict=True)\n",
    "print(f\"\\nPer-class metrics:\")\n",
    "for class_name in ['Low', 'Medium', 'High']:\n",
    "    metrics = mc_report[class_name]\n",
    "    print(f\"{class_name:>6}: Precision={metrics['precision']:.3f}, Recall={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}\")\n",
    "\n",
    "# Test 3: Class Distribution Analysis\n",
    "print(f\"\\n🔍 TEST 3: CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"True label distributions:\")\n",
    "for i, concept in enumerate(['Periodicity', 'Temporal Stability', 'Coordination', 'Movement Variability', 'Movement Consistency']):\n",
    "    true_labels = [periodicity_true, temporal_stability_true, coordination_true, \n",
    "                   movement_variability_true, movement_consistency_true][i]\n",
    "    unique, counts = np.unique(true_labels, return_counts=True)\n",
    "    print(f\"{concept:>20}: {dict(zip(unique, counts))}\")\n",
    "\n",
    "print(\"\\nPredicted label distributions:\")\n",
    "for i, concept in enumerate(['Periodicity', 'Temporal Stability', 'Coordination', 'Movement Variability', 'Movement Consistency']):\n",
    "    pred_labels = [periodicity_pred, temporal_stability_pred, coordination_pred, \n",
    "                   movement_variability_pred, movement_consistency_pred][i]\n",
    "    unique, counts = np.unique(pred_labels, return_counts=True)\n",
    "    print(f\"{concept:>20}: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# Test 4: Concept Correlation Analysis\n",
    "print(f\"\\n🔍 TEST 4: CONCEPT CORRELATION ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate correlations between all concepts\n",
    "concept_data = {\n",
    "    'Periodicity': periodicity_true,\n",
    "    'Temporal Stability': temporal_stability_true,\n",
    "    'Coordination': coordination_true,\n",
    "    'Movement Variability': movement_variability_true,\n",
    "    'Movement Consistency': movement_consistency_true\n",
    "}\n",
    "\n",
    "correlation_df = pd.DataFrame(concept_data)\n",
    "correlation_matrix = correlation_df.corr()\n",
    "\n",
    "print(\"Correlation matrix (True labels):\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Identify high correlations\n",
    "print(f\"\\nHigh correlations (>0.5):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr) > 0.5:\n",
    "            print(f\"{correlation_matrix.columns[i]} ↔ {correlation_matrix.columns[j]}: {corr:.3f}\")\n",
    "\n",
    "# Test 5: Rule-Based Concept Validation\n",
    "print(f\"\\n🔍 TEST 5: RULE-BASED CONCEPT VALIDATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check if Movement Variability makes sense\n",
    "print(\"Movement Variability validation:\")\n",
    "mv_stats = df_windows.groupby('movement_variability')['movement_variability'].count()\n",
    "print(f\"Class distribution: {dict(mv_stats)}\")\n",
    "\n",
    "# Check if Movement Consistency makes sense  \n",
    "print(f\"\\nMovement Consistency validation:\")\n",
    "mc_stats = df_windows.groupby('movement_consistency')['movement_consistency'].count()\n",
    "print(f\"Class distribution: {dict(mc_stats)}\")\n",
    "\n",
    "# Test 6: Cross-Validation on New Concepts\n",
    "print(f\"\\n🔍 TEST 6: CROSS-VALIDATION ON NEW CONCEPTS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Quick cross-validation test on Movement Variability\n",
    "print(\"Testing Movement Variability with Random Forest (5-fold CV):\")\n",
    "rf_mv = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "mv_cv_scores = cross_val_score(rf_mv, X_test.reshape(X_test.shape[0], -1), movement_variability_true, cv=5)\n",
    "print(f\"CV Scores: {mv_cv_scores}\")\n",
    "print(f\"Mean CV Score: {mv_cv_scores.mean():.3f} ± {mv_cv_scores.std():.3f}\")\n",
    "\n",
    "print(f\"\\nTesting Movement Consistency with Random Forest (5-fold CV):\")\n",
    "rf_mc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "mc_cv_scores = cross_val_score(rf_mc, X_test.reshape(X_test.shape[0], -1), movement_consistency_true, cv=5)\n",
    "print(f\"CV Scores: {mc_cv_scores}\")\n",
    "print(f\"Mean CV Score: {mc_cv_scores.mean():.3f} ± {mc_cv_scores.std():.3f}\")\n",
    "\n",
    "# Test 7: Performance Summary\n",
    "print(f\"\\n🔍 TEST 7: PERFORMANCE SUMMARY\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"AUROC Performance Summary:\")\n",
    "for concept, auroc in auroc_scores.items():\n",
    "    if auroc >= 0.9:\n",
    "        status = \"🟢 Excellent\"\n",
    "    elif auroc >= 0.8:\n",
    "        status = \"🟡 Good\"\n",
    "    elif auroc >= 0.7:\n",
    "        status = \"🟠 Fair\"\n",
    "    else:\n",
    "        status = \"🔴 Poor\"\n",
    "    print(f\"{concept:>20}: {auroc:.3f} {status}\")\n",
    "\n",
    "print(f\"\\nOverall Assessment:\")\n",
    "human_avg = np.mean([auroc_scores['Periodicity'], auroc_scores['Temporal Stability'], auroc_scores['Coordination']])\n",
    "rule_avg = np.mean([auroc_scores['Movement Variability'], auroc_scores['Movement Consistency']])\n",
    "print(f\"Human-labeled concepts average: {human_avg:.3f}\")\n",
    "print(f\"Rule-based concepts average: {rule_avg:.3f}\")\n",
    "print(f\"Improvement: {rule_avg - human_avg:+.3f}\")\n",
    "\n",
    "if rule_avg > human_avg:\n",
    "    print(\"✅ Rule-based concepts outperform human-labeled concepts!\")\n",
    "else:\n",
    "    print(\"⚠️  Human-labeled concepts still outperform rule-based concepts\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFICATION COMPLETE\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Evaluation\n",
    "\n",
    "**Purpose**: Evaluate model performance on test data and calculate individual concept accuracies.\n",
    "\n",
    "**Metrics**:\n",
    "- Individual accuracy for each of the 7 concepts\n",
    "- Overall accuracy across all concepts\n",
    "- Performance analysis and recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Performance Visualization and Analysis\n",
    "\n",
    "**Purpose**: Comprehensive visualization of model performance, concept relationships, and training insights.\n",
    "\n",
    "**Visualizations**:\n",
    "- Training history plots (loss and accuracy curves)\n",
    "- Concept accuracy comparison charts\n",
    "- Confusion matrices for each concept\n",
    "- Concept correlation heatmap\n",
    "- Performance summary dashboard\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
