{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick CNN Training - Ultra Lightweight + Augmentation\n",
    "\n",
    "## Overview\n",
    "This notebook contains only the essential components for training the ultra-lightweight CNN with augmentation and random shuffle split.\n",
    "\n",
    "## Features\n",
    "- **5 Core Concepts**: periodicity, temporal_stability, coordination, motion_intensity, vertical_dominance\n",
    "- **Data Augmentation**: Jitter, scaling, and rotation for robust training\n",
    "- **Contextual Learning**: Static posture context for motion concepts\n",
    "- **Optimized Architecture**: Lightweight CNN with 1,350 parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration\n",
    "\n",
    "**Purpose**: Load necessary libraries and contextual configuration for model training.\n",
    "\n",
    "**Key Components**:\n",
    "- TensorFlow/Keras for deep learning\n",
    "- Scikit-learn for data preprocessing\n",
    "- Contextual configuration for motion concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Discretization\n",
    "\n",
    "**Purpose**: Load sensor data and convert continuous concept values to discrete categories.\n",
    "\n",
    "**Process**:\n",
    "- Load raw sensor data and window labels\n",
    "- Convert continuous values to discrete (0.0, 0.5, 1.0) for all concepts\n",
    "- Apply discretization rules for motion_intensity and vertical_dominance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Window Extraction Functions\n",
    "\n",
    "**Purpose**: Extract sensor data windows with robust time matching and error handling.\n",
    "\n",
    "**Functions**:\n",
    "- `extract_window_robust()`: Extract single window with time tolerance\n",
    "- `extract_windows_robust()`: Extract all windows for 5 concepts\n",
    "- Handles missing data and time mismatches gracefully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation Functions\n",
    "\n",
    "**Purpose**: Create augmented versions of the dataset to improve model robustness.\n",
    "\n",
    "**Augmentation Types**:\n",
    "- **Jitter**: Add Gaussian noise to simulate sensor imperfections\n",
    "- **Scaling**: Scale magnitude to simulate different movement intensities  \n",
    "- **Rotation**: Rotate 3D data to simulate different phone orientations\n",
    "- **Factor**: 10x augmentation multiplier for robust training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Architecture Definition\n",
    "\n",
    "**Purpose**: Define the optimized CNN architecture for 5 concepts.\n",
    "\n",
    "**Architecture**:\n",
    "- **2 Conv1D layers** (16 filters each) with Batch Normalization\n",
    "- **Global Average Pooling** for dimensionality reduction\n",
    "- **Dropout (0.4)** for regularization\n",
    "- **Contextual Learning**: Static posture context for motion concepts\n",
    "- **Multi-output heads** for each concept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Extraction\n",
    "\n",
    "**Purpose**: Extract sensor windows for all 5 concepts with robust error handling.\n",
    "\n",
    "**Output**: \n",
    "- X: Sensor data (n_windows, timesteps, 3)\n",
    "- y_p, y_t, y_c, y_mi, y_vd, y_sp: Labels for 5 concepts + static context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split\n",
    "\n",
    "**Purpose**: Split data into training and testing sets with proper stratification.\n",
    "\n",
    "**Split**: 75% training, 25% testing\n",
    "**Static Context**: Convert static posture to binary context labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Augmentation\n",
    "\n",
    "**Purpose**: Apply augmentation to training data to increase dataset size and robustness.\n",
    "\n",
    "**Process**:\n",
    "- Apply jitter, scaling, and rotation augmentations\n",
    "- 10x augmentation factor (1,232 total training samples)\n",
    "- Convert static posture to binary context for augmented data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Label Conversion to Categorical\n",
    "\n",
    "**Purpose**: Convert discrete labels to categorical format for multi-class classification.\n",
    "\n",
    "**Process**:\n",
    "- Convert all concept labels to 3-class categorical format\n",
    "- Static context remains as binary (0 or 1)\n",
    "- Prepare labels for model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Building and Compilation\n",
    "\n",
    "**Purpose**: Build and compile the CNN model for 5 concepts.\n",
    "\n",
    "**Configuration**:\n",
    "- **Optimizer**: Adam (learning_rate=0.001)\n",
    "- **Loss Functions**: Categorical crossentropy for concepts, binary crossentropy for static context\n",
    "- **Loss Weights**: Balanced weights for all concepts\n",
    "- **Metrics**: Accuracy for all outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Training\n",
    "\n",
    "**Purpose**: Train the CNN model with early stopping and learning rate reduction.\n",
    "\n",
    "**Training Configuration**:\n",
    "- **Epochs**: 200 (with early stopping)\n",
    "- **Batch Size**: 32\n",
    "- **Callbacks**: EarlyStopping (patience=10), ReduceLROnPlateau (patience=5)\n",
    "- **Validation**: 25% of data for validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Evaluation\n",
    "\n",
    "**Purpose**: Evaluate model performance on test data and calculate individual concept accuracies.\n",
    "\n",
    "**Metrics**:\n",
    "- Individual accuracy for each of the 5 concepts\n",
    "- Overall accuracy across all concepts\n",
    "- Performance analysis and recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Training Visualization\n",
    "\n",
    "**Purpose**: Visualize training progress and concept-specific performance.\n",
    "\n",
    "**Visualizations**:\n",
    "- Training and validation loss curves\n",
    "- Individual concept accuracy over epochs\n",
    "- Final training accuracy summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick CNN Training - Ultra Lightweight + Augmentation\n",
    "## Streamlined version for rapid iteration\n",
    "\n",
    "This notebook contains only the essential components for training the ultra-lightweight CNN with augmentation and random shuffle split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.11.3\n",
      "Warning: contextual_config.json not found. Using default configuration.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# Load contextual configuration from rule definitions\n",
    "try:\n",
    "    with open('../rule_based_labeling/contextual_config.json', 'r') as f:\n",
    "        contextual_config = json.load(f)\n",
    "    print(f\"\\nLoaded contextual configuration:\")\n",
    "    for feature, uses_context in contextual_config.items():\n",
    "        print(f\"  {feature}: {'Uses static posture context' if uses_context else 'Independent'}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: contextual_config.json not found. Using default configuration.\")\n",
    "    contextual_config = {\n",
    "        'motion_intensity': True,\n",
    "        'vertical_dominance': True,\n",
    "        'periodicity': False,\n",
    "        'temporal_stability': False,\n",
    "        'coordination': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor data: 8802 readings\n",
      "Manual labels: 150 windows\n",
      "\n",
      "Labeled windows:\n",
      "   window_idx  user activity  start_time  end_time  periodicity  \\\n",
      "0           0     3  Walking      957.75    960.75          1.0   \n",
      "1           1     3  Walking       42.00     45.00          1.0   \n",
      "2           2     3  Walking      871.50    874.50          0.5   \n",
      "3           3     3  Walking       63.00     66.00          1.0   \n",
      "4           4     3  Jogging      117.75    120.75          1.0   \n",
      "\n",
      "   temporal_stability  coordination  motion_intensity  vertical_dominance  \\\n",
      "0                 0.5           0.5          0.316815            0.221105   \n",
      "1                 0.5           0.5          0.302850            0.291116   \n",
      "2                 0.5           0.5          0.303036            0.181147   \n",
      "3                 0.5           0.5          0.313779            0.305797   \n",
      "4                 0.5           0.5          0.408648            0.262989   \n",
      "\n",
      "   static_posture  \n",
      "0             0.0  \n",
      "1             0.0  \n",
      "2             0.0  \n",
      "3             0.0  \n",
      "4             0.0  \n",
      "\n",
      "Available concepts: ['periodicity', 'temporal_stability', 'coordination', 'motion_intensity', 'vertical_dominance', 'static_posture']\n",
      "Concept distributions:\n",
      "  periodicity: {0.0: np.int64(90), 0.5: np.int64(35), 1.0: np.int64(25)}\n",
      "  temporal_stability: {0.0: np.int64(12), 0.5: np.int64(87), 1.0: np.int64(51)}\n",
      "  coordination: {0.0: np.int64(16), 0.5: np.int64(64), 1.0: np.int64(70)}\n",
      "  motion_intensity: {0.2772373564163808: np.int64(1), 0.2837984269410516: np.int64(1), 0.2883114625007809: np.int64(1), 0.2904395699765311: np.int64(2), 0.2904716361566266: np.int64(2), 0.2905828015146394: np.int64(1), 0.2908408051170124: np.int64(1), 0.2925351640996887: np.int64(1), 0.2933462239699613: np.int64(1), 0.294256600528526: np.int64(1), 0.2943474893705625: np.int64(1), 0.2944169068657106: np.int64(2), 0.2954864408597494: np.int64(1), 0.2955126319669507: np.int64(1), 0.2980937530702702: np.int64(3), 0.2990668335109059: np.int64(2), 0.2993873139305019: np.int64(2), 0.2996145745259591: np.int64(1), 0.3000582848205436: np.int64(1), 0.3004781451635054: np.int64(1), 0.300801518037724: np.int64(1), 0.3015467595820938: np.int64(1), 0.3018746423192373: np.int64(1), 0.3020243134520984: np.int64(1), 0.3028499703475931: np.int64(3), 0.3030356104426947: np.int64(1), 0.3033306443963557: np.int64(1), 0.3042291809162929: np.int64(2), 0.3044952677135827: np.int64(1), 0.3045987463196768: np.int64(1), 0.3054025722123458: np.int64(2), 0.3054655043038867: np.int64(2), 0.3057353301134025: np.int64(1), 0.3065254755568568: np.int64(1), 0.3072135408512293: np.int64(1), 0.3073626400389634: np.int64(1), 0.3076195073111845: np.int64(2), 0.307627188995706: np.int64(1), 0.30788036524805: np.int64(1), 0.308275481399493: np.int64(1), 0.3092909207261241: np.int64(1), 0.3094177785693567: np.int64(1), 0.3103180409398018: np.int64(1), 0.3104063282247876: np.int64(1), 0.3106209686547314: np.int64(1), 0.3106745784108414: np.int64(1), 0.3117464384700492: np.int64(1), 0.3118163646707009: np.int64(1), 0.3122150987121891: np.int64(1), 0.3124640355923014: np.int64(1), 0.3133605113446256: np.int64(1), 0.3136064353355067: np.int64(1), 0.3137789065587562: np.int64(1), 0.3141305805360476: np.int64(1), 0.314491143265748: np.int64(3), 0.3147961429153452: np.int64(1), 0.3148096815035391: np.int64(1), 0.3161111209365336: np.int64(1), 0.31632835253664: np.int64(1), 0.3166762938766498: np.int64(1), 0.316727745242984: np.int64(1), 0.3167658181421907: np.int64(1), 0.3168154682119852: np.int64(1), 0.3180310634765014: np.int64(2), 0.3190262224618787: np.int64(1), 0.3195153714242839: np.int64(1), 0.319577846206767: np.int64(1), 0.3197182218173082: np.int64(2), 0.3199788729993933: np.int64(1), 0.3207083932829794: np.int64(1), 0.3209841715201347: np.int64(1), 0.3210135618567378: np.int64(1), 0.3216996009756706: np.int64(2), 0.3219075447930449: np.int64(1), 0.322457991258209: np.int64(1), 0.3245041388530763: np.int64(1), 0.3245780940640145: np.int64(1), 0.3249723826004875: np.int64(1), 0.3250675208606415: np.int64(1), 0.32541052390235: np.int64(1), 0.3272986738114569: np.int64(1), 0.3297577929684174: np.int64(1), 0.3313313752792833: np.int64(1), 0.332099006235832: np.int64(1), 0.3341604743764423: np.int64(1), 0.3355605534777582: np.int64(2), 0.3359231420154598: np.int64(1), 0.3367810014866235: np.int64(1), 0.3375463594951178: np.int64(1), 0.3377047829614873: np.int64(1), 0.3379958815236917: np.int64(1), 0.3383642216446519: np.int64(1), 0.3383698086764015: np.int64(1), 0.3384516137950631: np.int64(1), 0.3394869622356155: np.int64(1), 0.3410490331269297: np.int64(1), 0.3413897218245468: np.int64(1), 0.3423533047477596: np.int64(1), 0.3450194404389818: np.int64(1), 0.3518887517884267: np.int64(1), 0.3525110861481863: np.int64(1), 0.3562483091263943: np.int64(1), 0.3577756835727624: np.int64(1), 0.3641598873738212: np.int64(1), 0.3651990288022627: np.int64(1), 0.3684943417580639: np.int64(1), 0.3735043295332337: np.int64(1), 0.3747703385024187: np.int64(1), 0.3781080480989578: np.int64(1), 0.3824686629587057: np.int64(1), 0.3849090543035336: np.int64(1), 0.3930184270055168: np.int64(1), 0.3931473798349287: np.int64(1), 0.3953675685606606: np.int64(1), 0.3955271763209982: np.int64(1), 0.3979615581218284: np.int64(1), 0.4043320193720163: np.int64(1), 0.4053919070495184: np.int64(1), 0.4086477498362783: np.int64(1), 0.4101769174203756: np.int64(1), 0.4113300047741564: np.int64(1), 0.412171074913092: np.int64(1), 0.4129680537042481: np.int64(1), 0.4328637070533682: np.int64(1), 0.4347188432339759: np.int64(1), 0.4361241596360841: np.int64(1), 0.4402155466936992: np.int64(1), 0.440872110783343: np.int64(1), 0.443839419267619: np.int64(1), 0.4579584815526467: np.int64(1), 0.4711380329142512: np.int64(1)}\n",
      "  vertical_dominance: {0.0414013589326923: np.int64(1), 0.0498718406227278: np.int64(1), 0.0594944370621943: np.int64(1), 0.1254885371710537: np.int64(1), 0.1274325453816867: np.int64(2), 0.1389969148133974: np.int64(1), 0.1394394101254832: np.int64(1), 0.1418654235066842: np.int64(1), 0.1439392739222041: np.int64(1), 0.1445679194493549: np.int64(1), 0.1458414429506189: np.int64(1), 0.1588285474011569: np.int64(1), 0.1595256419925515: np.int64(1), 0.1614928054085334: np.int64(1), 0.1678146986720644: np.int64(1), 0.1680014838583347: np.int64(1), 0.1691302392816817: np.int64(1), 0.1695024987309993: np.int64(1), 0.1710605436920248: np.int64(1), 0.1737630270200145: np.int64(1), 0.1748578654652793: np.int64(1), 0.1763060080851442: np.int64(1), 0.1767160406806071: np.int64(1), 0.1811308581408615: np.int64(1), 0.1811469240149052: np.int64(1), 0.1874676403970541: np.int64(1), 0.1881332823313627: np.int64(2), 0.1886403065039095: np.int64(1), 0.1888264219553981: np.int64(1), 0.1900202011568653: np.int64(1), 0.1919454176453213: np.int64(1), 0.1930922709785184: np.int64(1), 0.1976011806372864: np.int64(1), 0.1999303846883954: np.int64(1), 0.1999401392303288: np.int64(1), 0.2012226210286131: np.int64(1), 0.2012455081155074: np.int64(1), 0.2029076080958227: np.int64(1), 0.2035491995839586: np.int64(1), 0.2040003503198927: np.int64(1), 0.2066965627326344: np.int64(1), 0.2067402415331694: np.int64(1), 0.2070201400905039: np.int64(1), 0.209631423240424: np.int64(1), 0.210647821970754: np.int64(1), 0.2113030566577581: np.int64(1), 0.2116256600617256: np.int64(1), 0.2127808864002326: np.int64(1), 0.2146436366737131: np.int64(1), 0.2164978758641146: np.int64(1), 0.2174355679918451: np.int64(1), 0.2174861606983785: np.int64(3), 0.2177861767779153: np.int64(2), 0.2211050305890152: np.int64(1), 0.2230745149148952: np.int64(1), 0.2258365858393407: np.int64(1), 0.2285744694171358: np.int64(1), 0.2292827481172151: np.int64(1), 0.2307317819718368: np.int64(1), 0.2316601731421503: np.int64(1), 0.2324461812820856: np.int64(1), 0.2329715053553454: np.int64(1), 0.2333299199683322: np.int64(1), 0.2333327441594597: np.int64(1), 0.2334552898235282: np.int64(1), 0.2334994248322335: np.int64(1), 0.2345500731058654: np.int64(1), 0.2351054941656678: np.int64(1), 0.2352091291993167: np.int64(2), 0.238654682114025: np.int64(1), 0.2391446456334397: np.int64(1), 0.2410401207754916: np.int64(1), 0.2411353492381247: np.int64(1), 0.2432518438223105: np.int64(1), 0.2468530701088953: np.int64(1), 0.2468963305768767: np.int64(1), 0.2474427431024609: np.int64(1), 0.2492150610045135: np.int64(1), 0.2497230909340144: np.int64(1), 0.2514698692300071: np.int64(1), 0.2526585761289738: np.int64(1), 0.2543695277941346: np.int64(1), 0.2543905227921507: np.int64(1), 0.2558198362124588: np.int64(1), 0.2573752742344229: np.int64(1), 0.2574871827872008: np.int64(1), 0.2586314918161142: np.int64(1), 0.2602916233651129: np.int64(1), 0.2617541236932778: np.int64(1), 0.262256972654781: np.int64(2), 0.2622780873899264: np.int64(1), 0.2629893720616242: np.int64(1), 0.2631543963209378: np.int64(1), 0.2654212428627325: np.int64(1), 0.2659411529200373: np.int64(1), 0.2678467691895577: np.int64(1), 0.2680787746452484: np.int64(1), 0.2682396417494164: np.int64(1), 0.2682650737409419: np.int64(1), 0.2702308719081406: np.int64(1), 0.2749546859890832: np.int64(1), 0.2797542134920575: np.int64(1), 0.2882142974760373: np.int64(1), 0.2888393467622078: np.int64(1), 0.2911157550912814: np.int64(3), 0.2919068462864121: np.int64(2), 0.2923271517973126: np.int64(3), 0.2926374245143738: np.int64(1), 0.2960771519640918: np.int64(1), 0.2966642568257807: np.int64(1), 0.3057965562906625: np.int64(1), 0.3097111905683205: np.int64(1), 0.3112446032922987: np.int64(2), 0.31431914305215: np.int64(1), 0.3203045780211706: np.int64(2), 0.3246354451311634: np.int64(2), 0.3249531344610544: np.int64(1), 0.3263709671018792: np.int64(1), 0.3371086847162602: np.int64(1), 0.3476222657524365: np.int64(1), 0.3487761348053768: np.int64(2), 0.3557569442992196: np.int64(1), 0.3563225379676743: np.int64(1), 0.378260918289896: np.int64(1), 0.3788814480247583: np.int64(1), 0.4075928208236769: np.int64(1), 0.4233168046465751: np.int64(2), 0.4316877769463982: np.int64(2), 0.4523401535527765: np.int64(2), 0.5236697387968143: np.int64(1), 0.5620173825162679: np.int64(1)}\n",
      "  static_posture: {0.0: np.int64(150)}\n",
      "\n",
      "Converting rule-based concepts to discrete labels...\n",
      "\n",
      "After discretization:\n",
      "  periodicity: {0.0: np.int64(90), 0.5: np.int64(35), 1.0: np.int64(25)}\n",
      "  temporal_stability: {0.0: np.int64(12), 0.5: np.int64(87), 1.0: np.int64(51)}\n",
      "  coordination: {0.0: np.int64(16), 0.5: np.int64(64), 1.0: np.int64(70)}\n",
      "  motion_intensity: {0.0: np.int64(118), 0.5: np.int64(30), 1.0: np.int64(2)}\n",
      "  vertical_dominance: {0.0: np.int64(37), 0.5: np.int64(100), 1.0: np.int64(13)}\n",
      "  static_posture: {0.0: np.int64(150)}\n"
     ]
    }
   ],
   "source": [
    "# Load data - CHANGE THESE PATHS AS NEEDED\n",
    "df_sensor = pd.read_csv('../rule_based_labeling/raw_with_features.csv')\n",
    "df_windows = pd.read_csv('../rule_based_labeling/window_with_features.csv') \n",
    "\n",
    "print(f\"Sensor data: {len(df_sensor)} readings\")\n",
    "print(f\"Manual labels: {len(df_windows)} windows\")\n",
    "print(f\"\\nLabeled windows:\")\n",
    "print(df_windows.head())\n",
    "\n",
    "# Check available concepts\n",
    "concept_columns = ['periodicity', 'temporal_stability', 'coordination', 'motion_intensity', 'vertical_dominance', 'static_posture']\n",
    "print(f\"\\nAvailable concepts: {concept_columns}\")\n",
    "print(f\"Concept distributions:\")\n",
    "for concept in concept_columns:\n",
    "    if concept in df_windows.columns:\n",
    "        values = df_windows[concept].value_counts().sort_index()\n",
    "        print(f\"  {concept}: {dict(values)}\")\n",
    "\n",
    "# Convert rule-based concepts to discrete labels (0, 0.5, 1.0)\n",
    "print(f\"\\nConverting rule-based concepts to discrete labels...\")\n",
    "\n",
    "# Motion Intensity: Convert continuous values to discrete\n",
    "# Low (0.0): < 0.35, Medium (0.5): 0.35-0.45, High (1.0): > 0.45\n",
    "df_windows['motion_intensity_discrete'] = pd.cut(\n",
    "    df_windows['motion_intensity'], \n",
    "    bins=[-np.inf, 0.35, 0.45, np.inf], \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Vertical Dominance: Convert continuous values to discrete  \n",
    "# Low (0.0): < 0.2, Medium (0.5): 0.2-0.35, High (1.0): > 0.35\n",
    "df_windows['vertical_dominance_discrete'] = pd.cut(\n",
    "    df_windows['vertical_dominance'], \n",
    "    bins=[-np.inf, 0.2, 0.35, np.inf], \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "# Static Posture: Already binary (0.0 or 1.0), keep as is\n",
    "df_windows['static_posture_discrete'] = df_windows['static_posture']\n",
    "\n",
    "# Update the dataframe to use discrete values\n",
    "df_windows['motion_intensity'] = df_windows['motion_intensity_discrete']\n",
    "df_windows['vertical_dominance'] = df_windows['vertical_dominance_discrete']\n",
    "df_windows['static_posture'] = df_windows['static_posture_discrete']\n",
    "\n",
    "# Drop the temporary columns\n",
    "df_windows = df_windows.drop(['motion_intensity_discrete', 'vertical_dominance_discrete', 'static_posture_discrete'], axis=1)\n",
    "\n",
    "print(f\"\\nAfter discretization:\")\n",
    "for concept in concept_columns:\n",
    "    if concept in df_windows.columns:\n",
    "        values = df_windows[concept].value_counts().sort_index()\n",
    "        print(f\"  {concept}: {dict(values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_window_robust(df_sensor, window_row, time_tolerance=0.5):\n",
    "    \"\"\"\n",
    "    Extract sensor data with time tolerance to handle mismatches.\n",
    "    \"\"\"\n",
    "    user = window_row['user']\n",
    "    activity = window_row['activity']\n",
    "    start_time = window_row['start_time']\n",
    "    end_time = window_row['end_time']\n",
    "    \n",
    "    # Get data for this user/activity\n",
    "    user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                  (df_sensor['activity'] == activity)].copy()\n",
    "    \n",
    "    if len(user_activity_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Find data within time window with tolerance\n",
    "    mask = ((user_activity_data['time_s'] >= start_time - time_tolerance) & \n",
    "            (user_activity_data['time_s'] <= end_time + time_tolerance))\n",
    "    \n",
    "    window_data = user_activity_data[mask]\n",
    "    \n",
    "    if len(window_data) < 10:  # Need minimum samples\n",
    "        return None\n",
    "    \n",
    "    # Extract sensor readings\n",
    "    sensor_data = window_data[['x-axis', 'y-axis', 'z-axis']].values\n",
    "    \n",
    "    # Pad or truncate to fixed length (e.g., 100 samples)\n",
    "    target_length = 100\n",
    "    if len(sensor_data) > target_length:\n",
    "        # Randomly sample if too long\n",
    "        indices = np.random.choice(len(sensor_data), target_length, replace=False)\n",
    "        sensor_data = sensor_data[indices]\n",
    "    elif len(sensor_data) < target_length:\n",
    "        # Pad with last value if too short\n",
    "        padding = np.tile(sensor_data[-1:], (target_length - len(sensor_data), 1))\n",
    "        sensor_data = np.vstack([sensor_data, padding])\n",
    "    \n",
    "    return sensor_data\n",
    "\n",
    "def extract_windows_robust(df_sensor, df_windows):\n",
    "    \"\"\"\n",
    "    Extract all windows with robust time matching for 7 concepts.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y_p = []  # periodicity\n",
    "    y_t = []  # temporal_stability\n",
    "    y_c = []  # coordination\n",
    "    y_mi = [] # motion_intensity\n",
    "    y_vd = [] # vertical_dominance\n",
    "    y_sp = [] # static_posture\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        window_data = extract_window_robust(df_sensor, window_row)\n",
    "        if window_data is not None:\n",
    "            X.append(window_data)\n",
    "            y_p.append(window_row['periodicity'])\n",
    "            y_t.append(window_row['temporal_stability'])\n",
    "            y_c.append(window_row['coordination'])\n",
    "            y_mi.append(window_row['motion_intensity'])\n",
    "            y_vd.append(window_row['vertical_dominance'])\n",
    "            y_sp.append(window_row['static_posture'])\n",
    "    \n",
    "    return np.array(X), np.array(y_p), np.array(y_t), np.array(y_c), np.array(y_mi), np.array(y_vd), np.array(y_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_jitter(data, sigma=0.05):\n",
    "    \"\"\"Add random Gaussian noise to simulate sensor imperfections\"\"\"\n",
    "    return data + np.random.normal(0, sigma, data.shape)\n",
    "\n",
    "def augment_scaling(data, sigma=0.1):\n",
    "    \"\"\"Scale magnitude to simulate different movement intensities\"\"\"\n",
    "    # Handle different data shapes\n",
    "    if len(data.shape) == 3:\n",
    "        factor = np.random.normal(1.0, sigma, (data.shape[0], 1, data.shape[2]))\n",
    "    elif len(data.shape) == 2:\n",
    "        factor = np.random.normal(1.0, sigma, (data.shape[0], data.shape[1]))\n",
    "    else:\n",
    "        factor = np.random.normal(1.0, sigma, data.shape)\n",
    "    return data * factor\n",
    "\n",
    "def augment_rotation(data):\n",
    "    \"\"\"Rotate 3D data to simulate different phone orientations\"\"\"\n",
    "    angle = np.random.uniform(-np.pi/6, np.pi/6)  # ±30 degrees\n",
    "    cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_a, -sin_a, 0],\n",
    "        [sin_a, cos_a, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return np.dot(data, rotation_matrix.T)\n",
    "\n",
    "def augment_dataset(X, y_p, y_t, y_c, y_mi, y_vd, y_sp, factor=10):\n",
    "    \"\"\"\n",
    "    Create augmented versions of the dataset for 7 concepts.\n",
    "    \n",
    "    Args:\n",
    "        X: Original data (n_samples, timesteps, 3)\n",
    "        y_p, y_t, y_c, y_mi, y_vd, y_sp, y_mag: Labels for seven concepts\n",
    "        factor: Augmentation multiplier (10 = 10x more data)\n",
    "    \n",
    "    Returns:\n",
    "        Augmented dataset with (factor+1) × original size\n",
    "    \"\"\"\n",
    "    n_original = len(X)\n",
    "    n_augmented = n_original * factor\n",
    "    \n",
    "    # Initialize augmented arrays\n",
    "    X_aug = np.zeros((n_augmented, X.shape[1], X.shape[2]))\n",
    "    y_p_aug = np.zeros(n_augmented)\n",
    "    y_t_aug = np.zeros(n_augmented)\n",
    "    y_c_aug = np.zeros(n_augmented)\n",
    "    y_mi_aug = np.zeros(n_augmented)\n",
    "    y_vd_aug = np.zeros(n_augmented)\n",
    "    y_sp_aug = np.zeros(n_augmented)\n",
    "    \n",
    "    for i in range(n_augmented):\n",
    "        # Randomly select original sample\n",
    "        idx = np.random.randint(0, n_original)\n",
    "        \n",
    "        # Apply random augmentation\n",
    "        aug_type = np.random.choice(['jitter', 'scaling', 'rotation', 'none'])\n",
    "        \n",
    "        if aug_type == 'jitter':\n",
    "            X_aug[i] = augment_jitter(X[idx])\n",
    "        elif aug_type == 'scaling':\n",
    "            X_aug[i] = augment_scaling(X[idx])\n",
    "        elif aug_type == 'rotation':\n",
    "            X_aug[i] = augment_rotation(X[idx])\n",
    "        else:  # none\n",
    "            X_aug[i] = X[idx]\n",
    "        \n",
    "        # Copy labels\n",
    "        y_p_aug[i] = y_p[idx]\n",
    "        y_t_aug[i] = y_t[idx]\n",
    "        y_c_aug[i] = y_c[idx]\n",
    "        y_mi_aug[i] = y_mi[idx]\n",
    "        y_vd_aug[i] = y_vd[idx]\n",
    "        y_sp_aug[i] = y_sp[idx]\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    X_combined = np.vstack([X, X_aug])\n",
    "    y_p_combined = np.concatenate([y_p, y_p_aug])\n",
    "    y_t_combined = np.concatenate([y_t, y_t_aug])\n",
    "    y_c_combined = np.concatenate([y_c, y_c_aug])\n",
    "    y_mi_combined = np.concatenate([y_mi, y_mi_aug])\n",
    "    y_vd_combined = np.concatenate([y_vd, y_vd_aug])\n",
    "    y_sp_combined = np.concatenate([y_sp, y_sp_aug])\n",
    "    \n",
    "    return X_combined, y_p_combined, y_t_combined, y_c_combined, y_mi_combined, y_vd_combined, y_sp_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1885,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimized_cnn(input_shape, n_classes_p, n_classes_t, n_classes_c, n_classes_mi, n_classes_vd, contextual_config):\n",
    "    \"\"\"\n",
    "    Optimized CNN using best parameters from grid search for 6 concepts:\n",
    "    - conv_filters_1: 16, conv_filters_2: 16\n",
    "    - dropout_rate: 0.4\n",
    "    - learning_rate: 0.001 (will be set in compile)\n",
    "    - batch_size: 32 (will be set in fit)\n",
    "    - Static posture used contextually based on contextual_config\n",
    "    \"\"\"\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Conv layer 1 (optimized: 16 filters)\n",
    "    x = layers.Conv1D(16, 3, activation='relu', padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    \n",
    "    # Conv layer 2 (optimized: 16 filters)\n",
    "    x = layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Dropout (optimized: 0.4)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Static posture context (binary feature)\n",
    "    static_context = layers.Dense(1, activation='sigmoid', name='static_context')(x)\n",
    "    \n",
    "    # Output heads for each concept - use contextual configuration\n",
    "    outputs = []\n",
    "    output_names = []\n",
    "    \n",
    "    # Independent concepts (don't use static context)\n",
    "    periodicity = layers.Dense(n_classes_p, activation='softmax', name='periodicity')(x)\n",
    "    temporal_stability = layers.Dense(n_classes_t, activation='softmax', name='temporal_stability')(x)\n",
    "    coordination = layers.Dense(n_classes_c, activation='softmax', name='coordination')(x)\n",
    "    \n",
    "    outputs.extend([periodicity, temporal_stability, coordination])\n",
    "    output_names.extend(['periodicity', 'temporal_stability', 'coordination'])\n",
    "    \n",
    "    # Contextual concepts (use static context if configured)\n",
    "    if contextual_config.get('motion_intensity', False):\n",
    "        motion_intensity_input = layers.Concatenate()([x, static_context])\n",
    "        motion_intensity = layers.Dense(n_classes_mi, activation='softmax', name='motion_intensity')(motion_intensity_input)\n",
    "    else:\n",
    "        motion_intensity = layers.Dense(n_classes_mi, activation='softmax', name='motion_intensity')(x)\n",
    "    \n",
    "    if contextual_config.get('vertical_dominance', False):\n",
    "        vertical_dominance_input = layers.Concatenate()([x, static_context])\n",
    "        vertical_dominance = layers.Dense(n_classes_vd, activation='softmax', name='vertical_dominance')(vertical_dominance_input)\n",
    "    else:\n",
    "        vertical_dominance = layers.Dense(n_classes_vd, activation='softmax', name='vertical_dominance')(x)\n",
    "    \n",
    "    outputs.extend([motion_intensity, vertical_dominance])\n",
    "    output_names.extend(['motion_intensity', 'vertical_dominance'])\n",
    "    \n",
    "    # Add static context output\n",
    "    outputs.append(static_context)\n",
    "    output_names.append('static_context')\n",
    "    \n",
    "    model = models.Model(inputs=input_layer, outputs=outputs)\n",
    "    \n",
    "    print(f\"Model architecture:\")\n",
    "    print(f\"  Independent concepts: {[name for name, uses_context in contextual_config.items() if not uses_context]}\")\n",
    "    print(f\"  Contextual concepts: {[name for name, uses_context in contextual_config.items() if uses_context]}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting windows...\n",
      "Extracted 150 windows\n",
      "Window shape: (150, 100, 3)\n",
      "Label distributions:\n",
      "  Periodicity: [125  25]\n",
      "  Temporal Stability: [99 51]\n",
      "  Coordination: [80 70]\n",
      "  Motion Intensity: [148   2]\n",
      "  Vertical Dominance: [137  13]\n",
      "  Static Posture: [150]\n"
     ]
    }
   ],
   "source": [
    "# Extract windows\n",
    "print(\"Extracting windows...\")\n",
    "X, y_p, y_t, y_c, y_mi, y_vd, y_sp = extract_windows_robust(df_sensor, df_windows)\n",
    "\n",
    "print(f\"Extracted {len(X)} windows\")\n",
    "print(f\"Window shape: {X.shape}\")\n",
    "print(f\"Label distributions:\")\n",
    "print(f\"  Periodicity: {np.bincount(y_p.astype(int))}\")\n",
    "print(f\"  Temporal Stability: {np.bincount(y_t.astype(int))}\")\n",
    "print(f\"  Coordination: {np.bincount(y_c.astype(int))}\")\n",
    "print(f\"  Motion Intensity: {np.bincount(y_mi.astype(int))}\")\n",
    "print(f\"  Vertical Dominance: {np.bincount(y_vd.astype(int))}\")\n",
    "print(f\"  Static Posture: {np.bincount(y_sp.astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1887,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Train: 112 windows\n",
      "Test: 38 windows\n",
      "Static context train: [112]\n",
      "Static context test: [38]\n"
     ]
    }
   ],
   "source": [
    "# Random shuffle split (75% train, 25% test)\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_p_train, y_p_test, y_t_train, y_t_test, y_c_train, y_c_test, y_mi_train, y_mi_test, y_vd_train, y_vd_test, y_sp_train, y_sp_test = train_test_split(\n",
    "    X, y_p, y_t, y_c, y_mi, y_vd, y_sp, test_size=0.25, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "# Convert static posture to binary context (0.0 -> 0, 1.0 -> 1)\n",
    "y_sp_context_train = (y_sp_train > 0).astype(int)\n",
    "y_sp_context_test = (y_sp_test > 0).astype(int)\n",
    "\n",
    "print(f\"Train: {len(X_train)} windows\")\n",
    "print(f\"Test: {len(X_test)} windows\")\n",
    "print(f\"Static context train: {np.bincount(y_sp_context_train)}\")\n",
    "print(f\"Static context test: {np.bincount(y_sp_context_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting training data...\n",
      "Original train: 112 windows\n",
      "Augmented train: 1232 windows\n",
      "Augmentation factor: 11.0x\n",
      "Static context train aug: [1232]\n"
     ]
    }
   ],
   "source": [
    "# Apply augmentation\n",
    "print(\"Augmenting training data...\")\n",
    "X_train_aug, y_p_train_aug, y_t_train_aug, y_c_train_aug, y_mi_train_aug, y_vd_train_aug, y_sp_train_aug = augment_dataset(\n",
    "    X_train, y_p_train, y_t_train, y_c_train, y_mi_train, y_vd_train, y_sp_train, factor=10\n",
    ")\n",
    "\n",
    "# Convert static posture to binary context for augmented data\n",
    "y_sp_context_train_aug = (y_sp_train_aug > 0).astype(int)\n",
    "\n",
    "print(f\"Original train: {len(X_train)} windows\")\n",
    "print(f\"Augmented train: {len(X_train_aug)} windows\")\n",
    "print(f\"Augmentation factor: {len(X_train_aug) / len(X_train):.1f}x\")\n",
    "print(f\"Static context train aug: {np.bincount(y_sp_context_train_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels converted to categorical format\n",
      "Static context train shape: (1232,)\n",
      "Static context test shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to categorical\n",
    "y_p_train_cat = to_categorical(y_p_train_aug * 2, num_classes=3)\n",
    "y_t_train_cat = to_categorical(y_t_train_aug * 2, num_classes=3)\n",
    "y_c_train_cat = to_categorical(y_c_train_aug * 2, num_classes=3)\n",
    "y_mi_train_cat = to_categorical(y_mi_train_aug * 2, num_classes=3)\n",
    "y_vd_train_cat = to_categorical(y_vd_train_aug * 2, num_classes=3)\n",
    "\n",
    "y_p_test_cat = to_categorical(y_p_test * 2, num_classes=3)\n",
    "y_t_test_cat = to_categorical(y_t_test * 2, num_classes=3)\n",
    "y_c_test_cat = to_categorical(y_c_test * 2, num_classes=3)\n",
    "y_mi_test_cat = to_categorical(y_mi_test * 2, num_classes=3)\n",
    "y_vd_test_cat = to_categorical(y_vd_test * 2, num_classes=3)\n",
    "\n",
    "# Static context is already binary (0 or 1), no need for categorical conversion\n",
    "y_sp_context_train_cat = y_sp_context_train_aug.astype(float)\n",
    "y_sp_context_test_cat = y_sp_context_test.astype(float)\n",
    "\n",
    "print(\"Labels converted to categorical format\")\n",
    "print(f\"Static context train shape: {y_sp_context_train_cat.shape}\")\n",
    "print(f\"Static context test shape: {y_sp_context_test_cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model architecture:\n",
      "  Independent concepts: ['periodicity', 'temporal_stability', 'coordination']\n",
      "  Contextual concepts: ['motion_intensity', 'vertical_dominance']\n",
      "Model parameters: 1,350\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_99\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_99\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_99      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_198 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ input_layer_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_198[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_99    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_199 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │ max_pooling1d_99… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_199[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_99          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_context      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dropout_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_64      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ static_context[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_65      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ static_context[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ periodicity (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ temporal_stability  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coordination        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ motion_intensity    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │ concatenate_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vertical_dominance  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │ concatenate_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_99      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_198 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │        \u001b[38;5;34m160\u001b[0m │ input_layer_99[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m64\u001b[0m │ conv1d_198[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_99    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_199 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │        \u001b[38;5;34m784\u001b[0m │ max_pooling1d_99… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m64\u001b[0m │ conv1d_199[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_99          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_context      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dropout_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_64      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ static_context[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_65      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ static_context[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ periodicity (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ temporal_stability  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ coordination        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ motion_intensity    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m54\u001b[0m │ concatenate_64[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vertical_dominance  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m54\u001b[0m │ concatenate_65[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,350</span> (5.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,350\u001b[0m (5.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,286</span> (5.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,286\u001b[0m (5.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build and compile model\n",
    "print(\"Building model...\")\n",
    "# Build model with contextual configuration\n",
    "model = build_optimized_cnn(\n",
    "    input_shape=(X_train_aug.shape[1], X_train_aug.shape[2]),\n",
    "    n_classes_p=3, n_classes_t=3, n_classes_c=3, n_classes_mi=3, n_classes_vd=3,\n",
    "    contextual_config=contextual_config\n",
    ")\n",
    "\n",
    "# Compile with appropriate loss weights\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        'periodicity': 'categorical_crossentropy',\n",
    "        'temporal_stability': 'categorical_crossentropy',\n",
    "        'coordination': 'categorical_crossentropy',\n",
    "        'motion_intensity': 'categorical_crossentropy',\n",
    "        'vertical_dominance': 'categorical_crossentropy',\n",
    "        'static_context': 'binary_crossentropy',\n",
    "    },\n",
    "    loss_weights={'periodicity': 1.0, 'temporal_stability': 1.0, 'coordination': 1.0, 'motion_intensity': 1.0, 'vertical_dominance': 1.0, 'static_context': 0.5},\n",
    "    metrics={\n",
    "        'periodicity': ['accuracy'],\n",
    "        'temporal_stability': ['accuracy'],\n",
    "        'coordination': ['accuracy'],\n",
    "        'motion_intensity': ['accuracy'],\n",
    "        'vertical_dominance': ['accuracy'],\n",
    "        'static_context': ['accuracy'],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {model.count_params():,}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - coordination_accuracy: 0.3969 - coordination_loss: 1.2807 - loss: 6.8014 - motion_intensity_accuracy: 0.4042 - motion_intensity_loss: 1.3809 - periodicity_accuracy: 0.3328 - periodicity_loss: 1.2442 - static_context_accuracy: 0.5130 - static_context_loss: 0.8825 - temporal_stability_accuracy: 0.4813 - temporal_stability_loss: 1.0590 - vertical_dominance_accuracy: 0.3231 - vertical_dominance_loss: 1.3870 - val_coordination_accuracy: 0.3158 - val_coordination_loss: 1.4264 - val_loss: 5.9784 - val_motion_intensity_accuracy: 0.6316 - val_motion_intensity_loss: 0.9999 - val_periodicity_accuracy: 0.5263 - val_periodicity_loss: 1.1265 - val_static_context_accuracy: 0.8684 - val_static_context_loss: 0.4692 - val_temporal_stability_accuracy: 0.4211 - val_temporal_stability_loss: 1.0241 - val_vertical_dominance_accuracy: 0.5000 - val_vertical_dominance_loss: 0.8575 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.5528 - coordination_loss: 0.9500 - loss: 5.3586 - motion_intensity_accuracy: 0.5747 - motion_intensity_loss: 0.9305 - periodicity_accuracy: 0.4537 - periodicity_loss: 1.0450 - static_context_accuracy: 0.5390 - static_context_loss: 0.7551 - temporal_stability_accuracy: 0.6047 - temporal_stability_loss: 0.9286 - vertical_dominance_accuracy: 0.4172 - vertical_dominance_loss: 1.1259 - val_coordination_accuracy: 0.4737 - val_coordination_loss: 1.0053 - val_loss: 5.0017 - val_motion_intensity_accuracy: 0.7368 - val_motion_intensity_loss: 0.7187 - val_periodicity_accuracy: 0.4737 - val_periodicity_loss: 1.0061 - val_static_context_accuracy: 0.9474 - val_static_context_loss: 0.4510 - val_temporal_stability_accuracy: 0.5263 - val_temporal_stability_loss: 0.9159 - val_vertical_dominance_accuracy: 0.6842 - val_vertical_dominance_loss: 0.8450 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.6055 - coordination_loss: 0.8679 - loss: 4.7422 - motion_intensity_accuracy: 0.7281 - motion_intensity_loss: 0.7133 - periodicity_accuracy: 0.5495 - periodicity_loss: 0.9473 - static_context_accuracy: 0.5779 - static_context_loss: 0.7244 - temporal_stability_accuracy: 0.6891 - temporal_stability_loss: 0.8100 - vertical_dominance_accuracy: 0.4878 - vertical_dominance_loss: 1.0437 - val_coordination_accuracy: 0.4737 - val_coordination_loss: 0.9441 - val_loss: 4.6566 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.6111 - val_periodicity_accuracy: 0.6316 - val_periodicity_loss: 0.8485 - val_static_context_accuracy: 0.9474 - val_static_context_loss: 0.4958 - val_temporal_stability_accuracy: 0.5789 - val_temporal_stability_loss: 0.8181 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.8522 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.6331 - coordination_loss: 0.8248 - loss: 4.3819 - motion_intensity_accuracy: 0.7938 - motion_intensity_loss: 0.6412 - periodicity_accuracy: 0.6112 - periodicity_loss: 0.8648 - static_context_accuracy: 0.6258 - static_context_loss: 0.6803 - temporal_stability_accuracy: 0.7403 - temporal_stability_loss: 0.7409 - vertical_dominance_accuracy: 0.5584 - vertical_dominance_loss: 0.9681 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.8210 - val_loss: 4.3513 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.5380 - val_periodicity_accuracy: 0.6053 - val_periodicity_loss: 0.7467 - val_static_context_accuracy: 0.9474 - val_static_context_loss: 0.5139 - val_temporal_stability_accuracy: 0.6316 - val_temporal_stability_loss: 0.7639 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.8493 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.6721 - coordination_loss: 0.7751 - loss: 4.0844 - motion_intensity_accuracy: 0.8174 - motion_intensity_loss: 0.5508 - periodicity_accuracy: 0.6144 - periodicity_loss: 0.8307 - static_context_accuracy: 0.6899 - static_context_loss: 0.6268 - temporal_stability_accuracy: 0.7614 - temporal_stability_loss: 0.6983 - vertical_dominance_accuracy: 0.5844 - vertical_dominance_loss: 0.9102 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.7298 - val_loss: 4.1423 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.4629 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.6766 - val_static_context_accuracy: 0.9211 - val_static_context_loss: 0.5651 - val_temporal_stability_accuracy: 0.6316 - val_temporal_stability_loss: 0.7290 - val_vertical_dominance_accuracy: 0.5789 - val_vertical_dominance_loss: 0.8413 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.6997 - coordination_loss: 0.7301 - loss: 3.8350 - motion_intensity_accuracy: 0.8515 - motion_intensity_loss: 0.4895 - periodicity_accuracy: 0.6356 - periodicity_loss: 0.8067 - static_context_accuracy: 0.7127 - static_context_loss: 0.5899 - temporal_stability_accuracy: 0.7857 - temporal_stability_loss: 0.6522 - vertical_dominance_accuracy: 0.6250 - vertical_dominance_loss: 0.8505 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.6954 - val_loss: 3.9987 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.4260 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.6279 - val_static_context_accuracy: 0.9474 - val_static_context_loss: 0.5352 - val_temporal_stability_accuracy: 0.6316 - val_temporal_stability_loss: 0.6900 - val_vertical_dominance_accuracy: 0.6316 - val_vertical_dominance_loss: 0.8086 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7151 - coordination_loss: 0.6970 - loss: 3.6258 - motion_intensity_accuracy: 0.8531 - motion_intensity_loss: 0.4622 - periodicity_accuracy: 0.6818 - periodicity_loss: 0.7788 - static_context_accuracy: 0.8003 - static_context_loss: 0.5200 - temporal_stability_accuracy: 0.8011 - temporal_stability_loss: 0.6123 - vertical_dominance_accuracy: 0.6380 - vertical_dominance_loss: 0.8184 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.6222 - val_loss: 3.7774 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.3815 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.5860 - val_static_context_accuracy: 0.9737 - val_static_context_loss: 0.4873 - val_temporal_stability_accuracy: 0.6579 - val_temporal_stability_loss: 0.6371 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7951 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7062 - coordination_loss: 0.6836 - loss: 3.4418 - motion_intensity_accuracy: 0.8758 - motion_intensity_loss: 0.4134 - periodicity_accuracy: 0.6672 - periodicity_loss: 0.7697 - static_context_accuracy: 0.8506 - static_context_loss: 0.4656 - temporal_stability_accuracy: 0.8093 - temporal_stability_loss: 0.5619 - vertical_dominance_accuracy: 0.6623 - vertical_dominance_loss: 0.7748 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5943 - val_loss: 3.7061 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.3560 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.5636 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.4483 - val_temporal_stability_accuracy: 0.6579 - val_temporal_stability_loss: 0.6032 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7771 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7313 - coordination_loss: 0.6755 - loss: 3.3473 - motion_intensity_accuracy: 0.8563 - motion_intensity_loss: 0.4075 - periodicity_accuracy: 0.6761 - periodicity_loss: 0.7402 - static_context_accuracy: 0.9083 - static_context_loss: 0.4198 - temporal_stability_accuracy: 0.8206 - temporal_stability_loss: 0.5477 - vertical_dominance_accuracy: 0.6583 - vertical_dominance_loss: 0.7671 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5879 - val_loss: 3.5565 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.3265 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.5380 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.3781 - val_temporal_stability_accuracy: 0.6579 - val_temporal_stability_loss: 0.5755 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.7475 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7240 - coordination_loss: 0.6650 - loss: 3.2404 - motion_intensity_accuracy: 0.8677 - motion_intensity_loss: 0.3806 - periodicity_accuracy: 0.6826 - periodicity_loss: 0.7267 - static_context_accuracy: 0.9237 - static_context_loss: 0.3771 - temporal_stability_accuracy: 0.8255 - temporal_stability_loss: 0.5336 - vertical_dominance_accuracy: 0.6550 - vertical_dominance_loss: 0.7451 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5629 - val_loss: 3.4935 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.3090 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.5240 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.3406 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.5790 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.7605 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7273 - coordination_loss: 0.6348 - loss: 3.1084 - motion_intensity_accuracy: 0.8782 - motion_intensity_loss: 0.3637 - periodicity_accuracy: 0.6753 - periodicity_loss: 0.7147 - static_context_accuracy: 0.9529 - static_context_loss: 0.3231 - temporal_stability_accuracy: 0.8385 - temporal_stability_loss: 0.5061 - vertical_dominance_accuracy: 0.6623 - vertical_dominance_loss: 0.7271 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5692 - val_loss: 3.4486 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2973 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.5218 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.3132 - val_temporal_stability_accuracy: 0.6579 - val_temporal_stability_loss: 0.5481 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.7443 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7338 - coordination_loss: 0.6570 - loss: 3.0987 - motion_intensity_accuracy: 0.8701 - motion_intensity_loss: 0.3555 - periodicity_accuracy: 0.6672 - periodicity_loss: 0.7273 - static_context_accuracy: 0.9659 - static_context_loss: 0.2849 - temporal_stability_accuracy: 0.8295 - temporal_stability_loss: 0.5096 - vertical_dominance_accuracy: 0.6851 - vertical_dominance_loss: 0.7133 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5941 - val_loss: 3.4207 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2750 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.5044 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.2674 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.5502 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.7273 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7411 - coordination_loss: 0.6243 - loss: 2.9672 - motion_intensity_accuracy: 0.8750 - motion_intensity_loss: 0.3373 - periodicity_accuracy: 0.6907 - periodicity_loss: 0.6894 - static_context_accuracy: 0.9692 - static_context_loss: 0.2564 - temporal_stability_accuracy: 0.8369 - temporal_stability_loss: 0.4829 - vertical_dominance_accuracy: 0.6664 - vertical_dominance_loss: 0.7169 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.5802 - val_loss: 3.3539 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2763 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4869 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.2208 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.5378 - val_vertical_dominance_accuracy: 0.6842 - val_vertical_dominance_loss: 0.7176 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7622 - coordination_loss: 0.6146 - loss: 2.9104 - motion_intensity_accuracy: 0.8782 - motion_intensity_loss: 0.3192 - periodicity_accuracy: 0.6924 - periodicity_loss: 0.7019 - static_context_accuracy: 0.9716 - static_context_loss: 0.2315 - temporal_stability_accuracy: 0.8377 - temporal_stability_loss: 0.4736 - vertical_dominance_accuracy: 0.6786 - vertical_dominance_loss: 0.6821 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5694 - val_loss: 3.3218 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2629 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4924 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.2092 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5288 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.7166 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7549 - coordination_loss: 0.6055 - loss: 2.8999 - motion_intensity_accuracy: 0.8831 - motion_intensity_loss: 0.3114 - periodicity_accuracy: 0.6883 - periodicity_loss: 0.7229 - static_context_accuracy: 0.9773 - static_context_loss: 0.2113 - temporal_stability_accuracy: 0.8458 - temporal_stability_loss: 0.4644 - vertical_dominance_accuracy: 0.6721 - vertical_dominance_loss: 0.6883 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.5753 - val_loss: 3.2980 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2596 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4798 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1876 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.5330 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.7214 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7565 - coordination_loss: 0.6132 - loss: 2.8298 - motion_intensity_accuracy: 0.8807 - motion_intensity_loss: 0.3161 - periodicity_accuracy: 0.7029 - periodicity_loss: 0.6847 - static_context_accuracy: 0.9821 - static_context_loss: 0.1876 - temporal_stability_accuracy: 0.8450 - temporal_stability_loss: 0.4483 - vertical_dominance_accuracy: 0.6778 - vertical_dominance_loss: 0.6713 - val_coordination_accuracy: 0.5789 - val_coordination_loss: 0.5821 - val_loss: 3.2859 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2562 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4730 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1640 - val_temporal_stability_accuracy: 0.6842 - val_temporal_stability_loss: 0.5239 - val_vertical_dominance_accuracy: 0.6842 - val_vertical_dominance_loss: 0.7141 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7516 - coordination_loss: 0.5936 - loss: 2.7822 - motion_intensity_accuracy: 0.8709 - motion_intensity_loss: 0.3113 - periodicity_accuracy: 0.6972 - periodicity_loss: 0.6745 - static_context_accuracy: 0.9878 - static_context_loss: 0.1670 - temporal_stability_accuracy: 0.8466 - temporal_stability_loss: 0.4530 - vertical_dominance_accuracy: 0.6940 - vertical_dominance_loss: 0.6649 - val_coordination_accuracy: 0.5789 - val_coordination_loss: 0.5852 - val_loss: 3.3019 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2603 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4765 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1283 - val_temporal_stability_accuracy: 0.6579 - val_temporal_stability_loss: 0.5481 - val_vertical_dominance_accuracy: 0.6842 - val_vertical_dominance_loss: 0.6955 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7565 - coordination_loss: 0.5862 - loss: 2.7420 - motion_intensity_accuracy: 0.8961 - motion_intensity_loss: 0.2940 - periodicity_accuracy: 0.7037 - periodicity_loss: 0.6889 - static_context_accuracy: 0.9919 - static_context_loss: 0.1498 - temporal_stability_accuracy: 0.8458 - temporal_stability_loss: 0.4365 - vertical_dominance_accuracy: 0.6794 - vertical_dominance_loss: 0.6611 - val_coordination_accuracy: 0.5789 - val_coordination_loss: 0.6056 - val_loss: 3.2618 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2417 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4729 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1278 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5257 - val_vertical_dominance_accuracy: 0.6842 - val_vertical_dominance_loss: 0.7113 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7662 - coordination_loss: 0.5727 - loss: 2.6950 - motion_intensity_accuracy: 0.8912 - motion_intensity_loss: 0.2777 - periodicity_accuracy: 0.6948 - periodicity_loss: 0.6663 - static_context_accuracy: 0.9927 - static_context_loss: 0.1363 - temporal_stability_accuracy: 0.8482 - temporal_stability_loss: 0.4437 - vertical_dominance_accuracy: 0.6688 - vertical_dominance_loss: 0.6662 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.5907 - val_loss: 3.2442 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2358 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4646 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1254 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5230 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7280 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7484 - coordination_loss: 0.5927 - loss: 2.7105 - motion_intensity_accuracy: 0.8839 - motion_intensity_loss: 0.2840 - periodicity_accuracy: 0.6997 - periodicity_loss: 0.6739 - static_context_accuracy: 0.9878 - static_context_loss: 0.1347 - temporal_stability_accuracy: 0.8377 - temporal_stability_loss: 0.4360 - vertical_dominance_accuracy: 0.6916 - vertical_dominance_loss: 0.6608 - val_coordination_accuracy: 0.5789 - val_coordination_loss: 0.5839 - val_loss: 3.2425 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2380 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4785 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1100 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5251 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.7124 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7719 - coordination_loss: 0.5483 - loss: 2.5963 - motion_intensity_accuracy: 0.9002 - motion_intensity_loss: 0.2667 - periodicity_accuracy: 0.7086 - periodicity_loss: 0.6573 - static_context_accuracy: 0.9870 - static_context_loss: 0.1242 - temporal_stability_accuracy: 0.8580 - temporal_stability_loss: 0.4114 - vertical_dominance_accuracy: 0.6907 - vertical_dominance_loss: 0.6482 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.6258 - val_loss: 3.3229 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2406 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4713 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.1056 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5413 - val_vertical_dominance_accuracy: 0.6579 - val_vertical_dominance_loss: 0.7157 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7679 - coordination_loss: 0.5537 - loss: 2.5830 - motion_intensity_accuracy: 0.8896 - motion_intensity_loss: 0.2644 - periodicity_accuracy: 0.7119 - periodicity_loss: 0.6359 - static_context_accuracy: 0.9919 - static_context_loss: 0.1148 - temporal_stability_accuracy: 0.8588 - temporal_stability_loss: 0.4271 - vertical_dominance_accuracy: 0.6769 - vertical_dominance_loss: 0.6477 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.5592 - val_loss: 3.1689 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2352 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4657 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0934 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4965 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7505 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7752 - coordination_loss: 0.5445 - loss: 2.5473 - motion_intensity_accuracy: 0.9131 - motion_intensity_loss: 0.2518 - periodicity_accuracy: 0.7200 - periodicity_loss: 0.6441 - static_context_accuracy: 0.9886 - static_context_loss: 0.1122 - temporal_stability_accuracy: 0.8588 - temporal_stability_loss: 0.4097 - vertical_dominance_accuracy: 0.6891 - vertical_dominance_loss: 0.6452 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.5580 - val_loss: 3.1733 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2282 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4715 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0863 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5069 - val_vertical_dominance_accuracy: 0.6316 - val_vertical_dominance_loss: 0.7311 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7784 - coordination_loss: 0.5472 - loss: 2.5264 - motion_intensity_accuracy: 0.8977 - motion_intensity_loss: 0.2558 - periodicity_accuracy: 0.7192 - periodicity_loss: 0.6475 - static_context_accuracy: 0.9894 - static_context_loss: 0.1022 - temporal_stability_accuracy: 0.8433 - temporal_stability_loss: 0.4044 - vertical_dominance_accuracy: 0.7078 - vertical_dominance_loss: 0.6241 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.5807 - val_loss: 3.2223 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2218 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4649 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0873 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.5236 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7406 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7703 - coordination_loss: 0.5424 - loss: 2.5467 - motion_intensity_accuracy: 0.9042 - motion_intensity_loss: 0.2494 - periodicity_accuracy: 0.7216 - periodicity_loss: 0.6588 - static_context_accuracy: 0.9951 - static_context_loss: 0.0959 - temporal_stability_accuracy: 0.8555 - temporal_stability_loss: 0.4171 - vertical_dominance_accuracy: 0.7054 - vertical_dominance_loss: 0.6257 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.5383 - val_loss: 3.1787 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2365 - val_periodicity_accuracy: 0.7632 - val_periodicity_loss: 0.4697 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0733 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5047 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7485 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7792 - coordination_loss: 0.5297 - loss: 2.4969 - motion_intensity_accuracy: 0.8977 - motion_intensity_loss: 0.2539 - periodicity_accuracy: 0.7273 - periodicity_loss: 0.6426 - static_context_accuracy: 0.9951 - static_context_loss: 0.0891 - temporal_stability_accuracy: 0.8555 - temporal_stability_loss: 0.4041 - vertical_dominance_accuracy: 0.6972 - vertical_dominance_loss: 0.6233 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.5438 - val_loss: 3.1596 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2237 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4720 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0625 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.5105 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7404 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7841 - coordination_loss: 0.5203 - loss: 2.4935 - motion_intensity_accuracy: 0.9099 - motion_intensity_loss: 0.2517 - periodicity_accuracy: 0.7119 - periodicity_loss: 0.6340 - static_context_accuracy: 0.9919 - static_context_loss: 0.0987 - temporal_stability_accuracy: 0.8580 - temporal_stability_loss: 0.3968 - vertical_dominance_accuracy: 0.6851 - vertical_dominance_loss: 0.6396 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5596 - val_loss: 3.2110 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2218 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4724 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0553 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5182 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7364 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8093 - coordination_loss: 0.4943 - loss: 2.3735 - motion_intensity_accuracy: 0.9067 - motion_intensity_loss: 0.2401 - periodicity_accuracy: 0.7256 - periodicity_loss: 0.6238 - static_context_accuracy: 0.9878 - static_context_loss: 0.0887 - temporal_stability_accuracy: 0.8726 - temporal_stability_loss: 0.3674 - vertical_dominance_accuracy: 0.7143 - vertical_dominance_loss: 0.6088 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.6249 - val_loss: 3.2518 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2253 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4683 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0520 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.5262 - val_vertical_dominance_accuracy: 0.6316 - val_vertical_dominance_loss: 0.7184 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7987 - coordination_loss: 0.4987 - loss: 2.3775 - motion_intensity_accuracy: 0.8929 - motion_intensity_loss: 0.2515 - periodicity_accuracy: 0.7192 - periodicity_loss: 0.6209 - static_context_accuracy: 0.9927 - static_context_loss: 0.0760 - temporal_stability_accuracy: 0.8653 - temporal_stability_loss: 0.3755 - vertical_dominance_accuracy: 0.7256 - vertical_dominance_loss: 0.5935 - val_coordination_accuracy: 0.6053 - val_coordination_loss: 0.5914 - val_loss: 3.2605 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2146 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.4712 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0565 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5195 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7716 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7963 - coordination_loss: 0.4947 - loss: 2.3802 - motion_intensity_accuracy: 0.9058 - motion_intensity_loss: 0.2478 - periodicity_accuracy: 0.7443 - periodicity_loss: 0.6101 - static_context_accuracy: 0.9886 - static_context_loss: 0.0834 - temporal_stability_accuracy: 0.8726 - temporal_stability_loss: 0.3741 - vertical_dominance_accuracy: 0.7151 - vertical_dominance_loss: 0.6123 - val_coordination_accuracy: 0.7105 - val_coordination_loss: 0.5183 - val_loss: 3.1313 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2287 - val_periodicity_accuracy: 0.6579 - val_periodicity_loss: 0.4854 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0493 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4997 - val_vertical_dominance_accuracy: 0.6842 - val_vertical_dominance_loss: 0.7370 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8044 - coordination_loss: 0.4828 - loss: 2.3541 - motion_intensity_accuracy: 0.9075 - motion_intensity_loss: 0.2269 - periodicity_accuracy: 0.7192 - periodicity_loss: 0.6221 - static_context_accuracy: 0.9951 - static_context_loss: 0.0741 - temporal_stability_accuracy: 0.8742 - temporal_stability_loss: 0.3704 - vertical_dominance_accuracy: 0.6964 - vertical_dominance_loss: 0.6167 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.5266 - val_loss: 3.1349 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2063 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.4905 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0544 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4941 - val_vertical_dominance_accuracy: 0.6316 - val_vertical_dominance_loss: 0.7829 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7946 - coordination_loss: 0.5083 - loss: 2.4053 - motion_intensity_accuracy: 0.9131 - motion_intensity_loss: 0.2327 - periodicity_accuracy: 0.7338 - periodicity_loss: 0.6191 - static_context_accuracy: 0.9943 - static_context_loss: 0.0772 - temporal_stability_accuracy: 0.8620 - temporal_stability_loss: 0.3716 - vertical_dominance_accuracy: 0.7013 - vertical_dominance_loss: 0.6370 - val_coordination_accuracy: 0.6316 - val_coordination_loss: 0.5289 - val_loss: 3.1833 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2156 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4743 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0476 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5098 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7884 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8101 - coordination_loss: 0.4700 - loss: 2.3139 - motion_intensity_accuracy: 0.8977 - motion_intensity_loss: 0.2433 - periodicity_accuracy: 0.7313 - periodicity_loss: 0.5986 - static_context_accuracy: 0.9951 - static_context_loss: 0.0660 - temporal_stability_accuracy: 0.8596 - temporal_stability_loss: 0.3683 - vertical_dominance_accuracy: 0.7289 - vertical_dominance_loss: 0.5960 - val_coordination_accuracy: 0.7105 - val_coordination_loss: 0.5649 - val_loss: 3.2444 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2136 - val_periodicity_accuracy: 0.6579 - val_periodicity_loss: 0.5000 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0472 - val_temporal_stability_accuracy: 0.7105 - val_temporal_stability_loss: 0.5140 - val_vertical_dominance_accuracy: 0.6316 - val_vertical_dominance_loss: 0.7809 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.7979 - coordination_loss: 0.4849 - loss: 2.3175 - motion_intensity_accuracy: 0.9115 - motion_intensity_loss: 0.2223 - periodicity_accuracy: 0.7476 - periodicity_loss: 0.5951 - static_context_accuracy: 0.9935 - static_context_loss: 0.0707 - temporal_stability_accuracy: 0.8571 - temporal_stability_loss: 0.3766 - vertical_dominance_accuracy: 0.6989 - vertical_dominance_loss: 0.6081 - val_coordination_accuracy: 0.6579 - val_coordination_loss: 0.5215 - val_loss: 3.1431 - val_motion_intensity_accuracy: 0.9211 - val_motion_intensity_loss: 0.2154 - val_periodicity_accuracy: 0.7105 - val_periodicity_loss: 0.4756 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0394 - val_temporal_stability_accuracy: 0.7632 - val_temporal_stability_loss: 0.4943 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7760 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8068 - coordination_loss: 0.4770 - loss: 2.2693 - motion_intensity_accuracy: 0.9107 - motion_intensity_loss: 0.2334 - periodicity_accuracy: 0.7468 - periodicity_loss: 0.5777 - static_context_accuracy: 0.9878 - static_context_loss: 0.0722 - temporal_stability_accuracy: 0.8726 - temporal_stability_loss: 0.3525 - vertical_dominance_accuracy: 0.7224 - vertical_dominance_loss: 0.5939 - val_coordination_accuracy: 0.7105 - val_coordination_loss: 0.5467 - val_loss: 3.2126 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2228 - val_periodicity_accuracy: 0.7368 - val_periodicity_loss: 0.5025 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0331 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.5088 - val_vertical_dominance_accuracy: 0.6316 - val_vertical_dominance_loss: 0.7766 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8222 - coordination_loss: 0.4474 - loss: 2.2519 - motion_intensity_accuracy: 0.8994 - motion_intensity_loss: 0.2306 - periodicity_accuracy: 0.7378 - periodicity_loss: 0.6005 - static_context_accuracy: 0.9951 - static_context_loss: 0.0648 - temporal_stability_accuracy: 0.8750 - temporal_stability_loss: 0.3442 - vertical_dominance_accuracy: 0.7143 - vertical_dominance_loss: 0.5922 - val_coordination_accuracy: 0.7105 - val_coordination_loss: 0.4998 - val_loss: 3.1356 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2185 - val_periodicity_accuracy: 0.6579 - val_periodicity_loss: 0.4865 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0342 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4966 - val_vertical_dominance_accuracy: 0.5789 - val_vertical_dominance_loss: 0.7644 - learning_rate: 5.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8003 - coordination_loss: 0.4602 - loss: 2.2587 - motion_intensity_accuracy: 0.9058 - motion_intensity_loss: 0.2352 - periodicity_accuracy: 0.7557 - periodicity_loss: 0.5803 - static_context_accuracy: 0.9968 - static_context_loss: 0.0621 - temporal_stability_accuracy: 0.8831 - temporal_stability_loss: 0.3322 - vertical_dominance_accuracy: 0.6972 - vertical_dominance_loss: 0.6141 - val_coordination_accuracy: 0.7105 - val_coordination_loss: 0.5103 - val_loss: 3.1615 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2143 - val_periodicity_accuracy: 0.6842 - val_periodicity_loss: 0.4803 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0337 - val_temporal_stability_accuracy: 0.7632 - val_temporal_stability_loss: 0.5057 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7731 - learning_rate: 5.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8141 - coordination_loss: 0.4661 - loss: 2.2807 - motion_intensity_accuracy: 0.9042 - motion_intensity_loss: 0.2450 - periodicity_accuracy: 0.7500 - periodicity_loss: 0.5822 - static_context_accuracy: 0.9951 - static_context_loss: 0.0645 - temporal_stability_accuracy: 0.8734 - temporal_stability_loss: 0.3533 - vertical_dominance_accuracy: 0.7094 - vertical_dominance_loss: 0.5970 - val_coordination_accuracy: 0.6842 - val_coordination_loss: 0.4998 - val_loss: 3.1453 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2116 - val_periodicity_accuracy: 0.6579 - val_periodicity_loss: 0.4834 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0314 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.5074 - val_vertical_dominance_accuracy: 0.5789 - val_vertical_dominance_loss: 0.7680 - learning_rate: 5.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8011 - coordination_loss: 0.4759 - loss: 2.2675 - motion_intensity_accuracy: 0.9010 - motion_intensity_loss: 0.2334 - periodicity_accuracy: 0.7508 - periodicity_loss: 0.5723 - static_context_accuracy: 0.9984 - static_context_loss: 0.0596 - temporal_stability_accuracy: 0.8701 - temporal_stability_loss: 0.3548 - vertical_dominance_accuracy: 0.7029 - vertical_dominance_loss: 0.6002 - val_coordination_accuracy: 0.7105 - val_coordination_loss: 0.5029 - val_loss: 3.1621 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2120 - val_periodicity_accuracy: 0.6579 - val_periodicity_loss: 0.4937 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0316 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.5095 - val_vertical_dominance_accuracy: 0.6053 - val_vertical_dominance_loss: 0.7738 - learning_rate: 5.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - coordination_accuracy: 0.8093 - coordination_loss: 0.4592 - loss: 2.2859 - motion_intensity_accuracy: 0.9156 - motion_intensity_loss: 0.2233 - periodicity_accuracy: 0.7492 - periodicity_loss: 0.5897 - static_context_accuracy: 0.9894 - static_context_loss: 0.0695 - temporal_stability_accuracy: 0.8718 - temporal_stability_loss: 0.3579 - vertical_dominance_accuracy: 0.6932 - vertical_dominance_loss: 0.6215 - val_coordination_accuracy: 0.7105 - val_coordination_loss: 0.5210 - val_loss: 3.1436 - val_motion_intensity_accuracy: 0.8947 - val_motion_intensity_loss: 0.2148 - val_periodicity_accuracy: 0.6579 - val_periodicity_loss: 0.4850 - val_static_context_accuracy: 1.0000 - val_static_context_loss: 0.0318 - val_temporal_stability_accuracy: 0.7368 - val_temporal_stability_loss: 0.4928 - val_vertical_dominance_accuracy: 0.6316 - val_vertical_dominance_loss: 0.7737 - learning_rate: 5.0000e-04\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Training model...\")\n",
    "history = model.fit(\n",
    "    X_train_aug,\n",
    "    [y_p_train_cat, y_t_train_cat, y_c_train_cat, y_mi_train_cat, y_vd_train_cat, y_sp_context_train_cat],\n",
    "    validation_data=(X_test, [y_p_test_cat, y_t_test_cat, y_c_test_cat, y_mi_test_cat, y_vd_test_cat, y_sp_context_test_cat]),\n",
    "    epochs=200,\n",
    "    batch_size=32,  # Optimized parameter from grid search\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1892,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "\n",
      "=== MODEL PERFORMANCE ===\n",
      "Periodicity Accuracy: 0.7105\n",
      "Temporal Stability Accuracy: 0.8947\n",
      "Coordination Accuracy: 0.6579\n",
      "Motion Intensity Accuracy: 1.0000\n",
      "Vertical Dominance Accuracy: 0.7368\n",
      "\n",
      "Overall Accuracy (5 concepts): 0.8000\n",
      "\n",
      "Note: Static context is used internally to help motion concepts but is not evaluated as a separate concept.\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model...\")\n",
    "results = model.evaluate(X_test, [y_p_test_cat, y_t_test_cat, y_c_test_cat, y_mi_test_cat, y_vd_test_cat, y_sp_context_test_cat], verbose=0)\n",
    "\n",
    "# Extract accuracies - only evaluate the 5 main concepts\n",
    "if len(results) >= 13:\n",
    "    periodicity_acc = results[7]\n",
    "    temporal_stability_acc = results[8] \n",
    "    coordination_acc = results[9]\n",
    "    motion_intensity_acc = results[10]\n",
    "    vertical_dominance_acc = results[11]\n",
    "    # static_context_acc = results[12]  # Not evaluated - just a helper feature\n",
    "    overall_acc = (periodicity_acc + temporal_stability_acc + coordination_acc + motion_intensity_acc + vertical_dominance_acc) / 5\n",
    "else:\n",
    "    print(\"Unexpected results structure, using alternative approach...\")\n",
    "    # Alternative: Get predictions and calculate accuracy manually\n",
    "    predictions = model.predict(X_test, verbose=0)\n",
    "    periodicity_pred = np.argmax(predictions[0], axis=1)\n",
    "    temporal_stability_pred = np.argmax(predictions[1], axis=1)\n",
    "    coordination_pred = np.argmax(predictions[2], axis=1)\n",
    "    motion_intensity_pred = np.argmax(predictions[3], axis=1)\n",
    "    vertical_dominance_pred = np.argmax(predictions[4], axis=1)\n",
    "    # static_context_pred = (predictions[5] > 0.5).astype(int)  # Not evaluated\n",
    "    \n",
    "    # Calculate accuracies for main concepts only\n",
    "    periodicity_acc = accuracy_score(np.argmax(y_p_test_cat, axis=1), periodicity_pred)\n",
    "    temporal_stability_acc = accuracy_score(np.argmax(y_t_test_cat, axis=1), temporal_stability_pred)\n",
    "    coordination_acc = accuracy_score(np.argmax(y_c_test_cat, axis=1), coordination_pred)\n",
    "    motion_intensity_acc = accuracy_score(np.argmax(y_mi_test_cat, axis=1), motion_intensity_pred)\n",
    "    vertical_dominance_acc = accuracy_score(np.argmax(y_vd_test_cat, axis=1), vertical_dominance_pred)\n",
    "    overall_acc = (periodicity_acc + temporal_stability_acc + coordination_acc + motion_intensity_acc + vertical_dominance_acc) / 5\n",
    "\n",
    "print(f\"\\n=== MODEL PERFORMANCE ===\")\n",
    "print(f\"Periodicity Accuracy: {periodicity_acc:.4f}\")\n",
    "print(f\"Temporal Stability Accuracy: {temporal_stability_acc:.4f}\")\n",
    "print(f\"Coordination Accuracy: {coordination_acc:.4f}\")\n",
    "print(f\"Motion Intensity Accuracy: {motion_intensity_acc:.4f}\")\n",
    "print(f\"Vertical Dominance Accuracy: {vertical_dominance_acc:.4f}\")\n",
    "print(f\"\\nOverall Accuracy (5 concepts): {overall_acc:.4f}\")\n",
    "print(f\"\\nNote: Static context is used internally to help motion concepts but is not evaluated as a separate concept.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
