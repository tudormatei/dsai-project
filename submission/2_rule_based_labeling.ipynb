{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b7b3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6edcfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"./data/merged_dataset_with_concepts.csv\")\n",
    "window_df = pd.read_csv(\"./data/merged_window_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af5ccc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8802, 10)\n",
      "(150, 8)\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.shape)\n",
    "print(window_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e492226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data columns to save: ['user', 'activity', 'timestamp', 'x-axis', 'y-axis', 'z-axis', 'time_s', 'periodicity', 'temporal_stability', 'coordination', 'movement_variability', 'movement_consistency']\n",
      "Window data columns to save: ['window_idx', 'user', 'activity', 'start_time', 'end_time', 'periodicity', 'temporal_stability', 'coordination', 'movement_variability', 'movement_consistency']\n"
     ]
    }
   ],
   "source": [
    "# these are what rule based concepts we're calculating\n",
    "rule_based_concepts = [\"movement_variability\", \"movement_consistency\"]\n",
    "\n",
    "# which of these concepts to actually exclude from the export csvs (so what concepts we actually dont want used for training)\n",
    "rules_to_exclude_from_saving = [\"static_posture\"]\n",
    "\n",
    "raw_df_cols_to_save = [col for col in (list(raw_df.columns) + rule_based_concepts)  if col not in rules_to_exclude_from_saving]\n",
    "window_df_cols_to_save = [col for col in (list(window_df.columns) + rule_based_concepts) if col not in rules_to_exclude_from_saving]\n",
    "print(\"Raw data columns to save:\", raw_df_cols_to_save)\n",
    "print(\"Window data columns to save:\", window_df_cols_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "366efea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating movement variability for raw data...\n",
      "Calculating movement consistency for raw data...\n",
      "New rule-based concepts computed for raw data!\n",
      "\n",
      "Calculating movement variability for window data...\n",
      "Calculating movement consistency for window data...\n",
      "New rule-based concepts computed for window data!\n",
      "\n",
      "=== NORMALIZATION VERIFICATION ===\n",
      "Raw data - Movement variability range: 0.0000 to 1.0000\n",
      "Raw data - Movement consistency range: 0.0000 to 1.0000\n",
      "Raw data - Static posture range: 0.0000 to 1.0000\n",
      "\n",
      "Window data - Movement variability range: 0.0000 to 1.0000\n",
      "Window data - Movement consistency range: 0.0000 to 1.0000\n",
      "Contextual Features Configuration:\n",
      "  periodicity: Independent\n",
      "  temporal_stability: Independent\n",
      "  coordination: Independent\n",
      "  movement_variability: Independent\n",
      "  movement_consistency: Independent\n"
     ]
    }
   ],
   "source": [
    "# Calculate concepts for both raw data and window data\n",
    "\n",
    "def calculate_raw_data_movement_variability(df, window_size=50):\n",
    "    \"\"\"Calculate movement variability for each row using a sliding window\"\"\"\n",
    "    variability_scores = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        start_idx = max(0, i - window_size // 2)\n",
    "        end_idx = min(len(df), i + window_size // 2)\n",
    "        \n",
    "        window_data = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        if len(window_data) < 5:\n",
    "            variability_scores.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        variability = magnitude.std()\n",
    "        variability_scores.append(variability)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    variability_scores = np.array(variability_scores)\n",
    "    if variability_scores.max() > variability_scores.min():\n",
    "        normalized = (variability_scores - variability_scores.min()) / (variability_scores.max() - variability_scores.min())\n",
    "    else:\n",
    "        normalized = np.zeros_like(variability_scores)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def calculate_raw_data_movement_consistency(df, window_size=50):\n",
    "    \"\"\"Calculate movement consistency for each row using a sliding window\"\"\"\n",
    "    consistency_scores = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        start_idx = max(0, i - window_size // 2)\n",
    "        end_idx = min(len(df), i + window_size // 2)\n",
    "        \n",
    "        window_data = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        if len(window_data) < 10:\n",
    "            consistency_scores.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        if len(magnitude) >= 2:\n",
    "            correlation = np.corrcoef(magnitude[:-1], magnitude[1:])[0, 1]\n",
    "            if np.isnan(correlation):\n",
    "                consistency_scores.append(0.0)\n",
    "            else:\n",
    "                consistency_scores.append(correlation)\n",
    "        else:\n",
    "            consistency_scores.append(0.0)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    consistency_scores = np.array(consistency_scores)\n",
    "    if consistency_scores.max() > consistency_scores.min():\n",
    "        normalized = (consistency_scores - consistency_scores.min()) / (consistency_scores.max() - consistency_scores.min())\n",
    "    else:\n",
    "        normalized = np.zeros_like(consistency_scores)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def calculate_movement_variability(df_sensor, df_windows):\n",
    "    \"\"\"Calculate movement variability as normalized standard deviation of magnitude for each window\"\"\"\n",
    "    variability_scores = []\n",
    "    \n",
    "    # First pass: collect all variability values to calculate global min/max for normalization\n",
    "    temp_variability = []\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 5:  \n",
    "            continue\n",
    "            \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        variability = magnitude.std()\n",
    "        temp_variability.append(variability)\n",
    "    \n",
    "    # Calculate normalization parameters\n",
    "    if len(temp_variability) > 0:\n",
    "        min_var = min(temp_variability)\n",
    "        max_var = max(temp_variability)\n",
    "        var_range = max_var - min_var\n",
    "    else:\n",
    "        min_var = 0\n",
    "        var_range = 1\n",
    "    \n",
    "    # Second pass: calculate normalized variability\n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            variability_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 5:  \n",
    "            variability_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        variability = magnitude.std()\n",
    "        \n",
    "        # Normalize to [0, 1] range\n",
    "        if var_range > 0:\n",
    "            normalized_variability = (variability - min_var) / var_range\n",
    "        else:\n",
    "            normalized_variability = 0.0\n",
    "            \n",
    "        variability_scores.append(normalized_variability)\n",
    "    \n",
    "    return np.array(variability_scores)\n",
    "\n",
    "def calculate_movement_consistency(df_sensor, df_windows):\n",
    "    \"\"\"Calculate movement consistency as normalized temporal correlation for each window\"\"\"\n",
    "    consistency_scores = []\n",
    "    \n",
    "    # First pass: collect all correlation values to calculate global min/max for normalization\n",
    "    temp_consistency = []\n",
    "    \n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 10:  \n",
    "            continue\n",
    "            \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        if len(magnitude) >= 2:\n",
    "            correlation = np.corrcoef(magnitude[:-1], magnitude[1:])[0, 1]\n",
    "            if not np.isnan(correlation):\n",
    "                temp_consistency.append(correlation)\n",
    "    \n",
    "    # Calculate normalization parameters\n",
    "    if len(temp_consistency) > 0:\n",
    "        min_consistency = min(temp_consistency)\n",
    "        max_consistency = max(temp_consistency)\n",
    "        consistency_range = max_consistency - min_consistency\n",
    "    else:\n",
    "        min_consistency = 0\n",
    "        consistency_range = 1\n",
    "    \n",
    "    # Second pass: calculate normalized consistency\n",
    "    for _, window_row in df_windows.iterrows():\n",
    "        user = window_row['user']\n",
    "        activity = window_row['activity']\n",
    "        start_time = window_row['start_time']\n",
    "        end_time = window_row['end_time']\n",
    "        \n",
    "        user_activity_data = df_sensor[(df_sensor['user'] == user) & \n",
    "                                      (df_sensor['activity'] == activity)].copy()\n",
    "        \n",
    "        if len(user_activity_data) == 0:\n",
    "            consistency_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        mask = ((user_activity_data['time_s'] >= start_time) & \n",
    "                (user_activity_data['time_s'] <= end_time))\n",
    "        window_data = user_activity_data[mask]\n",
    "        \n",
    "        if len(window_data) < 10:  \n",
    "            consistency_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        magnitude = np.sqrt(window_data['x-axis']**2 + window_data['y-axis']**2 + window_data['z-axis']**2)\n",
    "        \n",
    "        if len(magnitude) >= 2:\n",
    "            correlation = np.corrcoef(magnitude[:-1], magnitude[1:])[0, 1]\n",
    "            if np.isnan(correlation):\n",
    "                consistency_scores.append(0.0)\n",
    "            else:\n",
    "                # Normalize to [0, 1] range\n",
    "                if consistency_range > 0:\n",
    "                    normalized_consistency = (correlation - min_consistency) / consistency_range\n",
    "                else:\n",
    "                    normalized_consistency = 0.0\n",
    "                consistency_scores.append(normalized_consistency)\n",
    "        else:\n",
    "            consistency_scores.append(0.0)\n",
    "    \n",
    "    return np.array(consistency_scores)\n",
    "\n",
    "def detect_static_posture(df, window_size=10):\n",
    "    \"\"\"\n",
    "    Detect static posture based on signal variance, not motion intensity.\n",
    "    This removes the circular dependency.\n",
    "    \"\"\"\n",
    "    static_posture = np.zeros(len(df))\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        start_idx = max(0, i - window_size // 2)\n",
    "        end_idx = min(len(df), i + window_size // 2)\n",
    "        \n",
    "        # Get window of sensor data\n",
    "        window_data = df.iloc[start_idx:end_idx][['x-axis', 'y-axis', 'z-axis']].values\n",
    "        \n",
    "        # Calculate signal variance (not magnitude-based)\n",
    "        signal_variance = np.var(window_data, axis=0).mean()\n",
    "        \n",
    "        # Static if variance is very low (indicating minimal movement)\n",
    "        static_posture[i] = 1.0 if signal_variance < 0.5 else 0.0\n",
    "    \n",
    "    return static_posture\n",
    "\n",
    "# Apply static posture detection based on variance\n",
    "raw_df[\"static_posture\"] = detect_static_posture(raw_df)\n",
    "\n",
    "# Calculate new rule-based concepts for RAW data (using sliding windows)\n",
    "print(\"Calculating movement variability for raw data...\")\n",
    "raw_df['movement_variability'] = calculate_raw_data_movement_variability(raw_df)\n",
    "\n",
    "print(\"Calculating movement consistency for raw data...\")\n",
    "raw_df['movement_consistency'] = calculate_raw_data_movement_consistency(raw_df)\n",
    "\n",
    "print(\"New rule-based concepts computed for raw data!\")\n",
    "\n",
    "# Calculate new rule-based concepts for window data (using fixed windows)\n",
    "print(\"\\nCalculating movement variability for window data...\")\n",
    "window_df['movement_variability'] = calculate_movement_variability(raw_df, window_df)\n",
    "\n",
    "print(\"Calculating movement consistency for window data...\")\n",
    "window_df['movement_consistency'] = calculate_movement_consistency(raw_df, window_df)\n",
    "\n",
    "print(\"New rule-based concepts computed for window data!\")\n",
    "\n",
    "# Verify normalization ranges\n",
    "print(f\"\\n=== NORMALIZATION VERIFICATION ===\")\n",
    "print(f\"Raw data - Movement variability range: {raw_df['movement_variability'].min():.4f} to {raw_df['movement_variability'].max():.4f}\")\n",
    "print(f\"Raw data - Movement consistency range: {raw_df['movement_consistency'].min():.4f} to {raw_df['movement_consistency'].max():.4f}\")\n",
    "print(f\"Raw data - Static posture range: {raw_df['static_posture'].min():.4f} to {raw_df['static_posture'].max():.4f}\")\n",
    "print(f\"\\nWindow data - Movement variability range: {window_df['movement_variability'].min():.4f} to {window_df['movement_variability'].max():.4f}\")\n",
    "print(f\"Window data - Movement consistency range: {window_df['movement_consistency'].min():.4f} to {window_df['movement_consistency'].max():.4f}\")\n",
    "\n",
    "# Define contextual relationships - which features should use static posture contextually\n",
    "def get_contextual_features_config():\n",
    "    \"\"\"\n",
    "    Define which features should use static posture contextually.\n",
    "    This configuration determines how static posture influences other motion concepts.\n",
    "    \"\"\"\n",
    "    contextual_config = {\n",
    "        'periodicity': False,       # Independent - periodic patterns don't depend on static posture\n",
    "        'temporal_stability': False, # Independent - temporal stability is about consistency, not static periods\n",
    "        'coordination': False,      # Independent - coordination is about limb synchronization, not static posture\n",
    "        'movement_variability': False, # Independent - movement variability is about motion patterns, not static posture\n",
    "        'movement_consistency': False, # Independent - movement consistency is about temporal patterns, not static posture\n",
    "    }\n",
    "    return contextual_config\n",
    "\n",
    "# Get the contextual configuration\n",
    "contextual_config = get_contextual_features_config()\n",
    "print(\"Contextual Features Configuration:\")\n",
    "for feature, uses_context in contextual_config.items():\n",
    "    print(f\"  {feature}: {'Uses static posture context' if uses_context else 'Independent'}\")\n",
    "\n",
    "def compute_window_features(df, start, end):\n",
    "    segment = df[(df[\"time_s\"] >= start) & (df[\"time_s\"] <= end)]\n",
    "    if len(segment) == 0:\n",
    "        return pd.Series({\n",
    "            \"static_posture\": np.nan\n",
    "        })\n",
    "    \n",
    "    # FIXED: Static posture based on signal variance, not motion intensity\n",
    "    signal_variance = np.var(segment[['x-axis', 'y-axis', 'z-axis']].values, axis=0).mean()\n",
    "    static_posture = 1.0 if signal_variance < 0.5 else 0.0\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"static_posture\": static_posture\n",
    "    })\n",
    "\n",
    "window_features = window_df.apply(lambda row: compute_window_features(raw_df, row[\"start_time\"], row[\"end_time\"]), axis=1)\n",
    "window_df = pd.concat([window_df, window_features], axis=1)\n",
    "\n",
    "# make sure they are discrete\n",
    "\n",
    "raw_df['movement_variability'] = pd.cut(\n",
    "    raw_df['movement_variability'], \n",
    "    bins=3, \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "raw_df['movement_consistency'] = pd.cut(\n",
    "    raw_df['movement_consistency'], \n",
    "    bins=3, \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "window_df['movement_variability'] = pd.cut(\n",
    "    window_df['movement_variability'], \n",
    "    bins=3, \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "window_df['movement_consistency'] = pd.cut(\n",
    "    window_df['movement_consistency'], \n",
    "    bins=3, \n",
    "    labels=[0.0, 0.5, 1.0]\n",
    ").astype(float)\n",
    "\n",
    "raw_df.to_csv(\"./data/final_dataset.csv\", columns=raw_df_cols_to_save, index=False)\n",
    "window_df.to_csv(\"./data/final_window_labels.csv\", columns=window_df_cols_to_save, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
